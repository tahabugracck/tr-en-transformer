{"cells":[{"cell_type":"markdown","metadata":{"id":"Yn2krv22Ww6J"},"source":["## Google Colab Ortamını Hazırlama"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2468,"status":"ok","timestamp":1742106686476,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"2b09qeC6WhhG","outputId":"6b5638ce-f64c-4e9e-c102-e3dfb1af431a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.11/dist-packages (0.1.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from sacremoses) (1.4.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install torch transformers datasets tqdm sentencepiece sacremoses"]},{"cell_type":"markdown","metadata":{"id":"G-yiigBtW4LK"},"source":["## Veri Setini Yükleme ve Ön İşleme"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2297,"status":"ok","timestamp":1742106688931,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"z5RscI1JW5IY","outputId":"5666c985-dd83-411c-de76-84a7cbfeb4b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                  tr  \\\n","0            Devenin belini kıran son saman çöpüdür.   \n","1                                        Bilmiyorum.   \n","2                           Mum kendiliğinden söndü.   \n","3  On, on bir, on iki, on üç, on dört, on beş, on...   \n","4  Ek olarak yaşlılar birbirleriyle sosyalleşebil...   \n","\n","                                                  en  \n","0            The last straw breaks the camel's back.  \n","1                                      I don't know.  \n","2                     The candle went out by itself.  \n","3  Ten, eleven, twelve, thirteen, fourteen, fifte...  \n","4  In addition many groups have been formed so th...  \n"]}],"source":["import pandas as pd\n","import json\n","\n","# JSONL dosyasının bulunduğu yolu belirleyin\n","data_path = \"/content/data.jsonl\"  # Dosyanın yolu\n","data = []\n","\n","with open(data_path, \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        data.append(json.loads(line))\n","\n","# Pandas DataFrame'e dönüştürme\n","df = pd.DataFrame(data)\n","\n","# İlk birkaç satırı yazdırma\n","print(df.head())\n"]},{"cell_type":"markdown","metadata":{"id":"GHSkqqXCXc0i"},"source":["## Tokenizer Seçimi ve Veri Setinin Tokenize Edilmesi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":440},"executionInfo":{"elapsed":29797,"status":"ok","timestamp":1742106718736,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"pzcGcLWVXUDM","outputId":"7e9d9e00-53c7-4255-e493-42cd3398c997"},"outputs":[{"name":"stdout","output_type":"stream","text":["Türkçeden İngilizceye Tokenler: tensor([[31415,   187,  8922,   692,  3286,   373,   283, 29271, 33294,  2453,\n","             2,     0]])\n","İngilizceden Türkçeye Tokenler: tensor([[  71, 2169, 1517,  125, 9376,  985,  125, 3763,   47, 3739,    9, 6374,\n","          977,    4,    8,  125, 5544,    2,    0]])\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","# Tokenizer ve modeli doğrudan yükleyelim\n","tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-tr-en\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-tr-en\")\n","\n","# Örnek tokenizasyon\n","example_tr = df[\"tr\"].iloc[0]  # İlk Türkçe cümle\n","example_en = df[\"en\"].iloc[0]  # İlk İngilizce cümle\n","\n","tokens_tr2en = tokenizer(example_tr, return_tensors=\"pt\")\n","tokens_en2tr = tokenizer(example_en, return_tensors=\"pt\")\n","\n","# Tokenları yazdıralım\n","print(\"Türkçeden İngilizceye Tokenler:\", tokens_tr2en[\"input_ids\"])\n","print(\"İngilizceden Türkçeye Tokenler:\", tokens_en2tr[\"input_ids\"])\n"]},{"cell_type":"markdown","metadata":{"id":"fpGWMBThY6dt"},"source":["## Veri Setini Model İçin Hazırlama"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"elapsed":69,"status":"ok","timestamp":1742106718812,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"PfxHs7dLXhjH","outputId":"341bdb2d-9133-40b9-d743-c8f0038dec62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input IDs: torch.Size([16, 128])\n","Labels: torch.Size([16, 128])\n"]}],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","class TranslationDataset(Dataset):\n","    def __init__(self, dataframe, tokenizer, source_lang=\"tr\", target_lang=\"en\", max_length=128):\n","        self.data = dataframe\n","        self.tokenizer = tokenizer\n","        self.source_lang = source_lang\n","        self.target_lang = target_lang\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        src_text = self.data[self.source_lang].iloc[idx]  # Kaynak dildeki cümle\n","        tgt_text = self.data[self.target_lang].iloc[idx]  # Hedef dildeki çeviri\n","\n","        # Tokenize et\n","        src_encoding = self.tokenizer(src_text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n","        tgt_encoding = self.tokenizer(tgt_text, padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n","\n","        # PyTorch için tensörleri döndür\n","        return {\n","            \"input_ids\": src_encoding[\"input_ids\"].squeeze(0),\n","            \"attention_mask\": src_encoding[\"attention_mask\"].squeeze(0),\n","            \"labels\": tgt_encoding[\"input_ids\"].squeeze(0)\n","        }\n","\n","# Veri setini oluştur\n","train_dataset = TranslationDataset(df, tokenizer)\n","\n","# DataLoader: Modeli eğitirken kullanacağız\n","train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","\n","# Bir örnek alıp inceleyelim\n","batch = next(iter(train_dataloader))\n","print(\"Input IDs:\", batch[\"input_ids\"].shape)\n","print(\"Labels:\", batch[\"labels\"].shape)\n"]},{"cell_type":"markdown","metadata":{"id":"DXssAh5RZP5x"},"source":["## Modeli Eğitme"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":928},"executionInfo":{"elapsed":379,"status":"ok","timestamp":1742106719194,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"GfW9-wxZY9-z","outputId":"1c1074a4-2d50-49f5-fa9d-509bfce5a5e4"},"outputs":[{"data":{"text/plain":["MarianMTModel(\n","  (model): MarianModel(\n","    (shared): Embedding(62389, 512, padding_idx=62388)\n","    (encoder): MarianEncoder(\n","      (embed_tokens): Embedding(62389, 512, padding_idx=62388)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianEncoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): SiLU()\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decoder): MarianDecoder(\n","      (embed_tokens): Embedding(62389, 512, padding_idx=62388)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianDecoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (activation_fn): SiLU()\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): Linear(in_features=512, out_features=62389, bias=False)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"executionInfo":{"elapsed":3997114,"status":"error","timestamp":1742110716311,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"Tvqc_N2tZgX0","outputId":"1f2f4f31-d81f-4b90-9858-755bdef1cc49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[1;30;43mGörüntülenen çıkış son 5000 satıra kısaltıldı.\u001b[0m\n","Training Epoch 1:  20%|█▉        | 8696/44303 [51:43<3:32:30,  2.79it/s, loss=0.0808]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8696/44303 [51:43<3:32:30,  2.79it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8697/44303 [51:43<3:31:57,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8697/44303 [51:43<3:31:57,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8698/44303 [51:43<3:32:27,  2.79it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8698/44303 [51:44<3:32:27,  2.79it/s, loss=0.0596]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8699/44303 [51:44<3:31:26,  2.81it/s, loss=0.0596]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8699/44303 [51:44<3:31:26,  2.81it/s, loss=0.0365]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8700/44303 [51:44<3:31:18,  2.81it/s, loss=0.0365]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8700/44303 [51:45<3:31:18,  2.81it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8701/44303 [51:45<3:31:29,  2.81it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8701/44303 [51:45<3:31:29,  2.81it/s, loss=0.0989]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8702/44303 [51:45<3:31:09,  2.81it/s, loss=0.0989]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8702/44303 [51:45<3:31:09,  2.81it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8703/44303 [51:45<3:31:26,  2.81it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8703/44303 [51:46<3:31:26,  2.81it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8704/44303 [51:46<3:30:56,  2.81it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8704/44303 [51:46<3:30:56,  2.81it/s, loss=0.035] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8705/44303 [51:46<3:31:17,  2.81it/s, loss=0.035]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8705/44303 [51:46<3:31:17,  2.81it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8706/44303 [51:46<3:30:42,  2.82it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8706/44303 [51:47<3:30:42,  2.82it/s, loss=0.0677]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8707/44303 [51:47<3:31:33,  2.80it/s, loss=0.0677]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8707/44303 [51:47<3:31:33,  2.80it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8708/44303 [51:47<3:31:52,  2.80it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8708/44303 [51:47<3:31:52,  2.80it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8709/44303 [51:47<3:31:27,  2.81it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8709/44303 [51:48<3:31:27,  2.81it/s, loss=0.052] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8710/44303 [51:48<3:31:57,  2.80it/s, loss=0.052]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8710/44303 [51:48<3:31:57,  2.80it/s, loss=0.0761]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8711/44303 [51:48<3:31:34,  2.80it/s, loss=0.0761]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8711/44303 [51:48<3:31:34,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8712/44303 [51:48<3:31:28,  2.81it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8712/44303 [51:49<3:31:28,  2.81it/s, loss=0.0865]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8713/44303 [51:49<3:32:04,  2.80it/s, loss=0.0865]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8713/44303 [51:49<3:32:04,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8714/44303 [51:49<3:32:13,  2.79it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8714/44303 [51:50<3:32:13,  2.79it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8715/44303 [51:50<3:32:12,  2.80it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8715/44303 [51:50<3:32:12,  2.80it/s, loss=0.0906]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8716/44303 [51:50<3:32:42,  2.79it/s, loss=0.0906]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8716/44303 [51:50<3:32:42,  2.79it/s, loss=0.0622]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8717/44303 [51:50<3:32:07,  2.80it/s, loss=0.0622]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8717/44303 [51:51<3:32:07,  2.80it/s, loss=0.0615]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8718/44303 [51:51<3:31:28,  2.80it/s, loss=0.0615]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8718/44303 [51:51<3:31:28,  2.80it/s, loss=0.0588]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8719/44303 [51:51<3:32:20,  2.79it/s, loss=0.0588]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8719/44303 [51:51<3:32:20,  2.79it/s, loss=0.0727]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8720/44303 [51:51<3:31:36,  2.80it/s, loss=0.0727]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8720/44303 [51:52<3:31:36,  2.80it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8721/44303 [51:52<3:31:11,  2.81it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8721/44303 [51:52<3:31:11,  2.81it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8722/44303 [51:52<3:31:34,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8722/44303 [51:52<3:31:34,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8723/44303 [51:52<3:31:18,  2.81it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8723/44303 [51:53<3:31:18,  2.81it/s, loss=0.061] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8724/44303 [51:53<3:31:25,  2.80it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8724/44303 [51:53<3:31:25,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8725/44303 [51:53<3:30:56,  2.81it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8725/44303 [51:53<3:30:56,  2.81it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8726/44303 [51:53<3:31:22,  2.81it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8726/44303 [51:54<3:31:22,  2.81it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8727/44303 [51:54<3:30:48,  2.81it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8727/44303 [51:54<3:30:48,  2.81it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8728/44303 [51:54<3:31:13,  2.81it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8728/44303 [51:55<3:31:13,  2.81it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8729/44303 [51:55<3:32:00,  2.80it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8729/44303 [51:55<3:32:00,  2.80it/s, loss=0.0876]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8730/44303 [51:55<3:31:48,  2.80it/s, loss=0.0876]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8730/44303 [51:55<3:31:48,  2.80it/s, loss=0.0422]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8731/44303 [51:55<3:31:46,  2.80it/s, loss=0.0422]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8731/44303 [51:56<3:31:46,  2.80it/s, loss=0.0763]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8732/44303 [51:56<3:32:33,  2.79it/s, loss=0.0763]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8732/44303 [51:56<3:32:33,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8733/44303 [51:56<3:32:00,  2.80it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8733/44303 [51:56<3:32:00,  2.80it/s, loss=0.0615]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8734/44303 [51:56<3:32:04,  2.80it/s, loss=0.0615]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8734/44303 [51:57<3:32:04,  2.80it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8735/44303 [51:57<3:32:20,  2.79it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8735/44303 [51:57<3:32:20,  2.79it/s, loss=0.0778]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8736/44303 [51:57<3:32:49,  2.79it/s, loss=0.0778]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8736/44303 [51:57<3:32:49,  2.79it/s, loss=0.0929]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8737/44303 [51:57<3:31:33,  2.80it/s, loss=0.0929]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8737/44303 [51:58<3:31:33,  2.80it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8738/44303 [51:58<3:32:02,  2.80it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8738/44303 [51:58<3:32:02,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8739/44303 [51:58<3:31:11,  2.81it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8739/44303 [51:58<3:31:11,  2.81it/s, loss=0.033] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8740/44303 [51:58<3:31:17,  2.81it/s, loss=0.033]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8740/44303 [51:59<3:31:17,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8741/44303 [51:59<3:30:45,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8741/44303 [51:59<3:30:45,  2.81it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8742/44303 [51:59<3:31:03,  2.81it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8742/44303 [52:00<3:31:03,  2.81it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8743/44303 [52:00<3:30:54,  2.81it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8743/44303 [52:00<3:30:54,  2.81it/s, loss=0.0994]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8744/44303 [52:00<3:31:20,  2.80it/s, loss=0.0994]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8744/44303 [52:00<3:31:20,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8745/44303 [52:00<3:31:18,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8745/44303 [52:01<3:31:18,  2.80it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8746/44303 [52:01<3:31:22,  2.80it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8746/44303 [52:01<3:31:22,  2.80it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8747/44303 [52:01<3:30:53,  2.81it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8747/44303 [52:01<3:30:53,  2.81it/s, loss=0.0628]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8748/44303 [52:01<3:31:13,  2.81it/s, loss=0.0628]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8748/44303 [52:02<3:31:13,  2.81it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8749/44303 [52:02<3:30:53,  2.81it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8749/44303 [52:02<3:30:53,  2.81it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8750/44303 [52:02<3:31:12,  2.81it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8750/44303 [52:02<3:31:12,  2.81it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8751/44303 [52:02<3:31:03,  2.81it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8751/44303 [52:03<3:31:03,  2.81it/s, loss=0.0481]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8752/44303 [52:03<3:31:15,  2.80it/s, loss=0.0481]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8752/44303 [52:03<3:31:15,  2.80it/s, loss=0.0458]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8753/44303 [52:03<3:30:32,  2.81it/s, loss=0.0458]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8753/44303 [52:03<3:30:32,  2.81it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8754/44303 [52:03<3:30:47,  2.81it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8754/44303 [52:04<3:30:47,  2.81it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8755/44303 [52:04<3:30:37,  2.81it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8755/44303 [52:04<3:30:37,  2.81it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8756/44303 [52:04<3:30:40,  2.81it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8756/44303 [52:05<3:30:40,  2.81it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8757/44303 [52:05<3:31:51,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8757/44303 [52:05<3:31:51,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8758/44303 [52:05<3:31:19,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8758/44303 [52:05<3:31:19,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8759/44303 [52:05<3:31:23,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8759/44303 [52:06<3:31:23,  2.80it/s, loss=0.0574]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8760/44303 [52:06<3:31:52,  2.80it/s, loss=0.0574]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8760/44303 [52:06<3:31:52,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8761/44303 [52:06<3:31:55,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8761/44303 [52:06<3:31:55,  2.80it/s, loss=0.0749]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8762/44303 [52:06<3:31:48,  2.80it/s, loss=0.0749]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8762/44303 [52:07<3:31:48,  2.80it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8763/44303 [52:07<3:31:37,  2.80it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8763/44303 [52:07<3:31:37,  2.80it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8764/44303 [52:07<3:31:46,  2.80it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8764/44303 [52:07<3:31:46,  2.80it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8765/44303 [52:07<3:32:04,  2.79it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8765/44303 [52:08<3:32:04,  2.79it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8766/44303 [52:08<3:31:56,  2.79it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8766/44303 [52:08<3:31:56,  2.79it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8767/44303 [52:08<3:31:38,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8767/44303 [52:08<3:31:38,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8768/44303 [52:08<3:31:51,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8768/44303 [52:09<3:31:51,  2.80it/s, loss=0.0707]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8769/44303 [52:09<3:31:34,  2.80it/s, loss=0.0707]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8769/44303 [52:09<3:31:34,  2.80it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8770/44303 [52:09<3:31:36,  2.80it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8770/44303 [52:10<3:31:36,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8771/44303 [52:10<3:31:59,  2.79it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8771/44303 [52:10<3:31:59,  2.79it/s, loss=0.0777]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8772/44303 [52:10<3:31:57,  2.79it/s, loss=0.0777]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8772/44303 [52:10<3:31:57,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8773/44303 [52:10<3:31:35,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8773/44303 [52:11<3:31:35,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8774/44303 [52:11<3:31:57,  2.79it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8774/44303 [52:11<3:31:57,  2.79it/s, loss=0.052] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8775/44303 [52:11<3:31:43,  2.80it/s, loss=0.052]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8775/44303 [52:11<3:31:43,  2.80it/s, loss=0.0998]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8776/44303 [52:11<3:31:09,  2.80it/s, loss=0.0998]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8776/44303 [52:12<3:31:09,  2.80it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8777/44303 [52:12<3:31:38,  2.80it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8777/44303 [52:12<3:31:38,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8778/44303 [52:12<3:31:48,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8778/44303 [52:12<3:31:48,  2.80it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8779/44303 [52:12<3:31:12,  2.80it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8779/44303 [52:13<3:31:12,  2.80it/s, loss=0.0879]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8780/44303 [52:13<3:31:54,  2.79it/s, loss=0.0879]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8780/44303 [52:13<3:31:54,  2.79it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8781/44303 [52:13<3:30:37,  2.81it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8781/44303 [52:13<3:30:37,  2.81it/s, loss=0.0675]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8782/44303 [52:13<3:31:08,  2.80it/s, loss=0.0675]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8782/44303 [52:14<3:31:08,  2.80it/s, loss=0.0737]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8783/44303 [52:14<3:30:39,  2.81it/s, loss=0.0737]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8783/44303 [52:14<3:30:39,  2.81it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8784/44303 [52:14<3:30:52,  2.81it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8784/44303 [52:15<3:30:52,  2.81it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8785/44303 [52:15<3:31:20,  2.80it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8785/44303 [52:15<3:31:20,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8786/44303 [52:15<3:31:30,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8786/44303 [52:15<3:31:30,  2.80it/s, loss=0.0434]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8787/44303 [52:15<3:31:30,  2.80it/s, loss=0.0434]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8787/44303 [52:16<3:31:30,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8788/44303 [52:16<3:31:54,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8788/44303 [52:16<3:31:54,  2.79it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8789/44303 [52:16<3:32:05,  2.79it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8789/44303 [52:16<3:32:05,  2.79it/s, loss=0.0889]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8790/44303 [52:16<3:32:02,  2.79it/s, loss=0.0889]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8790/44303 [52:17<3:32:02,  2.79it/s, loss=0.11]  \u001b[A\n","Training Epoch 1:  20%|█▉        | 8791/44303 [52:17<3:31:30,  2.80it/s, loss=0.11]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8791/44303 [52:17<3:31:30,  2.80it/s, loss=0.0377]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8792/44303 [52:17<3:31:16,  2.80it/s, loss=0.0377]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8792/44303 [52:17<3:31:16,  2.80it/s, loss=0.0314]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8793/44303 [52:17<3:32:00,  2.79it/s, loss=0.0314]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8793/44303 [52:18<3:32:00,  2.79it/s, loss=0.07]  \u001b[A\n","Training Epoch 1:  20%|█▉        | 8794/44303 [52:18<3:32:02,  2.79it/s, loss=0.07]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8794/44303 [52:18<3:32:02,  2.79it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8795/44303 [52:18<3:32:46,  2.78it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8795/44303 [52:18<3:32:46,  2.78it/s, loss=0.048]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8796/44303 [52:18<3:32:13,  2.79it/s, loss=0.048]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8796/44303 [52:19<3:32:13,  2.79it/s, loss=0.0497]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8797/44303 [52:19<3:32:34,  2.78it/s, loss=0.0497]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8797/44303 [52:19<3:32:34,  2.78it/s, loss=0.0903]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8798/44303 [52:19<3:32:02,  2.79it/s, loss=0.0903]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8798/44303 [52:20<3:32:02,  2.79it/s, loss=0.0882]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8799/44303 [52:20<3:31:30,  2.80it/s, loss=0.0882]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8799/44303 [52:20<3:31:30,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8800/44303 [52:20<3:32:01,  2.79it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8800/44303 [52:20<3:32:01,  2.79it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8801/44303 [52:20<3:30:44,  2.81it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8801/44303 [52:21<3:30:44,  2.81it/s, loss=0.066] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8802/44303 [52:21<3:31:17,  2.80it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8802/44303 [52:21<3:31:17,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8803/44303 [52:21<3:30:49,  2.81it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8803/44303 [52:21<3:30:49,  2.81it/s, loss=0.04]  \u001b[A\n","Training Epoch 1:  20%|█▉        | 8804/44303 [52:21<3:30:39,  2.81it/s, loss=0.04]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8804/44303 [52:22<3:30:39,  2.81it/s, loss=0.0297]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8805/44303 [52:22<3:29:47,  2.82it/s, loss=0.0297]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8805/44303 [52:22<3:29:47,  2.82it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8806/44303 [52:22<3:30:19,  2.81it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8806/44303 [52:22<3:30:19,  2.81it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8807/44303 [52:22<3:30:15,  2.81it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8807/44303 [52:23<3:30:15,  2.81it/s, loss=0.0928]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8808/44303 [52:23<3:31:20,  2.80it/s, loss=0.0928]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8808/44303 [52:23<3:31:20,  2.80it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8809/44303 [52:23<3:31:54,  2.79it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8809/44303 [52:23<3:31:54,  2.79it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8810/44303 [52:23<3:31:03,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8810/44303 [52:24<3:31:03,  2.80it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8811/44303 [52:24<3:31:02,  2.80it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8811/44303 [52:24<3:31:02,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8812/44303 [52:24<3:31:24,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8812/44303 [52:25<3:31:24,  2.80it/s, loss=0.084] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8813/44303 [52:25<3:30:55,  2.80it/s, loss=0.084]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8813/44303 [52:25<3:30:55,  2.80it/s, loss=0.098]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8814/44303 [52:25<3:31:06,  2.80it/s, loss=0.098]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8814/44303 [52:25<3:31:06,  2.80it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8815/44303 [52:25<3:31:18,  2.80it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8815/44303 [52:26<3:31:18,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8816/44303 [52:26<3:31:13,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8816/44303 [52:26<3:31:13,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8817/44303 [52:26<3:31:51,  2.79it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8817/44303 [52:26<3:31:51,  2.79it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8818/44303 [52:26<3:30:52,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8818/44303 [52:27<3:30:52,  2.80it/s, loss=0.0968]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8819/44303 [52:27<3:30:56,  2.80it/s, loss=0.0968]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8819/44303 [52:27<3:30:56,  2.80it/s, loss=0.0295]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8820/44303 [52:27<3:30:24,  2.81it/s, loss=0.0295]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8820/44303 [52:27<3:30:24,  2.81it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8821/44303 [52:27<3:30:29,  2.81it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8821/44303 [52:28<3:30:29,  2.81it/s, loss=0.0382]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8822/44303 [52:28<3:30:36,  2.81it/s, loss=0.0382]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8822/44303 [52:28<3:30:36,  2.81it/s, loss=0.0855]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8823/44303 [52:28<3:31:00,  2.80it/s, loss=0.0855]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8823/44303 [52:28<3:31:00,  2.80it/s, loss=0.0575]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8824/44303 [52:28<3:30:15,  2.81it/s, loss=0.0575]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8824/44303 [52:29<3:30:15,  2.81it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8825/44303 [52:29<3:30:27,  2.81it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8825/44303 [52:29<3:30:27,  2.81it/s, loss=0.112] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8826/44303 [52:29<3:31:16,  2.80it/s, loss=0.112]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8826/44303 [52:30<3:31:16,  2.80it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8827/44303 [52:30<3:31:43,  2.79it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8827/44303 [52:30<3:31:43,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8828/44303 [52:30<3:31:08,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8828/44303 [52:30<3:31:08,  2.80it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8829/44303 [52:30<3:32:01,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8829/44303 [52:31<3:32:01,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8830/44303 [52:31<3:31:48,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8830/44303 [52:31<3:31:48,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8831/44303 [52:31<3:31:15,  2.80it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8831/44303 [52:31<3:31:15,  2.80it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8832/44303 [52:31<3:32:09,  2.79it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8832/44303 [52:32<3:32:09,  2.79it/s, loss=0.0622]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8833/44303 [52:32<3:31:46,  2.79it/s, loss=0.0622]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8833/44303 [52:32<3:31:46,  2.79it/s, loss=0.0693]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8834/44303 [52:32<3:31:24,  2.80it/s, loss=0.0693]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8834/44303 [52:32<3:31:24,  2.80it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8835/44303 [52:32<3:31:59,  2.79it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8835/44303 [52:33<3:31:59,  2.79it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8836/44303 [52:33<3:31:54,  2.79it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8836/44303 [52:33<3:31:54,  2.79it/s, loss=0.0901]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8837/44303 [52:33<3:31:21,  2.80it/s, loss=0.0901]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8837/44303 [52:33<3:31:21,  2.80it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8838/44303 [52:33<3:31:52,  2.79it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8838/44303 [52:34<3:31:52,  2.79it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8839/44303 [52:34<3:30:50,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8839/44303 [52:34<3:30:50,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8840/44303 [52:34<3:31:05,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8840/44303 [52:35<3:31:05,  2.80it/s, loss=0.0649]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8841/44303 [52:35<3:30:20,  2.81it/s, loss=0.0649]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8841/44303 [52:35<3:30:20,  2.81it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8842/44303 [52:35<3:30:15,  2.81it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8842/44303 [52:35<3:30:15,  2.81it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8843/44303 [52:35<3:30:13,  2.81it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8843/44303 [52:36<3:30:13,  2.81it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8844/44303 [52:36<3:30:14,  2.81it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8844/44303 [52:36<3:30:14,  2.81it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8845/44303 [52:36<3:30:28,  2.81it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8845/44303 [52:36<3:30:28,  2.81it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8846/44303 [52:36<3:29:54,  2.82it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8846/44303 [52:37<3:29:54,  2.82it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8847/44303 [52:37<3:29:56,  2.81it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8847/44303 [52:37<3:29:56,  2.81it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8848/44303 [52:37<3:30:13,  2.81it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8848/44303 [52:37<3:30:13,  2.81it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8849/44303 [52:37<3:30:46,  2.80it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8849/44303 [52:38<3:30:46,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8850/44303 [52:38<3:30:31,  2.81it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8850/44303 [52:38<3:30:31,  2.81it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8851/44303 [52:38<3:30:32,  2.81it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8851/44303 [52:38<3:30:32,  2.81it/s, loss=0.0765]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8852/44303 [52:38<3:31:01,  2.80it/s, loss=0.0765]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8852/44303 [52:39<3:31:01,  2.80it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8853/44303 [52:39<3:30:40,  2.80it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8853/44303 [52:39<3:30:40,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8854/44303 [52:39<3:31:21,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8854/44303 [52:40<3:31:21,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8855/44303 [52:40<3:31:04,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8855/44303 [52:40<3:31:04,  2.80it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8856/44303 [52:40<3:30:58,  2.80it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8856/44303 [52:40<3:30:58,  2.80it/s, loss=0.0816]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8857/44303 [52:40<3:31:20,  2.80it/s, loss=0.0816]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8857/44303 [52:41<3:31:20,  2.80it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8858/44303 [52:41<3:30:25,  2.81it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8858/44303 [52:41<3:30:25,  2.81it/s, loss=0.047] \u001b[A\n","Training Epoch 1:  20%|█▉        | 8859/44303 [52:41<3:31:18,  2.80it/s, loss=0.047]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8859/44303 [52:41<3:31:18,  2.80it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8860/44303 [52:41<3:31:30,  2.79it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  20%|█▉        | 8860/44303 [52:42<3:31:30,  2.79it/s, loss=0.0618]\u001b[A\n","Training Epoch 1:  20%|██        | 8861/44303 [52:42<3:31:20,  2.79it/s, loss=0.0618]\u001b[A\n","Training Epoch 1:  20%|██        | 8861/44303 [52:42<3:31:20,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  20%|██        | 8862/44303 [52:42<3:31:41,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  20%|██        | 8862/44303 [52:42<3:31:41,  2.79it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  20%|██        | 8863/44303 [52:42<3:31:10,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  20%|██        | 8863/44303 [52:43<3:31:10,  2.80it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  20%|██        | 8864/44303 [52:43<3:31:15,  2.80it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  20%|██        | 8864/44303 [52:43<3:31:15,  2.80it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  20%|██        | 8865/44303 [52:43<3:31:37,  2.79it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  20%|██        | 8865/44303 [52:43<3:31:37,  2.79it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  20%|██        | 8866/44303 [52:43<3:31:41,  2.79it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  20%|██        | 8866/44303 [52:44<3:31:41,  2.79it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  20%|██        | 8867/44303 [52:44<3:30:54,  2.80it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  20%|██        | 8867/44303 [52:44<3:30:54,  2.80it/s, loss=0.0259]\u001b[A\n","Training Epoch 1:  20%|██        | 8868/44303 [52:44<3:31:28,  2.79it/s, loss=0.0259]\u001b[A\n","Training Epoch 1:  20%|██        | 8868/44303 [52:45<3:31:28,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  20%|██        | 8869/44303 [52:45<3:31:24,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  20%|██        | 8869/44303 [52:45<3:31:24,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  20%|██        | 8870/44303 [52:45<3:30:52,  2.80it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  20%|██        | 8870/44303 [52:45<3:30:52,  2.80it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  20%|██        | 8871/44303 [52:45<3:31:40,  2.79it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  20%|██        | 8871/44303 [52:46<3:31:40,  2.79it/s, loss=0.0349]\u001b[A\n","Training Epoch 1:  20%|██        | 8872/44303 [52:46<3:31:21,  2.79it/s, loss=0.0349]\u001b[A\n","Training Epoch 1:  20%|██        | 8872/44303 [52:46<3:31:21,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  20%|██        | 8873/44303 [52:46<3:31:28,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  20%|██        | 8873/44303 [52:46<3:31:28,  2.79it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  20%|██        | 8874/44303 [52:46<3:31:45,  2.79it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  20%|██        | 8874/44303 [52:47<3:31:45,  2.79it/s, loss=0.0887]\u001b[A\n","Training Epoch 1:  20%|██        | 8875/44303 [52:47<3:32:04,  2.78it/s, loss=0.0887]\u001b[A\n","Training Epoch 1:  20%|██        | 8875/44303 [52:47<3:32:04,  2.78it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  20%|██        | 8876/44303 [52:47<3:31:02,  2.80it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  20%|██        | 8876/44303 [52:47<3:31:02,  2.80it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  20%|██        | 8877/44303 [52:47<3:31:03,  2.80it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  20%|██        | 8877/44303 [52:48<3:31:03,  2.80it/s, loss=0.0699]\u001b[A\n","Training Epoch 1:  20%|██        | 8878/44303 [52:48<3:31:52,  2.79it/s, loss=0.0699]\u001b[A\n","Training Epoch 1:  20%|██        | 8878/44303 [52:48<3:31:52,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  20%|██        | 8879/44303 [52:48<3:30:46,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  20%|██        | 8879/44303 [52:48<3:30:46,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|██        | 8880/44303 [52:48<3:31:48,  2.79it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|██        | 8880/44303 [52:49<3:31:48,  2.79it/s, loss=0.049] \u001b[A\n","Training Epoch 1:  20%|██        | 8881/44303 [52:49<3:31:57,  2.79it/s, loss=0.049]\u001b[A\n","Training Epoch 1:  20%|██        | 8881/44303 [52:49<3:31:57,  2.79it/s, loss=0.088]\u001b[A\n","Training Epoch 1:  20%|██        | 8882/44303 [52:49<3:31:22,  2.79it/s, loss=0.088]\u001b[A\n","Training Epoch 1:  20%|██        | 8882/44303 [52:50<3:31:22,  2.79it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  20%|██        | 8883/44303 [52:50<3:31:11,  2.80it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  20%|██        | 8883/44303 [52:50<3:31:11,  2.80it/s, loss=0.0337]\u001b[A\n","Training Epoch 1:  20%|██        | 8884/44303 [52:50<3:31:47,  2.79it/s, loss=0.0337]\u001b[A\n","Training Epoch 1:  20%|██        | 8884/44303 [52:50<3:31:47,  2.79it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  20%|██        | 8885/44303 [52:50<3:31:34,  2.79it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  20%|██        | 8885/44303 [52:51<3:31:34,  2.79it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  20%|██        | 8886/44303 [52:51<3:31:22,  2.79it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  20%|██        | 8886/44303 [52:51<3:31:22,  2.79it/s, loss=0.0765]\u001b[A\n","Training Epoch 1:  20%|██        | 8887/44303 [52:51<3:31:05,  2.80it/s, loss=0.0765]\u001b[A\n","Training Epoch 1:  20%|██        | 8887/44303 [52:51<3:31:05,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  20%|██        | 8888/44303 [52:51<3:30:40,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  20%|██        | 8888/44303 [52:52<3:30:40,  2.80it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  20%|██        | 8889/44303 [52:52<3:30:54,  2.80it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  20%|██        | 8889/44303 [52:52<3:30:54,  2.80it/s, loss=0.05]  \u001b[A\n","Training Epoch 1:  20%|██        | 8890/44303 [52:52<3:31:27,  2.79it/s, loss=0.05]\u001b[A\n","Training Epoch 1:  20%|██        | 8890/44303 [52:52<3:31:27,  2.79it/s, loss=0.0679]\u001b[A\n","Training Epoch 1:  20%|██        | 8891/44303 [52:52<3:31:08,  2.80it/s, loss=0.0679]\u001b[A\n","Training Epoch 1:  20%|██        | 8891/44303 [52:53<3:31:08,  2.80it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  20%|██        | 8892/44303 [52:53<3:31:09,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  20%|██        | 8892/44303 [52:53<3:31:09,  2.79it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  20%|██        | 8893/44303 [52:53<3:31:00,  2.80it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  20%|██        | 8893/44303 [52:53<3:31:00,  2.80it/s, loss=0.109] \u001b[A\n","Training Epoch 1:  20%|██        | 8894/44303 [52:53<3:30:16,  2.81it/s, loss=0.109]\u001b[A\n","Training Epoch 1:  20%|██        | 8894/44303 [52:54<3:30:16,  2.81it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  20%|██        | 8895/44303 [52:54<3:30:58,  2.80it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  20%|██        | 8895/44303 [52:54<3:30:58,  2.80it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  20%|██        | 8896/44303 [52:54<3:30:52,  2.80it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  20%|██        | 8896/44303 [52:55<3:30:52,  2.80it/s, loss=0.0347]\u001b[A\n","Training Epoch 1:  20%|██        | 8897/44303 [52:55<3:30:43,  2.80it/s, loss=0.0347]\u001b[A\n","Training Epoch 1:  20%|██        | 8897/44303 [52:55<3:30:43,  2.80it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  20%|██        | 8898/44303 [52:55<3:31:23,  2.79it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  20%|██        | 8898/44303 [52:55<3:31:23,  2.79it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  20%|██        | 8899/44303 [52:55<3:31:49,  2.79it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  20%|██        | 8899/44303 [52:56<3:31:49,  2.79it/s, loss=0.0485]\u001b[A\n","Training Epoch 1:  20%|██        | 8900/44303 [52:56<3:31:08,  2.79it/s, loss=0.0485]\u001b[A\n","Training Epoch 1:  20%|██        | 8900/44303 [52:56<3:31:08,  2.79it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  20%|██        | 8901/44303 [52:56<3:31:51,  2.79it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  20%|██        | 8901/44303 [52:56<3:31:51,  2.79it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  20%|██        | 8902/44303 [52:56<3:31:42,  2.79it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  20%|██        | 8902/44303 [52:57<3:31:42,  2.79it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  20%|██        | 8903/44303 [52:57<3:30:58,  2.80it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  20%|██        | 8903/44303 [52:57<3:30:58,  2.80it/s, loss=0.119] \u001b[A\n","Training Epoch 1:  20%|██        | 8904/44303 [52:57<3:31:02,  2.80it/s, loss=0.119]\u001b[A\n","Training Epoch 1:  20%|██        | 8904/44303 [52:57<3:31:02,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  20%|██        | 8905/44303 [52:57<3:31:00,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  20%|██        | 8905/44303 [52:58<3:31:00,  2.80it/s, loss=0.069] \u001b[A\n","Training Epoch 1:  20%|██        | 8906/44303 [52:58<3:30:35,  2.80it/s, loss=0.069]\u001b[A\n","Training Epoch 1:  20%|██        | 8906/44303 [52:58<3:30:35,  2.80it/s, loss=0.0754]\u001b[A\n","Training Epoch 1:  20%|██        | 8907/44303 [52:58<3:30:48,  2.80it/s, loss=0.0754]\u001b[A\n","Training Epoch 1:  20%|██        | 8907/44303 [52:59<3:30:48,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  20%|██        | 8908/44303 [52:59<3:30:44,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  20%|██        | 8908/44303 [52:59<3:30:44,  2.80it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  20%|██        | 8909/44303 [52:59<3:30:40,  2.80it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  20%|██        | 8909/44303 [52:59<3:30:40,  2.80it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  20%|██        | 8910/44303 [52:59<3:31:23,  2.79it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  20%|██        | 8910/44303 [53:00<3:31:23,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  20%|██        | 8911/44303 [53:00<3:30:07,  2.81it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  20%|██        | 8911/44303 [53:00<3:30:07,  2.81it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  20%|██        | 8912/44303 [53:00<3:30:01,  2.81it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  20%|██        | 8912/44303 [53:00<3:30:01,  2.81it/s, loss=0.0353]\u001b[A\n","Training Epoch 1:  20%|██        | 8913/44303 [53:00<3:30:27,  2.80it/s, loss=0.0353]\u001b[A\n","Training Epoch 1:  20%|██        | 8913/44303 [53:01<3:30:27,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|██        | 8914/44303 [53:01<3:30:02,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|██        | 8914/44303 [53:01<3:30:02,  2.81it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  20%|██        | 8915/44303 [53:01<3:30:46,  2.80it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  20%|██        | 8915/44303 [53:01<3:30:46,  2.80it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  20%|██        | 8916/44303 [53:01<3:29:52,  2.81it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  20%|██        | 8916/44303 [53:02<3:29:52,  2.81it/s, loss=0.0299]\u001b[A\n","Training Epoch 1:  20%|██        | 8917/44303 [53:02<3:30:47,  2.80it/s, loss=0.0299]\u001b[A\n","Training Epoch 1:  20%|██        | 8917/44303 [53:02<3:30:47,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  20%|██        | 8918/44303 [53:02<3:30:37,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  20%|██        | 8918/44303 [53:02<3:30:37,  2.80it/s, loss=0.096] \u001b[A\n","Training Epoch 1:  20%|██        | 8919/44303 [53:02<3:31:09,  2.79it/s, loss=0.096]\u001b[A\n","Training Epoch 1:  20%|██        | 8919/44303 [53:03<3:31:09,  2.79it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  20%|██        | 8920/44303 [53:03<3:31:12,  2.79it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  20%|██        | 8920/44303 [53:03<3:31:12,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  20%|██        | 8921/44303 [53:03<3:31:01,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  20%|██        | 8921/44303 [53:04<3:31:01,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  20%|██        | 8922/44303 [53:04<3:30:34,  2.80it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  20%|██        | 8922/44303 [53:04<3:30:34,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  20%|██        | 8923/44303 [53:04<3:30:21,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  20%|██        | 8923/44303 [53:04<3:30:21,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  20%|██        | 8924/44303 [53:04<3:30:39,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  20%|██        | 8924/44303 [53:05<3:30:39,  2.80it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  20%|██        | 8925/44303 [53:05<3:30:19,  2.80it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  20%|██        | 8925/44303 [53:05<3:30:19,  2.80it/s, loss=0.0884]\u001b[A\n","Training Epoch 1:  20%|██        | 8926/44303 [53:05<3:30:37,  2.80it/s, loss=0.0884]\u001b[A\n","Training Epoch 1:  20%|██        | 8926/44303 [53:05<3:30:37,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  20%|██        | 8927/44303 [53:05<3:30:43,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  20%|██        | 8927/44303 [53:06<3:30:43,  2.80it/s, loss=0.0722]\u001b[A\n","Training Epoch 1:  20%|██        | 8928/44303 [53:06<3:31:08,  2.79it/s, loss=0.0722]\u001b[A\n","Training Epoch 1:  20%|██        | 8928/44303 [53:06<3:31:08,  2.79it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  20%|██        | 8929/44303 [53:06<3:31:54,  2.78it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  20%|██        | 8929/44303 [53:06<3:31:54,  2.78it/s, loss=0.0454]\u001b[A\n","Training Epoch 1:  20%|██        | 8930/44303 [53:06<3:31:04,  2.79it/s, loss=0.0454]\u001b[A\n","Training Epoch 1:  20%|██        | 8930/44303 [53:07<3:31:04,  2.79it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  20%|██        | 8931/44303 [53:07<3:30:46,  2.80it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  20%|██        | 8931/44303 [53:07<3:30:46,  2.80it/s, loss=0.0345]\u001b[A\n","Training Epoch 1:  20%|██        | 8932/44303 [53:07<3:31:05,  2.79it/s, loss=0.0345]\u001b[A\n","Training Epoch 1:  20%|██        | 8932/44303 [53:07<3:31:05,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  20%|██        | 8933/44303 [53:07<3:31:02,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  20%|██        | 8933/44303 [53:08<3:31:02,  2.79it/s, loss=0.1]   \u001b[A\n","Training Epoch 1:  20%|██        | 8934/44303 [53:08<3:30:35,  2.80it/s, loss=0.1]\u001b[A\n","Training Epoch 1:  20%|██        | 8934/44303 [53:08<3:30:35,  2.80it/s, loss=0.0248]\u001b[A\n","Training Epoch 1:  20%|██        | 8935/44303 [53:08<3:30:46,  2.80it/s, loss=0.0248]\u001b[A\n","Training Epoch 1:  20%|██        | 8935/44303 [53:09<3:30:46,  2.80it/s, loss=0.0708]\u001b[A\n","Training Epoch 1:  20%|██        | 8936/44303 [53:09<3:30:56,  2.79it/s, loss=0.0708]\u001b[A\n","Training Epoch 1:  20%|██        | 8936/44303 [53:09<3:30:56,  2.79it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|██        | 8937/44303 [53:09<3:30:04,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  20%|██        | 8937/44303 [53:09<3:30:04,  2.81it/s, loss=0.0926]\u001b[A\n","Training Epoch 1:  20%|██        | 8938/44303 [53:09<3:30:41,  2.80it/s, loss=0.0926]\u001b[A\n","Training Epoch 1:  20%|██        | 8938/44303 [53:10<3:30:41,  2.80it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  20%|██        | 8939/44303 [53:10<3:30:00,  2.81it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  20%|██        | 8939/44303 [53:10<3:30:00,  2.81it/s, loss=0.0511]\u001b[A\n","Training Epoch 1:  20%|██        | 8940/44303 [53:10<3:30:14,  2.80it/s, loss=0.0511]\u001b[A\n","Training Epoch 1:  20%|██        | 8940/44303 [53:10<3:30:14,  2.80it/s, loss=0.126] \u001b[A\n","Training Epoch 1:  20%|██        | 8941/44303 [53:10<3:30:37,  2.80it/s, loss=0.126]\u001b[A\n","Training Epoch 1:  20%|██        | 8941/44303 [53:11<3:30:37,  2.80it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  20%|██        | 8942/44303 [53:11<3:30:05,  2.81it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  20%|██        | 8942/44303 [53:11<3:30:05,  2.81it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  20%|██        | 8943/44303 [53:11<3:30:56,  2.79it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  20%|██        | 8943/44303 [53:11<3:30:56,  2.79it/s, loss=0.0806]\u001b[A\n","Training Epoch 1:  20%|██        | 8944/44303 [53:11<3:31:03,  2.79it/s, loss=0.0806]\u001b[A\n","Training Epoch 1:  20%|██        | 8944/44303 [53:12<3:31:03,  2.79it/s, loss=0.111] \u001b[A\n","Training Epoch 1:  20%|██        | 8945/44303 [53:12<3:30:51,  2.79it/s, loss=0.111]\u001b[A\n","Training Epoch 1:  20%|██        | 8945/44303 [53:12<3:30:51,  2.79it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  20%|██        | 8946/44303 [53:12<3:30:36,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  20%|██        | 8946/44303 [53:12<3:30:36,  2.80it/s, loss=0.0637]\u001b[A\n","Training Epoch 1:  20%|██        | 8947/44303 [53:12<3:31:35,  2.78it/s, loss=0.0637]\u001b[A\n","Training Epoch 1:  20%|██        | 8947/44303 [53:13<3:31:35,  2.78it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  20%|██        | 8948/44303 [53:13<3:30:33,  2.80it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  20%|██        | 8948/44303 [53:13<3:30:33,  2.80it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  20%|██        | 8949/44303 [53:13<3:30:42,  2.80it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  20%|██        | 8949/44303 [53:14<3:30:42,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  20%|██        | 8950/44303 [53:14<3:31:14,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  20%|██        | 8950/44303 [53:14<3:31:14,  2.79it/s, loss=0.0755]\u001b[A\n","Training Epoch 1:  20%|██        | 8951/44303 [53:14<3:30:59,  2.79it/s, loss=0.0755]\u001b[A\n","Training Epoch 1:  20%|██        | 8951/44303 [53:14<3:30:59,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  20%|██        | 8952/44303 [53:14<3:29:42,  2.81it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  20%|██        | 8952/44303 [53:15<3:29:42,  2.81it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  20%|██        | 8953/44303 [53:15<3:30:09,  2.80it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  20%|██        | 8953/44303 [53:15<3:30:09,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  20%|██        | 8954/44303 [53:15<3:29:44,  2.81it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  20%|██        | 8954/44303 [53:15<3:29:44,  2.81it/s, loss=0.113] \u001b[A\n","Training Epoch 1:  20%|██        | 8955/44303 [53:15<3:30:24,  2.80it/s, loss=0.113]\u001b[A\n","Training Epoch 1:  20%|██        | 8955/44303 [53:16<3:30:24,  2.80it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  20%|██        | 8956/44303 [53:16<3:29:14,  2.82it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  20%|██        | 8956/44303 [53:16<3:29:14,  2.82it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  20%|██        | 8957/44303 [53:16<3:29:57,  2.81it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  20%|██        | 8957/44303 [53:16<3:29:57,  2.81it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  20%|██        | 8958/44303 [53:16<3:30:41,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  20%|██        | 8958/44303 [53:17<3:30:41,  2.80it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  20%|██        | 8959/44303 [53:17<3:30:13,  2.80it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  20%|██        | 8959/44303 [53:17<3:30:13,  2.80it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  20%|██        | 8960/44303 [53:17<3:30:03,  2.80it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  20%|██        | 8960/44303 [53:17<3:30:03,  2.80it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  20%|██        | 8961/44303 [53:17<3:29:42,  2.81it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  20%|██        | 8961/44303 [53:18<3:29:42,  2.81it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  20%|██        | 8962/44303 [53:18<3:30:04,  2.80it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  20%|██        | 8962/44303 [53:18<3:30:04,  2.80it/s, loss=0.053] \u001b[A\n","Training Epoch 1:  20%|██        | 8963/44303 [53:18<3:30:29,  2.80it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  20%|██        | 8963/44303 [53:19<3:30:29,  2.80it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  20%|██        | 8964/44303 [53:19<3:30:48,  2.79it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  20%|██        | 8964/44303 [53:19<3:30:48,  2.79it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  20%|██        | 8965/44303 [53:19<3:30:47,  2.79it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  20%|██        | 8965/44303 [53:19<3:30:47,  2.79it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  20%|██        | 8966/44303 [53:19<3:31:03,  2.79it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  20%|██        | 8966/44303 [53:20<3:31:03,  2.79it/s, loss=0.073] \u001b[A\n","Training Epoch 1:  20%|██        | 8967/44303 [53:20<3:30:11,  2.80it/s, loss=0.073]\u001b[A\n","Training Epoch 1:  20%|██        | 8967/44303 [53:20<3:30:11,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  20%|██        | 8968/44303 [53:20<3:30:11,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  20%|██        | 8968/44303 [53:20<3:30:11,  2.80it/s, loss=0.0292]\u001b[A\n","Training Epoch 1:  20%|██        | 8969/44303 [53:20<3:31:15,  2.79it/s, loss=0.0292]\u001b[A\n","Training Epoch 1:  20%|██        | 8969/44303 [53:21<3:31:15,  2.79it/s, loss=0.0361]\u001b[A\n","Training Epoch 1:  20%|██        | 8970/44303 [53:21<3:29:50,  2.81it/s, loss=0.0361]\u001b[A\n","Training Epoch 1:  20%|██        | 8970/44303 [53:21<3:29:50,  2.81it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  20%|██        | 8971/44303 [53:21<3:30:04,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  20%|██        | 8971/44303 [53:21<3:30:04,  2.80it/s, loss=0.0848]\u001b[A\n","Training Epoch 1:  20%|██        | 8972/44303 [53:21<3:30:06,  2.80it/s, loss=0.0848]\u001b[A\n","Training Epoch 1:  20%|██        | 8972/44303 [53:22<3:30:06,  2.80it/s, loss=0.0732]\u001b[A\n","Training Epoch 1:  20%|██        | 8973/44303 [53:22<3:30:11,  2.80it/s, loss=0.0732]\u001b[A\n","Training Epoch 1:  20%|██        | 8973/44303 [53:22<3:30:11,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  20%|██        | 8974/44303 [53:22<3:30:38,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  20%|██        | 8974/44303 [53:22<3:30:38,  2.80it/s, loss=0.07]  \u001b[A\n","Training Epoch 1:  20%|██        | 8975/44303 [53:22<3:31:09,  2.79it/s, loss=0.07]\u001b[A\n","Training Epoch 1:  20%|██        | 8975/44303 [53:23<3:31:09,  2.79it/s, loss=0.055]\u001b[A\n","Training Epoch 1:  20%|██        | 8976/44303 [53:23<3:30:34,  2.80it/s, loss=0.055]\u001b[A\n","Training Epoch 1:  20%|██        | 8976/44303 [53:23<3:30:34,  2.80it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  20%|██        | 8977/44303 [53:23<3:31:08,  2.79it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  20%|██        | 8977/44303 [53:24<3:31:08,  2.79it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  20%|██        | 8978/44303 [53:24<3:30:33,  2.80it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  20%|██        | 8978/44303 [53:24<3:30:33,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|██        | 8979/44303 [53:24<3:31:04,  2.79it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|██        | 8979/44303 [53:24<3:31:04,  2.79it/s, loss=0.0348]\u001b[A\n","Training Epoch 1:  20%|██        | 8980/44303 [53:24<3:32:17,  2.77it/s, loss=0.0348]\u001b[A\n","Training Epoch 1:  20%|██        | 8980/44303 [53:25<3:32:17,  2.77it/s, loss=0.0934]\u001b[A\n","Training Epoch 1:  20%|██        | 8981/44303 [53:25<3:31:59,  2.78it/s, loss=0.0934]\u001b[A\n","Training Epoch 1:  20%|██        | 8981/44303 [53:25<3:31:59,  2.78it/s, loss=0.0377]\u001b[A\n","Training Epoch 1:  20%|██        | 8982/44303 [53:25<3:32:22,  2.77it/s, loss=0.0377]\u001b[A\n","Training Epoch 1:  20%|██        | 8982/44303 [53:25<3:32:22,  2.77it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  20%|██        | 8983/44303 [53:25<3:31:38,  2.78it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  20%|██        | 8983/44303 [53:26<3:31:38,  2.78it/s, loss=0.06]  \u001b[A\n","Training Epoch 1:  20%|██        | 8984/44303 [53:26<3:30:53,  2.79it/s, loss=0.06]\u001b[A\n","Training Epoch 1:  20%|██        | 8984/44303 [53:26<3:30:53,  2.79it/s, loss=0.0652]\u001b[A\n","Training Epoch 1:  20%|██        | 8985/44303 [53:26<3:30:52,  2.79it/s, loss=0.0652]\u001b[A\n","Training Epoch 1:  20%|██        | 8985/44303 [53:26<3:30:52,  2.79it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  20%|██        | 8986/44303 [53:26<3:31:18,  2.79it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  20%|██        | 8986/44303 [53:27<3:31:18,  2.79it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  20%|██        | 8987/44303 [53:27<3:31:14,  2.79it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  20%|██        | 8987/44303 [53:27<3:31:14,  2.79it/s, loss=0.115] \u001b[A\n","Training Epoch 1:  20%|██        | 8988/44303 [53:27<3:31:23,  2.78it/s, loss=0.115]\u001b[A\n","Training Epoch 1:  20%|██        | 8988/44303 [53:27<3:31:23,  2.78it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  20%|██        | 8989/44303 [53:27<3:31:19,  2.79it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  20%|██        | 8989/44303 [53:28<3:31:19,  2.79it/s, loss=0.0352]\u001b[A\n","Training Epoch 1:  20%|██        | 8990/44303 [53:28<3:30:39,  2.79it/s, loss=0.0352]\u001b[A\n","Training Epoch 1:  20%|██        | 8990/44303 [53:28<3:30:39,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  20%|██        | 8991/44303 [53:28<3:31:25,  2.78it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  20%|██        | 8991/44303 [53:29<3:31:25,  2.78it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  20%|██        | 8992/44303 [53:29<3:31:23,  2.78it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  20%|██        | 8992/44303 [53:29<3:31:23,  2.78it/s, loss=0.0958]\u001b[A\n","Training Epoch 1:  20%|██        | 8993/44303 [53:29<3:31:07,  2.79it/s, loss=0.0958]\u001b[A\n","Training Epoch 1:  20%|██        | 8993/44303 [53:29<3:31:07,  2.79it/s, loss=0.0817]\u001b[A\n","Training Epoch 1:  20%|██        | 8994/44303 [53:29<3:31:29,  2.78it/s, loss=0.0817]\u001b[A\n","Training Epoch 1:  20%|██        | 8994/44303 [53:30<3:31:29,  2.78it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  20%|██        | 8995/44303 [53:30<3:30:43,  2.79it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  20%|██        | 8995/44303 [53:30<3:30:43,  2.79it/s, loss=0.0855]\u001b[A\n","Training Epoch 1:  20%|██        | 8996/44303 [53:30<3:30:09,  2.80it/s, loss=0.0855]\u001b[A\n","Training Epoch 1:  20%|██        | 8996/44303 [53:30<3:30:09,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  20%|██        | 8997/44303 [53:30<3:30:35,  2.79it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  20%|██        | 8997/44303 [53:31<3:30:35,  2.79it/s, loss=0.143] \u001b[A\n","Training Epoch 1:  20%|██        | 8998/44303 [53:31<3:29:57,  2.80it/s, loss=0.143]\u001b[A\n","Training Epoch 1:  20%|██        | 8998/44303 [53:31<3:29:57,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  20%|██        | 8999/44303 [53:31<3:29:58,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  20%|██        | 8999/44303 [53:31<3:29:58,  2.80it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  20%|██        | 9000/44303 [53:31<3:31:05,  2.79it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  20%|██        | 9000/44303 [53:32<3:31:05,  2.79it/s, loss=0.044] \u001b[A\n","Training Epoch 1:  20%|██        | 9001/44303 [53:32<3:30:19,  2.80it/s, loss=0.044]\u001b[A\n","Training Epoch 1:  20%|██        | 9001/44303 [53:32<3:30:19,  2.80it/s, loss=0.0895]\u001b[A\n","Training Epoch 1:  20%|██        | 9002/44303 [53:32<3:30:16,  2.80it/s, loss=0.0895]\u001b[A\n","Training Epoch 1:  20%|██        | 9002/44303 [53:32<3:30:16,  2.80it/s, loss=0.0907]\u001b[A\n","Training Epoch 1:  20%|██        | 9003/44303 [53:32<3:30:11,  2.80it/s, loss=0.0907]\u001b[A\n","Training Epoch 1:  20%|██        | 9003/44303 [53:33<3:30:11,  2.80it/s, loss=0.0239]\u001b[A\n","Training Epoch 1:  20%|██        | 9004/44303 [53:33<3:31:17,  2.78it/s, loss=0.0239]\u001b[A\n","Training Epoch 1:  20%|██        | 9004/44303 [53:33<3:31:17,  2.78it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|██        | 9005/44303 [53:33<3:31:07,  2.79it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  20%|██        | 9005/44303 [53:34<3:31:07,  2.79it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  20%|██        | 9006/44303 [53:34<3:31:07,  2.79it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  20%|██        | 9006/44303 [53:34<3:31:07,  2.79it/s, loss=0.0728]\u001b[A\n","Training Epoch 1:  20%|██        | 9007/44303 [53:34<3:30:44,  2.79it/s, loss=0.0728]\u001b[A\n","Training Epoch 1:  20%|██        | 9007/44303 [53:34<3:30:44,  2.79it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  20%|██        | 9008/44303 [53:34<3:31:04,  2.79it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  20%|██        | 9008/44303 [53:35<3:31:04,  2.79it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  20%|██        | 9009/44303 [53:35<3:31:07,  2.79it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  20%|██        | 9009/44303 [53:35<3:31:07,  2.79it/s, loss=0.077] \u001b[A\n","Training Epoch 1:  20%|██        | 9010/44303 [53:35<3:30:28,  2.79it/s, loss=0.077]\u001b[A\n","Training Epoch 1:  20%|██        | 9010/44303 [53:35<3:30:28,  2.79it/s, loss=0.0661]\u001b[A\n","Training Epoch 1:  20%|██        | 9011/44303 [53:35<3:30:20,  2.80it/s, loss=0.0661]\u001b[A\n","Training Epoch 1:  20%|██        | 9011/44303 [53:36<3:30:20,  2.80it/s, loss=0.0652]\u001b[A\n","Training Epoch 1:  20%|██        | 9012/44303 [53:36<3:30:27,  2.79it/s, loss=0.0652]\u001b[A\n","Training Epoch 1:  20%|██        | 9012/44303 [53:36<3:30:27,  2.79it/s, loss=0.0609]\u001b[A\n","Training Epoch 1:  20%|██        | 9013/44303 [53:36<3:30:16,  2.80it/s, loss=0.0609]\u001b[A\n","Training Epoch 1:  20%|██        | 9013/44303 [53:36<3:30:16,  2.80it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  20%|██        | 9014/44303 [53:36<3:30:41,  2.79it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  20%|██        | 9014/44303 [53:37<3:30:41,  2.79it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  20%|██        | 9015/44303 [53:37<3:30:44,  2.79it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  20%|██        | 9015/44303 [53:37<3:30:44,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  20%|██        | 9016/44303 [53:37<3:30:23,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  20%|██        | 9016/44303 [53:37<3:30:23,  2.80it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  20%|██        | 9017/44303 [53:37<3:30:33,  2.79it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  20%|██        | 9017/44303 [53:38<3:30:33,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  20%|██        | 9018/44303 [53:38<3:30:07,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  20%|██        | 9018/44303 [53:38<3:30:07,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  20%|██        | 9019/44303 [53:38<3:30:45,  2.79it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  20%|██        | 9019/44303 [53:39<3:30:45,  2.79it/s, loss=0.0419]\u001b[A\n","Training Epoch 1:  20%|██        | 9020/44303 [53:39<3:30:34,  2.79it/s, loss=0.0419]\u001b[A\n","Training Epoch 1:  20%|██        | 9020/44303 [53:39<3:30:34,  2.79it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  20%|██        | 9021/44303 [53:39<3:29:53,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  20%|██        | 9021/44303 [53:39<3:29:53,  2.80it/s, loss=0.108] \u001b[A\n","Training Epoch 1:  20%|██        | 9022/44303 [53:39<3:29:53,  2.80it/s, loss=0.108]\u001b[A\n","Training Epoch 1:  20%|██        | 9022/44303 [53:40<3:29:53,  2.80it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  20%|██        | 9023/44303 [53:40<3:30:05,  2.80it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  20%|██        | 9023/44303 [53:40<3:30:05,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  20%|██        | 9024/44303 [53:40<3:30:30,  2.79it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  20%|██        | 9024/44303 [53:40<3:30:30,  2.79it/s, loss=0.0858]\u001b[A\n","Training Epoch 1:  20%|██        | 9025/44303 [53:40<3:30:43,  2.79it/s, loss=0.0858]\u001b[A\n","Training Epoch 1:  20%|██        | 9025/44303 [53:41<3:30:43,  2.79it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  20%|██        | 9026/44303 [53:41<3:30:18,  2.80it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  20%|██        | 9026/44303 [53:41<3:30:18,  2.80it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  20%|██        | 9027/44303 [53:41<3:30:18,  2.80it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  20%|██        | 9027/44303 [53:41<3:30:18,  2.80it/s, loss=0.0963]\u001b[A\n","Training Epoch 1:  20%|██        | 9028/44303 [53:41<3:30:36,  2.79it/s, loss=0.0963]\u001b[A\n","Training Epoch 1:  20%|██        | 9028/44303 [53:42<3:30:36,  2.79it/s, loss=0.0367]\u001b[A\n","Training Epoch 1:  20%|██        | 9029/44303 [53:42<3:29:50,  2.80it/s, loss=0.0367]\u001b[A\n","Training Epoch 1:  20%|██        | 9029/44303 [53:42<3:29:50,  2.80it/s, loss=0.0954]\u001b[A\n","Training Epoch 1:  20%|██        | 9030/44303 [53:42<3:30:17,  2.80it/s, loss=0.0954]\u001b[A\n","Training Epoch 1:  20%|██        | 9030/44303 [53:43<3:30:17,  2.80it/s, loss=0.112] \u001b[A\n","Training Epoch 1:  20%|██        | 9031/44303 [53:43<3:30:21,  2.79it/s, loss=0.112]\u001b[A\n","Training Epoch 1:  20%|██        | 9031/44303 [53:43<3:30:21,  2.79it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  20%|██        | 9032/44303 [53:43<3:29:48,  2.80it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  20%|██        | 9032/44303 [53:43<3:29:48,  2.80it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  20%|██        | 9033/44303 [53:43<3:30:35,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  20%|██        | 9033/44303 [53:44<3:30:35,  2.79it/s, loss=0.0452]\u001b[A\n","Training Epoch 1:  20%|██        | 9034/44303 [53:44<3:30:41,  2.79it/s, loss=0.0452]\u001b[A\n","Training Epoch 1:  20%|██        | 9034/44303 [53:44<3:30:41,  2.79it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  20%|██        | 9035/44303 [53:44<3:30:34,  2.79it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  20%|██        | 9035/44303 [53:44<3:30:34,  2.79it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  20%|██        | 9036/44303 [53:44<3:30:51,  2.79it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  20%|██        | 9036/44303 [53:45<3:30:51,  2.79it/s, loss=0.0619]\u001b[A\n","Training Epoch 1:  20%|██        | 9037/44303 [53:45<3:30:29,  2.79it/s, loss=0.0619]\u001b[A\n","Training Epoch 1:  20%|██        | 9037/44303 [53:45<3:30:29,  2.79it/s, loss=0.032] \u001b[A\n","Training Epoch 1:  20%|██        | 9038/44303 [53:45<3:30:11,  2.80it/s, loss=0.032]\u001b[A\n","Training Epoch 1:  20%|██        | 9038/44303 [53:45<3:30:11,  2.80it/s, loss=0.0633]\u001b[A\n","Training Epoch 1:  20%|██        | 9039/44303 [53:45<3:30:30,  2.79it/s, loss=0.0633]\u001b[A\n","Training Epoch 1:  20%|██        | 9039/44303 [53:46<3:30:30,  2.79it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  20%|██        | 9040/44303 [53:46<3:30:11,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  20%|██        | 9040/44303 [53:46<3:30:11,  2.80it/s, loss=0.064] \u001b[A\n","Training Epoch 1:  20%|██        | 9041/44303 [53:46<3:29:45,  2.80it/s, loss=0.064]\u001b[A\n","Training Epoch 1:  20%|██        | 9041/44303 [53:46<3:29:45,  2.80it/s, loss=0.0242]\u001b[A\n","Training Epoch 1:  20%|██        | 9042/44303 [53:46<3:30:01,  2.80it/s, loss=0.0242]\u001b[A\n","Training Epoch 1:  20%|██        | 9042/44303 [53:47<3:30:01,  2.80it/s, loss=0.11]  \u001b[A\n","Training Epoch 1:  20%|██        | 9043/44303 [53:47<3:30:25,  2.79it/s, loss=0.11]\u001b[A\n","Training Epoch 1:  20%|██        | 9043/44303 [53:47<3:30:25,  2.79it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  20%|██        | 9044/44303 [53:47<3:30:08,  2.80it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  20%|██        | 9044/44303 [53:48<3:30:08,  2.80it/s, loss=0.052] \u001b[A\n","Training Epoch 1:  20%|██        | 9045/44303 [53:48<3:30:42,  2.79it/s, loss=0.052]\u001b[A\n","Training Epoch 1:  20%|██        | 9045/44303 [53:48<3:30:42,  2.79it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  20%|██        | 9046/44303 [53:48<3:30:21,  2.79it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  20%|██        | 9046/44303 [53:48<3:30:21,  2.79it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  20%|██        | 9047/44303 [53:48<3:30:15,  2.79it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  20%|██        | 9047/44303 [53:49<3:30:15,  2.79it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  20%|██        | 9048/44303 [53:49<3:31:02,  2.78it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  20%|██        | 9048/44303 [53:49<3:31:02,  2.78it/s, loss=0.0925]\u001b[A\n","Training Epoch 1:  20%|██        | 9049/44303 [53:49<3:30:32,  2.79it/s, loss=0.0925]\u001b[A\n","Training Epoch 1:  20%|██        | 9049/44303 [53:49<3:30:32,  2.79it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  20%|██        | 9050/44303 [53:49<3:30:03,  2.80it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  20%|██        | 9050/44303 [53:50<3:30:03,  2.80it/s, loss=0.0661]\u001b[A\n","Training Epoch 1:  20%|██        | 9051/44303 [53:50<3:30:21,  2.79it/s, loss=0.0661]\u001b[A\n","Training Epoch 1:  20%|██        | 9051/44303 [53:50<3:30:21,  2.79it/s, loss=0.0864]\u001b[A\n","Training Epoch 1:  20%|██        | 9052/44303 [53:50<3:30:04,  2.80it/s, loss=0.0864]\u001b[A\n","Training Epoch 1:  20%|██        | 9052/44303 [53:50<3:30:04,  2.80it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  20%|██        | 9053/44303 [53:50<3:29:29,  2.80it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  20%|██        | 9053/44303 [53:51<3:29:29,  2.80it/s, loss=0.0321]\u001b[A\n","Training Epoch 1:  20%|██        | 9054/44303 [53:51<3:29:27,  2.80it/s, loss=0.0321]\u001b[A\n","Training Epoch 1:  20%|██        | 9054/44303 [53:51<3:29:27,  2.80it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  20%|██        | 9055/44303 [53:51<3:29:08,  2.81it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  20%|██        | 9055/44303 [53:51<3:29:08,  2.81it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  20%|██        | 9056/44303 [53:51<3:29:35,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  20%|██        | 9056/44303 [53:52<3:29:35,  2.80it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  20%|██        | 9057/44303 [53:52<3:29:44,  2.80it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  20%|██        | 9057/44303 [53:52<3:29:44,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  20%|██        | 9058/44303 [53:52<3:29:20,  2.81it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  20%|██        | 9058/44303 [53:53<3:29:20,  2.81it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  20%|██        | 9059/44303 [53:53<3:29:48,  2.80it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  20%|██        | 9059/44303 [53:53<3:29:48,  2.80it/s, loss=0.0837]\u001b[A\n","Training Epoch 1:  20%|██        | 9060/44303 [53:53<3:30:04,  2.80it/s, loss=0.0837]\u001b[A\n","Training Epoch 1:  20%|██        | 9060/44303 [53:53<3:30:04,  2.80it/s, loss=0.0706]\u001b[A\n","Training Epoch 1:  20%|██        | 9061/44303 [53:53<3:29:46,  2.80it/s, loss=0.0706]\u001b[A\n","Training Epoch 1:  20%|██        | 9061/44303 [53:54<3:29:46,  2.80it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  20%|██        | 9062/44303 [53:54<3:30:19,  2.79it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  20%|██        | 9062/44303 [53:54<3:30:19,  2.79it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  20%|██        | 9063/44303 [53:54<3:30:43,  2.79it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  20%|██        | 9063/44303 [53:54<3:30:43,  2.79it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  20%|██        | 9064/44303 [53:54<3:29:52,  2.80it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  20%|██        | 9064/44303 [53:55<3:29:52,  2.80it/s, loss=0.0536]\u001b[A\n","Training Epoch 1:  20%|██        | 9065/44303 [53:55<3:30:16,  2.79it/s, loss=0.0536]\u001b[A\n","Training Epoch 1:  20%|██        | 9065/44303 [53:55<3:30:16,  2.79it/s, loss=0.0511]\u001b[A\n","Training Epoch 1:  20%|██        | 9066/44303 [53:55<3:30:30,  2.79it/s, loss=0.0511]\u001b[A\n","Training Epoch 1:  20%|██        | 9066/44303 [53:55<3:30:30,  2.79it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  20%|██        | 9067/44303 [53:55<3:30:05,  2.80it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  20%|██        | 9067/44303 [53:56<3:30:05,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  20%|██        | 9068/44303 [53:56<3:29:38,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  20%|██        | 9068/44303 [53:56<3:29:38,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  20%|██        | 9069/44303 [53:56<3:30:12,  2.79it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  20%|██        | 9069/44303 [53:56<3:30:12,  2.79it/s, loss=0.0314]\u001b[A\n","Training Epoch 1:  20%|██        | 9070/44303 [53:56<3:29:45,  2.80it/s, loss=0.0314]\u001b[A\n","Training Epoch 1:  20%|██        | 9070/44303 [53:57<3:29:45,  2.80it/s, loss=0.095] \u001b[A\n","Training Epoch 1:  20%|██        | 9071/44303 [53:57<3:29:46,  2.80it/s, loss=0.095]\u001b[A\n","Training Epoch 1:  20%|██        | 9071/44303 [53:57<3:29:46,  2.80it/s, loss=0.0797]\u001b[A\n","Training Epoch 1:  20%|██        | 9072/44303 [53:57<3:29:59,  2.80it/s, loss=0.0797]\u001b[A\n","Training Epoch 1:  20%|██        | 9072/44303 [53:58<3:29:59,  2.80it/s, loss=0.0312]\u001b[A\n","Training Epoch 1:  20%|██        | 9073/44303 [53:58<3:29:54,  2.80it/s, loss=0.0312]\u001b[A\n","Training Epoch 1:  20%|██        | 9073/44303 [53:58<3:29:54,  2.80it/s, loss=0.0756]\u001b[A\n","Training Epoch 1:  20%|██        | 9074/44303 [53:58<3:29:49,  2.80it/s, loss=0.0756]\u001b[A\n","Training Epoch 1:  20%|██        | 9074/44303 [53:58<3:29:49,  2.80it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  20%|██        | 9075/44303 [53:58<3:30:09,  2.79it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  20%|██        | 9075/44303 [53:59<3:30:09,  2.79it/s, loss=0.0404]\u001b[A\n","Training Epoch 1:  20%|██        | 9076/44303 [53:59<3:30:02,  2.80it/s, loss=0.0404]\u001b[A\n","Training Epoch 1:  20%|██        | 9076/44303 [53:59<3:30:02,  2.80it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  20%|██        | 9077/44303 [53:59<3:30:14,  2.79it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  20%|██        | 9077/44303 [53:59<3:30:14,  2.79it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  20%|██        | 9078/44303 [53:59<3:30:40,  2.79it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  20%|██        | 9078/44303 [54:00<3:30:40,  2.79it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  20%|██        | 9079/44303 [54:00<3:30:07,  2.79it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  20%|██        | 9079/44303 [54:00<3:30:07,  2.79it/s, loss=0.0688]\u001b[A\n","Training Epoch 1:  20%|██        | 9080/44303 [54:00<3:30:12,  2.79it/s, loss=0.0688]\u001b[A\n","Training Epoch 1:  20%|██        | 9080/44303 [54:00<3:30:12,  2.79it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  20%|██        | 9081/44303 [54:00<3:30:41,  2.79it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  20%|██        | 9081/44303 [54:01<3:30:41,  2.79it/s, loss=0.0885]\u001b[A\n","Training Epoch 1:  20%|██        | 9082/44303 [54:01<3:29:37,  2.80it/s, loss=0.0885]\u001b[A\n","Training Epoch 1:  20%|██        | 9082/44303 [54:01<3:29:37,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  21%|██        | 9083/44303 [54:01<3:30:24,  2.79it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  21%|██        | 9083/44303 [54:01<3:30:24,  2.79it/s, loss=0.043] \u001b[A\n","Training Epoch 1:  21%|██        | 9084/44303 [54:01<3:31:17,  2.78it/s, loss=0.043]\u001b[A\n","Training Epoch 1:  21%|██        | 9084/44303 [54:02<3:31:17,  2.78it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  21%|██        | 9085/44303 [54:02<3:30:30,  2.79it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  21%|██        | 9085/44303 [54:02<3:30:30,  2.79it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  21%|██        | 9086/44303 [54:02<3:30:39,  2.79it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  21%|██        | 9086/44303 [54:03<3:30:39,  2.79it/s, loss=0.127] \u001b[A\n","Training Epoch 1:  21%|██        | 9087/44303 [54:03<3:30:33,  2.79it/s, loss=0.127]\u001b[A\n","Training Epoch 1:  21%|██        | 9087/44303 [54:03<3:30:33,  2.79it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  21%|██        | 9088/44303 [54:03<3:30:09,  2.79it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  21%|██        | 9088/44303 [54:03<3:30:09,  2.79it/s, loss=0.045] \u001b[A\n","Training Epoch 1:  21%|██        | 9089/44303 [54:03<3:30:07,  2.79it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  21%|██        | 9089/44303 [54:04<3:30:07,  2.79it/s, loss=0.0614]\u001b[A\n","Training Epoch 1:  21%|██        | 9090/44303 [54:04<3:30:14,  2.79it/s, loss=0.0614]\u001b[A\n","Training Epoch 1:  21%|██        | 9090/44303 [54:04<3:30:14,  2.79it/s, loss=0.0656]\u001b[A\n","Training Epoch 1:  21%|██        | 9091/44303 [54:04<3:30:05,  2.79it/s, loss=0.0656]\u001b[A\n","Training Epoch 1:  21%|██        | 9091/44303 [54:04<3:30:05,  2.79it/s, loss=0.0796]\u001b[A\n","Training Epoch 1:  21%|██        | 9092/44303 [54:04<3:29:44,  2.80it/s, loss=0.0796]\u001b[A\n","Training Epoch 1:  21%|██        | 9092/44303 [54:05<3:29:44,  2.80it/s, loss=0.0929]\u001b[A\n","Training Epoch 1:  21%|██        | 9093/44303 [54:05<3:29:59,  2.79it/s, loss=0.0929]\u001b[A\n","Training Epoch 1:  21%|██        | 9093/44303 [54:05<3:29:59,  2.79it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  21%|██        | 9094/44303 [54:05<3:30:09,  2.79it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  21%|██        | 9094/44303 [54:05<3:30:09,  2.79it/s, loss=0.0985]\u001b[A\n","Training Epoch 1:  21%|██        | 9095/44303 [54:05<3:30:13,  2.79it/s, loss=0.0985]\u001b[A\n","Training Epoch 1:  21%|██        | 9095/44303 [54:06<3:30:13,  2.79it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  21%|██        | 9096/44303 [54:06<3:29:41,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  21%|██        | 9096/44303 [54:06<3:29:41,  2.80it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  21%|██        | 9097/44303 [54:06<3:30:37,  2.79it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  21%|██        | 9097/44303 [54:06<3:30:37,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  21%|██        | 9098/44303 [54:06<3:29:49,  2.80it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  21%|██        | 9098/44303 [54:07<3:29:49,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  21%|██        | 9099/44303 [54:07<3:30:25,  2.79it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  21%|██        | 9099/44303 [54:07<3:30:25,  2.79it/s, loss=0.0635]\u001b[A\n","Training Epoch 1:  21%|██        | 9100/44303 [54:07<3:30:53,  2.78it/s, loss=0.0635]\u001b[A\n","Training Epoch 1:  21%|██        | 9100/44303 [54:08<3:30:53,  2.78it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  21%|██        | 9101/44303 [54:08<3:30:27,  2.79it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  21%|██        | 9101/44303 [54:08<3:30:27,  2.79it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  21%|██        | 9102/44303 [54:08<3:29:56,  2.79it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  21%|██        | 9102/44303 [54:08<3:29:56,  2.79it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  21%|██        | 9103/44303 [54:08<3:30:12,  2.79it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  21%|██        | 9103/44303 [54:09<3:30:12,  2.79it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  21%|██        | 9104/44303 [54:09<3:30:21,  2.79it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  21%|██        | 9104/44303 [54:09<3:30:21,  2.79it/s, loss=0.0713]\u001b[A\n","Training Epoch 1:  21%|██        | 9105/44303 [54:09<3:29:35,  2.80it/s, loss=0.0713]\u001b[A\n","Training Epoch 1:  21%|██        | 9105/44303 [54:09<3:29:35,  2.80it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  21%|██        | 9106/44303 [54:09<3:30:06,  2.79it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  21%|██        | 9106/44303 [54:10<3:30:06,  2.79it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  21%|██        | 9107/44303 [54:10<3:29:51,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  21%|██        | 9107/44303 [54:10<3:29:51,  2.80it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  21%|██        | 9108/44303 [54:10<3:29:47,  2.80it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  21%|██        | 9108/44303 [54:10<3:29:47,  2.80it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  21%|██        | 9109/44303 [54:10<3:30:01,  2.79it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  21%|██        | 9109/44303 [54:11<3:30:01,  2.79it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  21%|██        | 9110/44303 [54:11<3:29:59,  2.79it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  21%|██        | 9110/44303 [54:11<3:29:59,  2.79it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  21%|██        | 9111/44303 [54:11<3:29:29,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  21%|██        | 9111/44303 [54:11<3:29:29,  2.80it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  21%|██        | 9112/44303 [54:11<3:29:22,  2.80it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  21%|██        | 9112/44303 [54:12<3:29:22,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  21%|██        | 9113/44303 [54:12<3:29:11,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  21%|██        | 9113/44303 [54:12<3:29:11,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  21%|██        | 9114/44303 [54:12<3:29:28,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  21%|██        | 9114/44303 [54:13<3:29:28,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  21%|██        | 9115/44303 [54:13<3:29:35,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  21%|██        | 9115/44303 [54:13<3:29:35,  2.80it/s, loss=0.0865]\u001b[A\n","Training Epoch 1:  21%|██        | 9116/44303 [54:13<3:29:22,  2.80it/s, loss=0.0865]\u001b[A\n","Training Epoch 1:  21%|██        | 9116/44303 [54:13<3:29:22,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  21%|██        | 9117/44303 [54:13<3:31:02,  2.78it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  21%|██        | 9117/44303 [54:14<3:31:02,  2.78it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  21%|██        | 9118/44303 [54:14<3:30:39,  2.78it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  21%|██        | 9118/44303 [54:14<3:30:39,  2.78it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  21%|██        | 9119/44303 [54:14<3:30:34,  2.78it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  21%|██        | 9119/44303 [54:14<3:30:34,  2.78it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  21%|██        | 9120/44303 [54:14<3:29:22,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  21%|██        | 9120/44303 [54:15<3:29:22,  2.80it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  21%|██        | 9121/44303 [54:15<3:29:27,  2.80it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  21%|██        | 9121/44303 [54:15<3:29:27,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  21%|██        | 9122/44303 [54:15<3:29:05,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  21%|██        | 9122/44303 [54:15<3:29:05,  2.80it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  21%|██        | 9123/44303 [54:15<3:29:09,  2.80it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  21%|██        | 9123/44303 [54:16<3:29:09,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  21%|██        | 9124/44303 [54:16<3:29:11,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  21%|██        | 9124/44303 [54:16<3:29:11,  2.80it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  21%|██        | 9125/44303 [54:16<3:29:20,  2.80it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  21%|██        | 9125/44303 [54:16<3:29:20,  2.80it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  21%|██        | 9126/44303 [54:16<3:29:35,  2.80it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  21%|██        | 9126/44303 [54:17<3:29:35,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  21%|██        | 9127/44303 [54:17<3:29:38,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  21%|██        | 9127/44303 [54:17<3:29:38,  2.80it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  21%|██        | 9128/44303 [54:17<3:29:04,  2.80it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  21%|██        | 9128/44303 [54:18<3:29:04,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██        | 9129/44303 [54:18<3:30:26,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██        | 9129/44303 [54:18<3:30:26,  2.79it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  21%|██        | 9130/44303 [54:18<3:29:57,  2.79it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  21%|██        | 9130/44303 [54:18<3:29:57,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  21%|██        | 9131/44303 [54:18<3:29:55,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  21%|██        | 9131/44303 [54:19<3:29:55,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  21%|██        | 9132/44303 [54:19<3:30:18,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  21%|██        | 9132/44303 [54:19<3:30:18,  2.79it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  21%|██        | 9133/44303 [54:19<3:30:20,  2.79it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  21%|██        | 9133/44303 [54:19<3:30:20,  2.79it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  21%|██        | 9134/44303 [54:19<3:29:47,  2.79it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  21%|██        | 9134/44303 [54:20<3:29:47,  2.79it/s, loss=0.0968]\u001b[A\n","Training Epoch 1:  21%|██        | 9135/44303 [54:20<3:29:57,  2.79it/s, loss=0.0968]\u001b[A\n","Training Epoch 1:  21%|██        | 9135/44303 [54:20<3:29:57,  2.79it/s, loss=0.0797]\u001b[A\n","Training Epoch 1:  21%|██        | 9136/44303 [54:20<3:30:09,  2.79it/s, loss=0.0797]\u001b[A\n","Training Epoch 1:  21%|██        | 9136/44303 [54:20<3:30:09,  2.79it/s, loss=0.092] \u001b[A\n","Training Epoch 1:  21%|██        | 9137/44303 [54:20<3:29:11,  2.80it/s, loss=0.092]\u001b[A\n","Training Epoch 1:  21%|██        | 9137/44303 [54:21<3:29:11,  2.80it/s, loss=0.0296]\u001b[A\n","Training Epoch 1:  21%|██        | 9138/44303 [54:21<3:29:32,  2.80it/s, loss=0.0296]\u001b[A\n","Training Epoch 1:  21%|██        | 9138/44303 [54:21<3:29:32,  2.80it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  21%|██        | 9139/44303 [54:21<3:29:03,  2.80it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  21%|██        | 9139/44303 [54:22<3:29:03,  2.80it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  21%|██        | 9140/44303 [54:22<3:28:51,  2.81it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  21%|██        | 9140/44303 [54:22<3:28:51,  2.81it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  21%|██        | 9141/44303 [54:22<3:29:34,  2.80it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  21%|██        | 9141/44303 [54:22<3:29:34,  2.80it/s, loss=0.033] \u001b[A\n","Training Epoch 1:  21%|██        | 9142/44303 [54:22<3:29:43,  2.79it/s, loss=0.033]\u001b[A\n","Training Epoch 1:  21%|██        | 9142/44303 [54:23<3:29:43,  2.79it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  21%|██        | 9143/44303 [54:23<3:29:43,  2.79it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  21%|██        | 9143/44303 [54:23<3:29:43,  2.79it/s, loss=0.0804]\u001b[A\n","Training Epoch 1:  21%|██        | 9144/44303 [54:23<3:29:23,  2.80it/s, loss=0.0804]\u001b[A\n","Training Epoch 1:  21%|██        | 9144/44303 [54:23<3:29:23,  2.80it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  21%|██        | 9145/44303 [54:23<3:29:03,  2.80it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  21%|██        | 9145/44303 [54:24<3:29:03,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██        | 9146/44303 [54:24<3:29:12,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██        | 9146/44303 [54:24<3:29:12,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  21%|██        | 9147/44303 [54:24<3:29:44,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  21%|██        | 9147/44303 [54:24<3:29:44,  2.79it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  21%|██        | 9148/44303 [54:24<3:29:34,  2.80it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  21%|██        | 9148/44303 [54:25<3:29:34,  2.80it/s, loss=0.131]\u001b[A\n","Training Epoch 1:  21%|██        | 9149/44303 [54:25<3:29:38,  2.79it/s, loss=0.131]\u001b[A\n","Training Epoch 1:  21%|██        | 9149/44303 [54:25<3:29:38,  2.79it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  21%|██        | 9150/44303 [54:25<3:29:45,  2.79it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  21%|██        | 9150/44303 [54:25<3:29:45,  2.79it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  21%|██        | 9151/44303 [54:25<3:28:47,  2.81it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  21%|██        | 9151/44303 [54:26<3:28:47,  2.81it/s, loss=0.109]\u001b[A\n","Training Epoch 1:  21%|██        | 9152/44303 [54:26<3:28:58,  2.80it/s, loss=0.109]\u001b[A\n","Training Epoch 1:  21%|██        | 9152/44303 [54:26<3:28:58,  2.80it/s, loss=0.166]\u001b[A\n","Training Epoch 1:  21%|██        | 9153/44303 [54:26<3:28:39,  2.81it/s, loss=0.166]\u001b[A\n","Training Epoch 1:  21%|██        | 9153/44303 [54:27<3:28:39,  2.81it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  21%|██        | 9154/44303 [54:27<3:28:44,  2.81it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  21%|██        | 9154/44303 [54:27<3:28:44,  2.81it/s, loss=0.0684]\u001b[A\n","Training Epoch 1:  21%|██        | 9155/44303 [54:27<3:29:05,  2.80it/s, loss=0.0684]\u001b[A\n","Training Epoch 1:  21%|██        | 9155/44303 [54:27<3:29:05,  2.80it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  21%|██        | 9156/44303 [54:27<3:28:39,  2.81it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  21%|██        | 9156/44303 [54:28<3:28:39,  2.81it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  21%|██        | 9157/44303 [54:28<3:28:38,  2.81it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  21%|██        | 9157/44303 [54:28<3:28:38,  2.81it/s, loss=0.0818]\u001b[A\n","Training Epoch 1:  21%|██        | 9158/44303 [54:28<3:28:36,  2.81it/s, loss=0.0818]\u001b[A\n","Training Epoch 1:  21%|██        | 9158/44303 [54:28<3:28:36,  2.81it/s, loss=0.0706]\u001b[A\n","Training Epoch 1:  21%|██        | 9159/44303 [54:28<3:28:51,  2.80it/s, loss=0.0706]\u001b[A\n","Training Epoch 1:  21%|██        | 9159/44303 [54:29<3:28:51,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  21%|██        | 9160/44303 [54:29<3:29:25,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  21%|██        | 9160/44303 [54:29<3:29:25,  2.80it/s, loss=0.075] \u001b[A\n","Training Epoch 1:  21%|██        | 9161/44303 [54:29<3:28:37,  2.81it/s, loss=0.075]\u001b[A\n","Training Epoch 1:  21%|██        | 9161/44303 [54:29<3:28:37,  2.81it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  21%|██        | 9162/44303 [54:29<3:29:21,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  21%|██        | 9162/44303 [54:30<3:29:21,  2.80it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  21%|██        | 9163/44303 [54:30<3:29:35,  2.79it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  21%|██        | 9163/44303 [54:30<3:29:35,  2.79it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  21%|██        | 9164/44303 [54:30<3:29:18,  2.80it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  21%|██        | 9164/44303 [54:30<3:29:18,  2.80it/s, loss=0.0569]\u001b[A\n","Training Epoch 1:  21%|██        | 9165/44303 [54:30<3:29:43,  2.79it/s, loss=0.0569]\u001b[A\n","Training Epoch 1:  21%|██        | 9165/44303 [54:31<3:29:43,  2.79it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  21%|██        | 9166/44303 [54:31<3:29:23,  2.80it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  21%|██        | 9166/44303 [54:31<3:29:23,  2.80it/s, loss=0.079] \u001b[A\n","Training Epoch 1:  21%|██        | 9167/44303 [54:31<3:28:39,  2.81it/s, loss=0.079]\u001b[A\n","Training Epoch 1:  21%|██        | 9167/44303 [54:32<3:28:39,  2.81it/s, loss=0.0199]\u001b[A\n","Training Epoch 1:  21%|██        | 9168/44303 [54:32<3:29:38,  2.79it/s, loss=0.0199]\u001b[A\n","Training Epoch 1:  21%|██        | 9168/44303 [54:32<3:29:38,  2.79it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  21%|██        | 9169/44303 [54:32<3:28:31,  2.81it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  21%|██        | 9169/44303 [54:32<3:28:31,  2.81it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  21%|██        | 9170/44303 [54:32<3:28:09,  2.81it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  21%|██        | 9170/44303 [54:33<3:28:09,  2.81it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  21%|██        | 9171/44303 [54:33<3:28:39,  2.81it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  21%|██        | 9171/44303 [54:33<3:28:39,  2.81it/s, loss=0.0635]\u001b[A\n","Training Epoch 1:  21%|██        | 9172/44303 [54:33<3:29:01,  2.80it/s, loss=0.0635]\u001b[A\n","Training Epoch 1:  21%|██        | 9172/44303 [54:33<3:29:01,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  21%|██        | 9173/44303 [54:33<3:29:00,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  21%|██        | 9173/44303 [54:34<3:29:00,  2.80it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  21%|██        | 9174/44303 [54:34<3:28:32,  2.81it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  21%|██        | 9174/44303 [54:34<3:28:32,  2.81it/s, loss=0.0337]\u001b[A\n","Training Epoch 1:  21%|██        | 9175/44303 [54:34<3:28:42,  2.81it/s, loss=0.0337]\u001b[A\n","Training Epoch 1:  21%|██        | 9175/44303 [54:34<3:28:42,  2.81it/s, loss=0.044] \u001b[A\n","Training Epoch 1:  21%|██        | 9176/44303 [54:34<3:28:50,  2.80it/s, loss=0.044]\u001b[A\n","Training Epoch 1:  21%|██        | 9176/44303 [54:35<3:28:50,  2.80it/s, loss=0.0919]\u001b[A\n","Training Epoch 1:  21%|██        | 9177/44303 [54:35<3:28:29,  2.81it/s, loss=0.0919]\u001b[A\n","Training Epoch 1:  21%|██        | 9177/44303 [54:35<3:28:29,  2.81it/s, loss=0.0317]\u001b[A\n","Training Epoch 1:  21%|██        | 9178/44303 [54:35<3:28:43,  2.80it/s, loss=0.0317]\u001b[A\n","Training Epoch 1:  21%|██        | 9178/44303 [54:35<3:28:43,  2.80it/s, loss=0.0275]\u001b[A\n","Training Epoch 1:  21%|██        | 9179/44303 [54:35<3:28:22,  2.81it/s, loss=0.0275]\u001b[A\n","Training Epoch 1:  21%|██        | 9179/44303 [54:36<3:28:22,  2.81it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  21%|██        | 9180/44303 [54:36<3:28:39,  2.81it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  21%|██        | 9180/44303 [54:36<3:28:39,  2.81it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  21%|██        | 9181/44303 [54:36<3:28:22,  2.81it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  21%|██        | 9181/44303 [54:36<3:28:22,  2.81it/s, loss=0.0731]\u001b[A\n","Training Epoch 1:  21%|██        | 9182/44303 [54:36<3:28:29,  2.81it/s, loss=0.0731]\u001b[A\n","Training Epoch 1:  21%|██        | 9182/44303 [54:37<3:28:29,  2.81it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9183/44303 [54:37<3:29:28,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9183/44303 [54:37<3:29:28,  2.79it/s, loss=0.0714]\u001b[A\n","Training Epoch 1:  21%|██        | 9184/44303 [54:37<3:28:52,  2.80it/s, loss=0.0714]\u001b[A\n","Training Epoch 1:  21%|██        | 9184/44303 [54:38<3:28:52,  2.80it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  21%|██        | 9185/44303 [54:38<3:29:08,  2.80it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  21%|██        | 9185/44303 [54:38<3:29:08,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  21%|██        | 9186/44303 [54:38<3:28:12,  2.81it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  21%|██        | 9186/44303 [54:38<3:28:12,  2.81it/s, loss=0.0865]\u001b[A\n","Training Epoch 1:  21%|██        | 9187/44303 [54:38<3:29:01,  2.80it/s, loss=0.0865]\u001b[A\n","Training Epoch 1:  21%|██        | 9187/44303 [54:39<3:29:01,  2.80it/s, loss=0.05]  \u001b[A\n","Training Epoch 1:  21%|██        | 9188/44303 [54:39<3:29:47,  2.79it/s, loss=0.05]\u001b[A\n","Training Epoch 1:  21%|██        | 9188/44303 [54:39<3:29:47,  2.79it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  21%|██        | 9189/44303 [54:39<3:29:45,  2.79it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  21%|██        | 9189/44303 [54:39<3:29:45,  2.79it/s, loss=0.08]  \u001b[A\n","Training Epoch 1:  21%|██        | 9190/44303 [54:39<3:29:33,  2.79it/s, loss=0.08]\u001b[A\n","Training Epoch 1:  21%|██        | 9190/44303 [54:40<3:29:33,  2.79it/s, loss=0.074]\u001b[A\n","Training Epoch 1:  21%|██        | 9191/44303 [54:40<3:29:42,  2.79it/s, loss=0.074]\u001b[A\n","Training Epoch 1:  21%|██        | 9191/44303 [54:40<3:29:42,  2.79it/s, loss=0.0827]\u001b[A\n","Training Epoch 1:  21%|██        | 9192/44303 [54:40<3:29:26,  2.79it/s, loss=0.0827]\u001b[A\n","Training Epoch 1:  21%|██        | 9192/44303 [54:40<3:29:26,  2.79it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  21%|██        | 9193/44303 [54:40<3:29:09,  2.80it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  21%|██        | 9193/44303 [54:41<3:29:09,  2.80it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  21%|██        | 9194/44303 [54:41<3:30:00,  2.79it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  21%|██        | 9194/44303 [54:41<3:30:00,  2.79it/s, loss=0.057] \u001b[A\n","Training Epoch 1:  21%|██        | 9195/44303 [54:41<3:28:34,  2.81it/s, loss=0.057]\u001b[A\n","Training Epoch 1:  21%|██        | 9195/44303 [54:42<3:28:34,  2.81it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  21%|██        | 9196/44303 [54:42<3:29:02,  2.80it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  21%|██        | 9196/44303 [54:42<3:29:02,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9197/44303 [54:42<3:29:48,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9197/44303 [54:42<3:29:48,  2.79it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██        | 9198/44303 [54:42<3:29:22,  2.79it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██        | 9198/44303 [54:43<3:29:22,  2.79it/s, loss=0.0326]\u001b[A\n","Training Epoch 1:  21%|██        | 9199/44303 [54:43<3:29:13,  2.80it/s, loss=0.0326]\u001b[A\n","Training Epoch 1:  21%|██        | 9199/44303 [54:43<3:29:13,  2.80it/s, loss=0.0427]\u001b[A\n","Training Epoch 1:  21%|██        | 9200/44303 [54:43<3:29:38,  2.79it/s, loss=0.0427]\u001b[A\n","Training Epoch 1:  21%|██        | 9200/44303 [54:43<3:29:38,  2.79it/s, loss=0.0313]\u001b[A\n","Training Epoch 1:  21%|██        | 9201/44303 [54:43<3:28:59,  2.80it/s, loss=0.0313]\u001b[A\n","Training Epoch 1:  21%|██        | 9201/44303 [54:44<3:28:59,  2.80it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  21%|██        | 9202/44303 [54:44<3:29:20,  2.79it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  21%|██        | 9202/44303 [54:44<3:29:20,  2.79it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  21%|██        | 9203/44303 [54:44<3:28:41,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  21%|██        | 9203/44303 [54:44<3:28:41,  2.80it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  21%|██        | 9204/44303 [54:44<3:29:20,  2.79it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  21%|██        | 9204/44303 [54:45<3:29:20,  2.79it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  21%|██        | 9205/44303 [54:45<3:30:05,  2.78it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  21%|██        | 9205/44303 [54:45<3:30:05,  2.78it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  21%|██        | 9206/44303 [54:45<3:28:54,  2.80it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  21%|██        | 9206/44303 [54:45<3:28:54,  2.80it/s, loss=0.0806]\u001b[A\n","Training Epoch 1:  21%|██        | 9207/44303 [54:45<3:29:31,  2.79it/s, loss=0.0806]\u001b[A\n","Training Epoch 1:  21%|██        | 9207/44303 [54:46<3:29:31,  2.79it/s, loss=0.053] \u001b[A\n","Training Epoch 1:  21%|██        | 9208/44303 [54:46<3:29:51,  2.79it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  21%|██        | 9208/44303 [54:46<3:29:51,  2.79it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  21%|██        | 9209/44303 [54:46<3:28:44,  2.80it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  21%|██        | 9209/44303 [54:47<3:28:44,  2.80it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  21%|██        | 9210/44303 [54:47<3:29:41,  2.79it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  21%|██        | 9210/44303 [54:47<3:29:41,  2.79it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  21%|██        | 9211/44303 [54:47<3:29:53,  2.79it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  21%|██        | 9211/44303 [54:47<3:29:53,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  21%|██        | 9212/44303 [54:47<3:30:02,  2.78it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  21%|██        | 9212/44303 [54:48<3:30:02,  2.78it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  21%|██        | 9213/44303 [54:48<3:29:36,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  21%|██        | 9213/44303 [54:48<3:29:36,  2.79it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  21%|██        | 9214/44303 [54:48<3:29:45,  2.79it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  21%|██        | 9214/44303 [54:48<3:29:45,  2.79it/s, loss=0.0251]\u001b[A\n","Training Epoch 1:  21%|██        | 9215/44303 [54:48<3:29:22,  2.79it/s, loss=0.0251]\u001b[A\n","Training Epoch 1:  21%|██        | 9215/44303 [54:49<3:29:22,  2.79it/s, loss=0.0705]\u001b[A\n","Training Epoch 1:  21%|██        | 9216/44303 [54:49<3:28:55,  2.80it/s, loss=0.0705]\u001b[A\n","Training Epoch 1:  21%|██        | 9216/44303 [54:49<3:28:55,  2.80it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  21%|██        | 9217/44303 [54:49<3:29:06,  2.80it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  21%|██        | 9217/44303 [54:49<3:29:06,  2.80it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  21%|██        | 9218/44303 [54:49<3:28:24,  2.81it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  21%|██        | 9218/44303 [54:50<3:28:24,  2.81it/s, loss=0.0568]\u001b[A\n","Training Epoch 1:  21%|██        | 9219/44303 [54:50<3:29:02,  2.80it/s, loss=0.0568]\u001b[A\n","Training Epoch 1:  21%|██        | 9219/44303 [54:50<3:29:02,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  21%|██        | 9220/44303 [54:50<3:28:16,  2.81it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  21%|██        | 9220/44303 [54:50<3:28:16,  2.81it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  21%|██        | 9221/44303 [54:50<3:28:33,  2.80it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  21%|██        | 9221/44303 [54:51<3:28:33,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  21%|██        | 9222/44303 [54:51<3:28:12,  2.81it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  21%|██        | 9222/44303 [54:51<3:28:12,  2.81it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  21%|██        | 9223/44303 [54:51<3:28:43,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  21%|██        | 9223/44303 [54:52<3:28:43,  2.80it/s, loss=0.0267]\u001b[A\n","Training Epoch 1:  21%|██        | 9224/44303 [54:52<3:28:36,  2.80it/s, loss=0.0267]\u001b[A\n","Training Epoch 1:  21%|██        | 9224/44303 [54:52<3:28:36,  2.80it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  21%|██        | 9225/44303 [54:52<3:28:20,  2.81it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  21%|██        | 9225/44303 [54:52<3:28:20,  2.81it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  21%|██        | 9226/44303 [54:52<3:28:59,  2.80it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  21%|██        | 9226/44303 [54:53<3:28:59,  2.80it/s, loss=0.0761]\u001b[A\n","Training Epoch 1:  21%|██        | 9227/44303 [54:53<3:29:04,  2.80it/s, loss=0.0761]\u001b[A\n","Training Epoch 1:  21%|██        | 9227/44303 [54:53<3:29:04,  2.80it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  21%|██        | 9228/44303 [54:53<3:28:57,  2.80it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  21%|██        | 9228/44303 [54:53<3:28:57,  2.80it/s, loss=0.076] \u001b[A\n","Training Epoch 1:  21%|██        | 9229/44303 [54:53<3:29:15,  2.79it/s, loss=0.076]\u001b[A\n","Training Epoch 1:  21%|██        | 9229/44303 [54:54<3:29:15,  2.79it/s, loss=0.0773]\u001b[A\n","Training Epoch 1:  21%|██        | 9230/44303 [54:54<3:28:56,  2.80it/s, loss=0.0773]\u001b[A\n","Training Epoch 1:  21%|██        | 9230/44303 [54:54<3:28:56,  2.80it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  21%|██        | 9231/44303 [54:54<3:28:30,  2.80it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  21%|██        | 9231/44303 [54:54<3:28:30,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  21%|██        | 9232/44303 [54:54<3:29:23,  2.79it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  21%|██        | 9232/44303 [54:55<3:29:23,  2.79it/s, loss=0.037] \u001b[A\n","Training Epoch 1:  21%|██        | 9233/44303 [54:55<3:29:31,  2.79it/s, loss=0.037]\u001b[A\n","Training Epoch 1:  21%|██        | 9233/44303 [54:55<3:29:31,  2.79it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  21%|██        | 9234/44303 [54:55<3:28:38,  2.80it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  21%|██        | 9234/44303 [54:55<3:28:38,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  21%|██        | 9235/44303 [54:55<3:29:15,  2.79it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  21%|██        | 9235/44303 [54:56<3:29:15,  2.79it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  21%|██        | 9236/44303 [54:56<3:29:42,  2.79it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  21%|██        | 9236/44303 [54:56<3:29:42,  2.79it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  21%|██        | 9237/44303 [54:56<3:29:28,  2.79it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  21%|██        | 9237/44303 [54:57<3:29:28,  2.79it/s, loss=0.0811]\u001b[A\n","Training Epoch 1:  21%|██        | 9238/44303 [54:57<3:28:40,  2.80it/s, loss=0.0811]\u001b[A\n","Training Epoch 1:  21%|██        | 9238/44303 [54:57<3:28:40,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  21%|██        | 9239/44303 [54:57<3:29:42,  2.79it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  21%|██        | 9239/44303 [54:57<3:29:42,  2.79it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  21%|██        | 9240/44303 [54:57<3:29:35,  2.79it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  21%|██        | 9240/44303 [54:58<3:29:35,  2.79it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  21%|██        | 9241/44303 [54:58<3:29:49,  2.79it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  21%|██        | 9241/44303 [54:58<3:29:49,  2.79it/s, loss=0.0746]\u001b[A\n","Training Epoch 1:  21%|██        | 9242/44303 [54:58<3:29:54,  2.78it/s, loss=0.0746]\u001b[A\n","Training Epoch 1:  21%|██        | 9242/44303 [54:58<3:29:54,  2.78it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  21%|██        | 9243/44303 [54:58<3:29:31,  2.79it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  21%|██        | 9243/44303 [54:59<3:29:31,  2.79it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  21%|██        | 9244/44303 [54:59<3:28:48,  2.80it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  21%|██        | 9244/44303 [54:59<3:28:48,  2.80it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  21%|██        | 9245/44303 [54:59<3:29:34,  2.79it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  21%|██        | 9245/44303 [54:59<3:29:34,  2.79it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  21%|██        | 9246/44303 [54:59<3:29:21,  2.79it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  21%|██        | 9246/44303 [55:00<3:29:21,  2.79it/s, loss=0.076] \u001b[A\n","Training Epoch 1:  21%|██        | 9247/44303 [55:00<3:29:17,  2.79it/s, loss=0.076]\u001b[A\n","Training Epoch 1:  21%|██        | 9247/44303 [55:00<3:29:17,  2.79it/s, loss=0.0897]\u001b[A\n","Training Epoch 1:  21%|██        | 9248/44303 [55:00<3:29:13,  2.79it/s, loss=0.0897]\u001b[A\n","Training Epoch 1:  21%|██        | 9248/44303 [55:00<3:29:13,  2.79it/s, loss=0.0922]\u001b[A\n","Training Epoch 1:  21%|██        | 9249/44303 [55:00<3:29:37,  2.79it/s, loss=0.0922]\u001b[A\n","Training Epoch 1:  21%|██        | 9249/44303 [55:01<3:29:37,  2.79it/s, loss=0.0465]\u001b[A\n","Training Epoch 1:  21%|██        | 9250/44303 [55:01<3:28:59,  2.80it/s, loss=0.0465]\u001b[A\n","Training Epoch 1:  21%|██        | 9250/44303 [55:01<3:28:59,  2.80it/s, loss=0.061] \u001b[A\n","Training Epoch 1:  21%|██        | 9251/44303 [55:01<3:28:54,  2.80it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  21%|██        | 9251/44303 [55:02<3:28:54,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  21%|██        | 9252/44303 [55:02<3:29:07,  2.79it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  21%|██        | 9252/44303 [55:02<3:29:07,  2.79it/s, loss=0.044] \u001b[A\n","Training Epoch 1:  21%|██        | 9253/44303 [55:02<3:28:36,  2.80it/s, loss=0.044]\u001b[A\n","Training Epoch 1:  21%|██        | 9253/44303 [55:02<3:28:36,  2.80it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  21%|██        | 9254/44303 [55:02<3:28:54,  2.80it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  21%|██        | 9254/44303 [55:03<3:28:54,  2.80it/s, loss=0.083] \u001b[A\n","Training Epoch 1:  21%|██        | 9255/44303 [55:03<3:29:26,  2.79it/s, loss=0.083]\u001b[A\n","Training Epoch 1:  21%|██        | 9255/44303 [55:03<3:29:26,  2.79it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  21%|██        | 9256/44303 [55:03<3:28:50,  2.80it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  21%|██        | 9256/44303 [55:03<3:28:50,  2.80it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  21%|██        | 9257/44303 [55:03<3:28:36,  2.80it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  21%|██        | 9257/44303 [55:04<3:28:36,  2.80it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  21%|██        | 9258/44303 [55:04<3:28:02,  2.81it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  21%|██        | 9258/44303 [55:04<3:28:02,  2.81it/s, loss=0.0902]\u001b[A\n","Training Epoch 1:  21%|██        | 9259/44303 [55:04<3:28:34,  2.80it/s, loss=0.0902]\u001b[A\n","Training Epoch 1:  21%|██        | 9259/44303 [55:04<3:28:34,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  21%|██        | 9260/44303 [55:04<3:28:58,  2.79it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  21%|██        | 9260/44303 [55:05<3:28:58,  2.79it/s, loss=0.0598]\u001b[A\n","Training Epoch 1:  21%|██        | 9261/44303 [55:05<3:28:27,  2.80it/s, loss=0.0598]\u001b[A\n","Training Epoch 1:  21%|██        | 9261/44303 [55:05<3:28:27,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  21%|██        | 9262/44303 [55:05<3:28:30,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  21%|██        | 9262/44303 [55:05<3:28:30,  2.80it/s, loss=0.0354]\u001b[A\n","Training Epoch 1:  21%|██        | 9263/44303 [55:05<3:28:35,  2.80it/s, loss=0.0354]\u001b[A\n","Training Epoch 1:  21%|██        | 9263/44303 [55:06<3:28:35,  2.80it/s, loss=0.0377]\u001b[A\n","Training Epoch 1:  21%|██        | 9264/44303 [55:06<3:28:34,  2.80it/s, loss=0.0377]\u001b[A\n","Training Epoch 1:  21%|██        | 9264/44303 [55:06<3:28:34,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  21%|██        | 9265/44303 [55:06<3:29:25,  2.79it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  21%|██        | 9265/44303 [55:07<3:29:25,  2.79it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  21%|██        | 9266/44303 [55:07<3:29:27,  2.79it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  21%|██        | 9266/44303 [55:07<3:29:27,  2.79it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  21%|██        | 9267/44303 [55:07<3:29:14,  2.79it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  21%|██        | 9267/44303 [55:07<3:29:14,  2.79it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  21%|██        | 9268/44303 [55:07<3:29:39,  2.79it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  21%|██        | 9268/44303 [55:08<3:29:39,  2.79it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██        | 9269/44303 [55:08<3:28:53,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██        | 9269/44303 [55:08<3:28:53,  2.80it/s, loss=0.0868]\u001b[A\n","Training Epoch 1:  21%|██        | 9270/44303 [55:08<3:28:48,  2.80it/s, loss=0.0868]\u001b[A\n","Training Epoch 1:  21%|██        | 9270/44303 [55:08<3:28:48,  2.80it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  21%|██        | 9271/44303 [55:08<3:28:24,  2.80it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  21%|██        | 9271/44303 [55:09<3:28:24,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  21%|██        | 9272/44303 [55:09<3:27:39,  2.81it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  21%|██        | 9272/44303 [55:09<3:27:39,  2.81it/s, loss=0.0529]\u001b[A\n","Training Epoch 1:  21%|██        | 9273/44303 [55:09<3:28:13,  2.80it/s, loss=0.0529]\u001b[A\n","Training Epoch 1:  21%|██        | 9273/44303 [55:09<3:28:13,  2.80it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  21%|██        | 9274/44303 [55:09<3:28:56,  2.79it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  21%|██        | 9274/44303 [55:10<3:28:56,  2.79it/s, loss=0.145] \u001b[A\n","Training Epoch 1:  21%|██        | 9275/44303 [55:10<3:28:48,  2.80it/s, loss=0.145]\u001b[A\n","Training Epoch 1:  21%|██        | 9275/44303 [55:10<3:28:48,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  21%|██        | 9276/44303 [55:10<3:28:53,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  21%|██        | 9276/44303 [55:10<3:28:53,  2.79it/s, loss=0.0746]\u001b[A\n","Training Epoch 1:  21%|██        | 9277/44303 [55:10<3:28:58,  2.79it/s, loss=0.0746]\u001b[A\n","Training Epoch 1:  21%|██        | 9277/44303 [55:11<3:28:58,  2.79it/s, loss=0.0301]\u001b[A\n","Training Epoch 1:  21%|██        | 9278/44303 [55:11<3:28:20,  2.80it/s, loss=0.0301]\u001b[A\n","Training Epoch 1:  21%|██        | 9278/44303 [55:11<3:28:20,  2.80it/s, loss=0.0707]\u001b[A\n","Training Epoch 1:  21%|██        | 9279/44303 [55:11<3:28:37,  2.80it/s, loss=0.0707]\u001b[A\n","Training Epoch 1:  21%|██        | 9279/44303 [55:12<3:28:37,  2.80it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  21%|██        | 9280/44303 [55:12<3:28:44,  2.80it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  21%|██        | 9280/44303 [55:12<3:28:44,  2.80it/s, loss=0.0741]\u001b[A\n","Training Epoch 1:  21%|██        | 9281/44303 [55:12<3:28:33,  2.80it/s, loss=0.0741]\u001b[A\n","Training Epoch 1:  21%|██        | 9281/44303 [55:12<3:28:33,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  21%|██        | 9282/44303 [55:12<3:28:55,  2.79it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  21%|██        | 9282/44303 [55:13<3:28:55,  2.79it/s, loss=0.072] \u001b[A\n","Training Epoch 1:  21%|██        | 9283/44303 [55:13<3:29:20,  2.79it/s, loss=0.072]\u001b[A\n","Training Epoch 1:  21%|██        | 9283/44303 [55:13<3:29:20,  2.79it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  21%|██        | 9284/44303 [55:13<3:28:14,  2.80it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  21%|██        | 9284/44303 [55:13<3:28:14,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  21%|██        | 9285/44303 [55:13<3:28:37,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  21%|██        | 9285/44303 [55:14<3:28:37,  2.80it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  21%|██        | 9286/44303 [55:14<3:28:28,  2.80it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  21%|██        | 9286/44303 [55:14<3:28:28,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  21%|██        | 9287/44303 [55:14<3:28:15,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  21%|██        | 9287/44303 [55:14<3:28:15,  2.80it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  21%|██        | 9288/44303 [55:14<3:28:25,  2.80it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  21%|██        | 9288/44303 [55:15<3:28:25,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9289/44303 [55:15<3:28:28,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9289/44303 [55:15<3:28:28,  2.80it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  21%|██        | 9290/44303 [55:15<3:29:00,  2.79it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  21%|██        | 9290/44303 [55:15<3:29:00,  2.79it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  21%|██        | 9291/44303 [55:15<3:29:07,  2.79it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  21%|██        | 9291/44303 [55:16<3:29:07,  2.79it/s, loss=0.061] \u001b[A\n","Training Epoch 1:  21%|██        | 9292/44303 [55:16<3:28:23,  2.80it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  21%|██        | 9292/44303 [55:16<3:28:23,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  21%|██        | 9293/44303 [55:16<3:28:08,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  21%|██        | 9293/44303 [55:17<3:28:08,  2.80it/s, loss=0.0745]\u001b[A\n","Training Epoch 1:  21%|██        | 9294/44303 [55:17<3:29:21,  2.79it/s, loss=0.0745]\u001b[A\n","Training Epoch 1:  21%|██        | 9294/44303 [55:17<3:29:21,  2.79it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  21%|██        | 9295/44303 [55:17<3:29:04,  2.79it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  21%|██        | 9295/44303 [55:17<3:29:04,  2.79it/s, loss=0.055] \u001b[A\n","Training Epoch 1:  21%|██        | 9296/44303 [55:17<3:29:21,  2.79it/s, loss=0.055]\u001b[A\n","Training Epoch 1:  21%|██        | 9296/44303 [55:18<3:29:21,  2.79it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  21%|██        | 9297/44303 [55:18<3:29:41,  2.78it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  21%|██        | 9297/44303 [55:18<3:29:41,  2.78it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  21%|██        | 9298/44303 [55:18<3:29:07,  2.79it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  21%|██        | 9298/44303 [55:18<3:29:07,  2.79it/s, loss=0.0315]\u001b[A\n","Training Epoch 1:  21%|██        | 9299/44303 [55:18<3:29:02,  2.79it/s, loss=0.0315]\u001b[A\n","Training Epoch 1:  21%|██        | 9299/44303 [55:19<3:29:02,  2.79it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  21%|██        | 9300/44303 [55:19<3:28:53,  2.79it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  21%|██        | 9300/44303 [55:19<3:28:53,  2.79it/s, loss=0.0749]\u001b[A\n","Training Epoch 1:  21%|██        | 9301/44303 [55:19<3:29:20,  2.79it/s, loss=0.0749]\u001b[A\n","Training Epoch 1:  21%|██        | 9301/44303 [55:19<3:29:20,  2.79it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  21%|██        | 9302/44303 [55:19<3:29:39,  2.78it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  21%|██        | 9302/44303 [55:20<3:29:39,  2.78it/s, loss=0.0536]\u001b[A\n","Training Epoch 1:  21%|██        | 9303/44303 [55:20<3:29:16,  2.79it/s, loss=0.0536]\u001b[A\n","Training Epoch 1:  21%|██        | 9303/44303 [55:20<3:29:16,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██        | 9304/44303 [55:20<3:29:04,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██        | 9304/44303 [55:20<3:29:04,  2.79it/s, loss=0.046] \u001b[A\n","Training Epoch 1:  21%|██        | 9305/44303 [55:20<3:28:01,  2.80it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  21%|██        | 9305/44303 [55:21<3:28:01,  2.80it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  21%|██        | 9306/44303 [55:21<3:28:14,  2.80it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  21%|██        | 9306/44303 [55:21<3:28:14,  2.80it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  21%|██        | 9307/44303 [55:21<3:28:58,  2.79it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  21%|██        | 9307/44303 [55:22<3:28:58,  2.79it/s, loss=0.0974]\u001b[A\n","Training Epoch 1:  21%|██        | 9308/44303 [55:22<3:28:48,  2.79it/s, loss=0.0974]\u001b[A\n","Training Epoch 1:  21%|██        | 9308/44303 [55:22<3:28:48,  2.79it/s, loss=0.0767]\u001b[A\n","Training Epoch 1:  21%|██        | 9309/44303 [55:22<3:28:35,  2.80it/s, loss=0.0767]\u001b[A\n","Training Epoch 1:  21%|██        | 9309/44303 [55:22<3:28:35,  2.80it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  21%|██        | 9310/44303 [55:22<3:29:38,  2.78it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  21%|██        | 9310/44303 [55:23<3:29:38,  2.78it/s, loss=0.0787]\u001b[A\n","Training Epoch 1:  21%|██        | 9311/44303 [55:23<3:28:32,  2.80it/s, loss=0.0787]\u001b[A\n","Training Epoch 1:  21%|██        | 9311/44303 [55:23<3:28:32,  2.80it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  21%|██        | 9312/44303 [55:23<3:28:20,  2.80it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  21%|██        | 9312/44303 [55:23<3:28:20,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  21%|██        | 9313/44303 [55:23<3:28:34,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  21%|██        | 9313/44303 [55:24<3:28:34,  2.80it/s, loss=0.039] \u001b[A\n","Training Epoch 1:  21%|██        | 9314/44303 [55:24<3:28:05,  2.80it/s, loss=0.039]\u001b[A\n","Training Epoch 1:  21%|██        | 9314/44303 [55:24<3:28:05,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  21%|██        | 9315/44303 [55:24<3:28:29,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  21%|██        | 9315/44303 [55:24<3:28:29,  2.80it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  21%|██        | 9316/44303 [55:24<3:28:52,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  21%|██        | 9316/44303 [55:25<3:28:52,  2.79it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  21%|██        | 9317/44303 [55:25<3:27:34,  2.81it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  21%|██        | 9317/44303 [55:25<3:27:34,  2.81it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  21%|██        | 9318/44303 [55:25<3:28:14,  2.80it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  21%|██        | 9318/44303 [55:26<3:28:14,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  21%|██        | 9319/44303 [55:26<3:28:43,  2.79it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  21%|██        | 9319/44303 [55:26<3:28:43,  2.79it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  21%|██        | 9320/44303 [55:26<3:28:28,  2.80it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  21%|██        | 9320/44303 [55:26<3:28:28,  2.80it/s, loss=0.0749]\u001b[A\n","Training Epoch 1:  21%|██        | 9321/44303 [55:26<3:28:45,  2.79it/s, loss=0.0749]\u001b[A\n","Training Epoch 1:  21%|██        | 9321/44303 [55:27<3:28:45,  2.79it/s, loss=0.05]  \u001b[A\n","Training Epoch 1:  21%|██        | 9322/44303 [55:27<3:28:54,  2.79it/s, loss=0.05]\u001b[A\n","Training Epoch 1:  21%|██        | 9322/44303 [55:27<3:28:54,  2.79it/s, loss=0.0366]\u001b[A\n","Training Epoch 1:  21%|██        | 9323/44303 [55:27<3:28:46,  2.79it/s, loss=0.0366]\u001b[A\n","Training Epoch 1:  21%|██        | 9323/44303 [55:27<3:28:46,  2.79it/s, loss=0.0832]\u001b[A\n","Training Epoch 1:  21%|██        | 9324/44303 [55:27<3:29:06,  2.79it/s, loss=0.0832]\u001b[A\n","Training Epoch 1:  21%|██        | 9324/44303 [55:28<3:29:06,  2.79it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  21%|██        | 9325/44303 [55:28<3:29:37,  2.78it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  21%|██        | 9325/44303 [55:28<3:29:37,  2.78it/s, loss=0.0638]\u001b[A\n","Training Epoch 1:  21%|██        | 9326/44303 [55:28<3:29:19,  2.78it/s, loss=0.0638]\u001b[A\n","Training Epoch 1:  21%|██        | 9326/44303 [55:28<3:29:19,  2.78it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  21%|██        | 9327/44303 [55:28<3:28:43,  2.79it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  21%|██        | 9327/44303 [55:29<3:28:43,  2.79it/s, loss=0.0568]\u001b[A\n","Training Epoch 1:  21%|██        | 9328/44303 [55:29<3:29:09,  2.79it/s, loss=0.0568]\u001b[A\n","Training Epoch 1:  21%|██        | 9328/44303 [55:29<3:29:09,  2.79it/s, loss=0.0964]\u001b[A\n","Training Epoch 1:  21%|██        | 9329/44303 [55:29<3:28:55,  2.79it/s, loss=0.0964]\u001b[A\n","Training Epoch 1:  21%|██        | 9329/44303 [55:29<3:28:55,  2.79it/s, loss=0.0912]\u001b[A\n","Training Epoch 1:  21%|██        | 9330/44303 [55:29<3:28:29,  2.80it/s, loss=0.0912]\u001b[A\n","Training Epoch 1:  21%|██        | 9330/44303 [55:30<3:28:29,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  21%|██        | 9331/44303 [55:30<3:28:37,  2.79it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  21%|██        | 9331/44303 [55:30<3:28:37,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  21%|██        | 9332/44303 [55:30<3:28:44,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  21%|██        | 9332/44303 [55:31<3:28:44,  2.79it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  21%|██        | 9333/44303 [55:31<3:28:37,  2.79it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  21%|██        | 9333/44303 [55:31<3:28:37,  2.79it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  21%|██        | 9334/44303 [55:31<3:28:57,  2.79it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  21%|██        | 9334/44303 [55:31<3:28:57,  2.79it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  21%|██        | 9335/44303 [55:31<3:29:23,  2.78it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  21%|██        | 9335/44303 [55:32<3:29:23,  2.78it/s, loss=0.23]  \u001b[A\n","Training Epoch 1:  21%|██        | 9336/44303 [55:32<3:29:15,  2.78it/s, loss=0.23]\u001b[A\n","Training Epoch 1:  21%|██        | 9336/44303 [55:32<3:29:15,  2.78it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  21%|██        | 9337/44303 [55:32<3:29:01,  2.79it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  21%|██        | 9337/44303 [55:32<3:29:01,  2.79it/s, loss=0.0679]\u001b[A\n","Training Epoch 1:  21%|██        | 9338/44303 [55:32<3:28:59,  2.79it/s, loss=0.0679]\u001b[A\n","Training Epoch 1:  21%|██        | 9338/44303 [55:33<3:28:59,  2.79it/s, loss=0.0651]\u001b[A\n","Training Epoch 1:  21%|██        | 9339/44303 [55:33<3:28:48,  2.79it/s, loss=0.0651]\u001b[A\n","Training Epoch 1:  21%|██        | 9339/44303 [55:33<3:28:48,  2.79it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  21%|██        | 9340/44303 [55:33<3:28:05,  2.80it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  21%|██        | 9340/44303 [55:33<3:28:05,  2.80it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  21%|██        | 9341/44303 [55:33<3:28:06,  2.80it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  21%|██        | 9341/44303 [55:34<3:28:06,  2.80it/s, loss=0.0353]\u001b[A\n","Training Epoch 1:  21%|██        | 9342/44303 [55:34<3:28:14,  2.80it/s, loss=0.0353]\u001b[A\n","Training Epoch 1:  21%|██        | 9342/44303 [55:34<3:28:14,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  21%|██        | 9343/44303 [55:34<3:27:51,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  21%|██        | 9343/44303 [55:34<3:27:51,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  21%|██        | 9344/44303 [55:34<3:28:26,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  21%|██        | 9344/44303 [55:35<3:28:26,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  21%|██        | 9345/44303 [55:35<3:27:54,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  21%|██        | 9345/44303 [55:35<3:27:54,  2.80it/s, loss=0.046] \u001b[A\n","Training Epoch 1:  21%|██        | 9346/44303 [55:35<3:28:33,  2.79it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  21%|██        | 9346/44303 [55:36<3:28:33,  2.79it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  21%|██        | 9347/44303 [55:36<3:28:50,  2.79it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  21%|██        | 9347/44303 [55:36<3:28:50,  2.79it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  21%|██        | 9348/44303 [55:36<3:28:42,  2.79it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  21%|██        | 9348/44303 [55:36<3:28:42,  2.79it/s, loss=0.045] \u001b[A\n","Training Epoch 1:  21%|██        | 9349/44303 [55:36<3:28:03,  2.80it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  21%|██        | 9349/44303 [55:37<3:28:03,  2.80it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  21%|██        | 9350/44303 [55:37<3:28:34,  2.79it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  21%|██        | 9350/44303 [55:37<3:28:34,  2.79it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  21%|██        | 9351/44303 [55:37<3:27:44,  2.80it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  21%|██        | 9351/44303 [55:37<3:27:44,  2.80it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  21%|██        | 9352/44303 [55:37<3:28:09,  2.80it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  21%|██        | 9352/44303 [55:38<3:28:09,  2.80it/s, loss=0.0438]\u001b[A\n","Training Epoch 1:  21%|██        | 9353/44303 [55:38<3:29:21,  2.78it/s, loss=0.0438]\u001b[A\n","Training Epoch 1:  21%|██        | 9353/44303 [55:38<3:29:21,  2.78it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  21%|██        | 9354/44303 [55:38<3:28:57,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  21%|██        | 9354/44303 [55:38<3:28:57,  2.79it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  21%|██        | 9355/44303 [55:38<3:28:16,  2.80it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  21%|██        | 9355/44303 [55:39<3:28:16,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  21%|██        | 9356/44303 [55:39<3:28:52,  2.79it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  21%|██        | 9356/44303 [55:39<3:28:52,  2.79it/s, loss=0.127] \u001b[A\n","Training Epoch 1:  21%|██        | 9357/44303 [55:39<3:27:51,  2.80it/s, loss=0.127]\u001b[A\n","Training Epoch 1:  21%|██        | 9357/44303 [55:39<3:27:51,  2.80it/s, loss=0.0259]\u001b[A\n","Training Epoch 1:  21%|██        | 9358/44303 [55:39<3:27:30,  2.81it/s, loss=0.0259]\u001b[A\n","Training Epoch 1:  21%|██        | 9358/44303 [55:40<3:27:30,  2.81it/s, loss=0.0922]\u001b[A\n","Training Epoch 1:  21%|██        | 9359/44303 [55:40<3:27:48,  2.80it/s, loss=0.0922]\u001b[A\n","Training Epoch 1:  21%|██        | 9359/44303 [55:40<3:27:48,  2.80it/s, loss=0.029] \u001b[A\n","Training Epoch 1:  21%|██        | 9360/44303 [55:40<3:27:51,  2.80it/s, loss=0.029]\u001b[A\n","Training Epoch 1:  21%|██        | 9360/44303 [55:41<3:27:51,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  21%|██        | 9361/44303 [55:41<3:28:06,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  21%|██        | 9361/44303 [55:41<3:28:06,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  21%|██        | 9362/44303 [55:41<3:28:05,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  21%|██        | 9362/44303 [55:41<3:28:05,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  21%|██        | 9363/44303 [55:41<3:28:00,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  21%|██        | 9363/44303 [55:42<3:28:00,  2.80it/s, loss=0.0434]\u001b[A\n","Training Epoch 1:  21%|██        | 9364/44303 [55:42<3:28:12,  2.80it/s, loss=0.0434]\u001b[A\n","Training Epoch 1:  21%|██        | 9364/44303 [55:42<3:28:12,  2.80it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  21%|██        | 9365/44303 [55:42<3:27:25,  2.81it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  21%|██        | 9365/44303 [55:42<3:27:25,  2.81it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  21%|██        | 9366/44303 [55:42<3:27:44,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  21%|██        | 9366/44303 [55:43<3:27:44,  2.80it/s, loss=0.0696]\u001b[A\n","Training Epoch 1:  21%|██        | 9367/44303 [55:43<3:27:41,  2.80it/s, loss=0.0696]\u001b[A\n","Training Epoch 1:  21%|██        | 9367/44303 [55:43<3:27:41,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  21%|██        | 9368/44303 [55:43<3:28:04,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  21%|██        | 9368/44303 [55:43<3:28:04,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  21%|██        | 9369/44303 [55:43<3:28:08,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  21%|██        | 9369/44303 [55:44<3:28:08,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  21%|██        | 9370/44303 [55:44<3:27:53,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  21%|██        | 9370/44303 [55:44<3:27:53,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  21%|██        | 9371/44303 [55:44<3:28:12,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  21%|██        | 9371/44303 [55:44<3:28:12,  2.80it/s, loss=0.0368]\u001b[A\n","Training Epoch 1:  21%|██        | 9372/44303 [55:44<3:28:22,  2.79it/s, loss=0.0368]\u001b[A\n","Training Epoch 1:  21%|██        | 9372/44303 [55:45<3:28:22,  2.79it/s, loss=0.0343]\u001b[A\n","Training Epoch 1:  21%|██        | 9373/44303 [55:45<3:28:27,  2.79it/s, loss=0.0343]\u001b[A\n","Training Epoch 1:  21%|██        | 9373/44303 [55:45<3:28:27,  2.79it/s, loss=0.0267]\u001b[A\n","Training Epoch 1:  21%|██        | 9374/44303 [55:45<3:28:43,  2.79it/s, loss=0.0267]\u001b[A\n","Training Epoch 1:  21%|██        | 9374/44303 [55:46<3:28:43,  2.79it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  21%|██        | 9375/44303 [55:46<3:28:31,  2.79it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  21%|██        | 9375/44303 [55:46<3:28:31,  2.79it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  21%|██        | 9376/44303 [55:46<3:28:00,  2.80it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  21%|██        | 9376/44303 [55:46<3:28:00,  2.80it/s, loss=0.058] \u001b[A\n","Training Epoch 1:  21%|██        | 9377/44303 [55:46<3:28:26,  2.79it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  21%|██        | 9377/44303 [55:47<3:28:26,  2.79it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  21%|██        | 9378/44303 [55:47<3:27:36,  2.80it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  21%|██        | 9378/44303 [55:47<3:27:36,  2.80it/s, loss=0.0996]\u001b[A\n","Training Epoch 1:  21%|██        | 9379/44303 [55:47<3:27:49,  2.80it/s, loss=0.0996]\u001b[A\n","Training Epoch 1:  21%|██        | 9379/44303 [55:47<3:27:49,  2.80it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  21%|██        | 9380/44303 [55:47<3:27:48,  2.80it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  21%|██        | 9380/44303 [55:48<3:27:48,  2.80it/s, loss=0.0263]\u001b[A\n","Training Epoch 1:  21%|██        | 9381/44303 [55:48<3:27:23,  2.81it/s, loss=0.0263]\u001b[A\n","Training Epoch 1:  21%|██        | 9381/44303 [55:48<3:27:23,  2.81it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  21%|██        | 9382/44303 [55:48<3:27:46,  2.80it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  21%|██        | 9382/44303 [55:48<3:27:46,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9383/44303 [55:48<3:27:37,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██        | 9383/44303 [55:49<3:27:37,  2.80it/s, loss=0.0384]\u001b[A\n","Training Epoch 1:  21%|██        | 9384/44303 [55:49<3:27:51,  2.80it/s, loss=0.0384]\u001b[A\n","Training Epoch 1:  21%|██        | 9384/44303 [55:49<3:27:51,  2.80it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  21%|██        | 9385/44303 [55:49<3:27:47,  2.80it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  21%|██        | 9385/44303 [55:49<3:27:47,  2.80it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  21%|██        | 9386/44303 [55:49<3:27:29,  2.80it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  21%|██        | 9386/44303 [55:50<3:27:29,  2.80it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  21%|██        | 9387/44303 [55:50<3:27:48,  2.80it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  21%|██        | 9387/44303 [55:50<3:27:48,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  21%|██        | 9388/44303 [55:50<3:27:43,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  21%|██        | 9388/44303 [55:51<3:27:43,  2.80it/s, loss=0.0444]\u001b[A\n","Training Epoch 1:  21%|██        | 9389/44303 [55:51<3:27:28,  2.80it/s, loss=0.0444]\u001b[A\n","Training Epoch 1:  21%|██        | 9389/44303 [55:51<3:27:28,  2.80it/s, loss=0.0809]\u001b[A\n","Training Epoch 1:  21%|██        | 9390/44303 [55:51<3:27:26,  2.81it/s, loss=0.0809]\u001b[A\n","Training Epoch 1:  21%|██        | 9390/44303 [55:51<3:27:26,  2.81it/s, loss=0.025] \u001b[A\n","Training Epoch 1:  21%|██        | 9391/44303 [55:51<3:27:31,  2.80it/s, loss=0.025]\u001b[A\n","Training Epoch 1:  21%|██        | 9391/44303 [55:52<3:27:31,  2.80it/s, loss=0.028]\u001b[A\n","Training Epoch 1:  21%|██        | 9392/44303 [55:52<3:27:38,  2.80it/s, loss=0.028]\u001b[A\n","Training Epoch 1:  21%|██        | 9392/44303 [55:52<3:27:38,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  21%|██        | 9393/44303 [55:52<3:27:15,  2.81it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  21%|██        | 9393/44303 [55:52<3:27:15,  2.81it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  21%|██        | 9394/44303 [55:52<3:27:46,  2.80it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  21%|██        | 9394/44303 [55:53<3:27:46,  2.80it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  21%|██        | 9395/44303 [55:53<3:28:46,  2.79it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  21%|██        | 9395/44303 [55:53<3:28:46,  2.79it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  21%|██        | 9396/44303 [55:53<3:28:04,  2.80it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  21%|██        | 9396/44303 [55:53<3:28:04,  2.80it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  21%|██        | 9397/44303 [55:53<3:28:23,  2.79it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  21%|██        | 9397/44303 [55:54<3:28:23,  2.79it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  21%|██        | 9398/44303 [55:54<3:28:34,  2.79it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  21%|██        | 9398/44303 [55:54<3:28:34,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██        | 9399/44303 [55:54<3:27:37,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██        | 9399/44303 [55:54<3:27:37,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  21%|██        | 9400/44303 [55:54<3:28:00,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  21%|██        | 9400/44303 [55:55<3:28:00,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  21%|██        | 9401/44303 [55:55<3:27:42,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  21%|██        | 9401/44303 [55:55<3:27:42,  2.80it/s, loss=0.0437]\u001b[A\n","Training Epoch 1:  21%|██        | 9402/44303 [55:55<3:27:50,  2.80it/s, loss=0.0437]\u001b[A\n","Training Epoch 1:  21%|██        | 9402/44303 [55:56<3:27:50,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  21%|██        | 9403/44303 [55:56<3:27:44,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  21%|██        | 9403/44303 [55:56<3:27:44,  2.80it/s, loss=0.0864]\u001b[A\n","Training Epoch 1:  21%|██        | 9404/44303 [55:56<3:28:03,  2.80it/s, loss=0.0864]\u001b[A\n","Training Epoch 1:  21%|██        | 9404/44303 [55:56<3:28:03,  2.80it/s, loss=0.109] \u001b[A\n","Training Epoch 1:  21%|██        | 9405/44303 [55:56<3:28:47,  2.79it/s, loss=0.109]\u001b[A\n","Training Epoch 1:  21%|██        | 9405/44303 [55:57<3:28:47,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  21%|██        | 9406/44303 [55:57<3:28:39,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  21%|██        | 9406/44303 [55:57<3:28:39,  2.79it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  21%|██        | 9407/44303 [55:57<3:27:58,  2.80it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  21%|██        | 9407/44303 [55:57<3:27:58,  2.80it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  21%|██        | 9408/44303 [55:57<3:28:22,  2.79it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  21%|██        | 9408/44303 [55:58<3:28:22,  2.79it/s, loss=0.0268]\u001b[A\n","Training Epoch 1:  21%|██        | 9409/44303 [55:58<3:28:42,  2.79it/s, loss=0.0268]\u001b[A\n","Training Epoch 1:  21%|██        | 9409/44303 [55:58<3:28:42,  2.79it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  21%|██        | 9410/44303 [55:58<3:28:00,  2.80it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  21%|██        | 9410/44303 [55:58<3:28:00,  2.80it/s, loss=0.0712]\u001b[A\n","Training Epoch 1:  21%|██        | 9411/44303 [55:58<3:28:14,  2.79it/s, loss=0.0712]\u001b[A\n","Training Epoch 1:  21%|██        | 9411/44303 [55:59<3:28:14,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  21%|██        | 9412/44303 [55:59<3:26:50,  2.81it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  21%|██        | 9412/44303 [55:59<3:26:50,  2.81it/s, loss=0.0782]\u001b[A\n","Training Epoch 1:  21%|██        | 9413/44303 [55:59<3:27:17,  2.81it/s, loss=0.0782]\u001b[A\n","Training Epoch 1:  21%|██        | 9413/44303 [55:59<3:27:17,  2.81it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  21%|██        | 9414/44303 [55:59<3:27:44,  2.80it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  21%|██        | 9414/44303 [56:00<3:27:44,  2.80it/s, loss=0.0951]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9415/44303 [56:00<3:27:26,  2.80it/s, loss=0.0951]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9415/44303 [56:00<3:27:26,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9416/44303 [56:00<3:27:46,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9416/44303 [56:01<3:27:46,  2.80it/s, loss=0.0912]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9417/44303 [56:01<3:27:41,  2.80it/s, loss=0.0912]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9417/44303 [56:01<3:27:41,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9418/44303 [56:01<3:27:39,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9418/44303 [56:01<3:27:39,  2.80it/s, loss=0.0827]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9419/44303 [56:01<3:28:05,  2.79it/s, loss=0.0827]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9419/44303 [56:02<3:28:05,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9420/44303 [56:02<3:27:14,  2.81it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9420/44303 [56:02<3:27:14,  2.81it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9421/44303 [56:02<3:27:47,  2.80it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9421/44303 [56:02<3:27:47,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9422/44303 [56:02<3:28:17,  2.79it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9422/44303 [56:03<3:28:17,  2.79it/s, loss=0.0658]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9423/44303 [56:03<3:27:30,  2.80it/s, loss=0.0658]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9423/44303 [56:03<3:27:30,  2.80it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9424/44303 [56:03<3:27:47,  2.80it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9424/44303 [56:03<3:27:47,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9425/44303 [56:03<3:27:47,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9425/44303 [56:04<3:27:47,  2.80it/s, loss=0.0628]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9426/44303 [56:04<3:27:17,  2.80it/s, loss=0.0628]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9426/44303 [56:04<3:27:17,  2.80it/s, loss=0.035] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9427/44303 [56:04<3:28:14,  2.79it/s, loss=0.035]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9427/44303 [56:04<3:28:14,  2.79it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9428/44303 [56:04<3:27:58,  2.79it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9428/44303 [56:05<3:27:58,  2.79it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9429/44303 [56:05<3:27:41,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9429/44303 [56:05<3:27:41,  2.80it/s, loss=0.118] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9430/44303 [56:05<3:28:12,  2.79it/s, loss=0.118]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9430/44303 [56:06<3:28:12,  2.79it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9431/44303 [56:06<3:27:33,  2.80it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9431/44303 [56:06<3:27:33,  2.80it/s, loss=0.0412]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9432/44303 [56:06<3:28:05,  2.79it/s, loss=0.0412]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9432/44303 [56:06<3:28:05,  2.79it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9433/44303 [56:06<3:29:21,  2.78it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9433/44303 [56:07<3:29:21,  2.78it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9434/44303 [56:07<3:28:33,  2.79it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9434/44303 [56:07<3:28:33,  2.79it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9435/44303 [56:07<3:28:23,  2.79it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9435/44303 [56:07<3:28:23,  2.79it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9436/44303 [56:07<3:28:17,  2.79it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9436/44303 [56:08<3:28:17,  2.79it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9437/44303 [56:08<3:27:48,  2.80it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9437/44303 [56:08<3:27:48,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9438/44303 [56:08<3:27:28,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9438/44303 [56:08<3:27:28,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9439/44303 [56:08<3:27:50,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9439/44303 [56:09<3:27:50,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9440/44303 [56:09<3:27:40,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9440/44303 [56:09<3:27:40,  2.80it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9441/44303 [56:09<3:27:24,  2.80it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9441/44303 [56:09<3:27:24,  2.80it/s, loss=0.106] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9442/44303 [56:09<3:27:09,  2.80it/s, loss=0.106]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9442/44303 [56:10<3:27:09,  2.80it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9443/44303 [56:10<3:26:21,  2.82it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9443/44303 [56:10<3:26:21,  2.82it/s, loss=0.0381]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9444/44303 [56:10<3:27:14,  2.80it/s, loss=0.0381]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9444/44303 [56:11<3:27:14,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9445/44303 [56:11<3:27:28,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9445/44303 [56:11<3:27:28,  2.80it/s, loss=0.0312]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9446/44303 [56:11<3:26:50,  2.81it/s, loss=0.0312]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9446/44303 [56:11<3:26:50,  2.81it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9447/44303 [56:11<3:27:13,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9447/44303 [56:12<3:27:13,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9448/44303 [56:12<3:26:29,  2.81it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9448/44303 [56:12<3:26:29,  2.81it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9449/44303 [56:12<3:26:42,  2.81it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9449/44303 [56:12<3:26:42,  2.81it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9450/44303 [56:12<3:26:56,  2.81it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9450/44303 [56:13<3:26:56,  2.81it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9451/44303 [56:13<3:26:49,  2.81it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9451/44303 [56:13<3:26:49,  2.81it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9452/44303 [56:13<3:27:29,  2.80it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9452/44303 [56:13<3:27:29,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9453/44303 [56:13<3:26:57,  2.81it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9453/44303 [56:14<3:26:57,  2.81it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9454/44303 [56:14<3:26:50,  2.81it/s, loss=0.0528]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9454/44303 [56:14<3:26:50,  2.81it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9455/44303 [56:14<3:26:39,  2.81it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9455/44303 [56:14<3:26:39,  2.81it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9456/44303 [56:14<3:26:51,  2.81it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9456/44303 [56:15<3:26:51,  2.81it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9457/44303 [56:15<3:26:57,  2.81it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9457/44303 [56:15<3:26:57,  2.81it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9458/44303 [56:15<3:26:30,  2.81it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9458/44303 [56:16<3:26:30,  2.81it/s, loss=0.0224]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9459/44303 [56:16<3:27:03,  2.80it/s, loss=0.0224]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9459/44303 [56:16<3:27:03,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9460/44303 [56:16<3:26:17,  2.82it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9460/44303 [56:16<3:26:17,  2.82it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9461/44303 [56:16<3:26:55,  2.81it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9461/44303 [56:17<3:26:55,  2.81it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9462/44303 [56:17<3:26:40,  2.81it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9462/44303 [56:17<3:26:40,  2.81it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9463/44303 [56:17<3:27:02,  2.80it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9463/44303 [56:17<3:27:02,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9464/44303 [56:17<3:27:09,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9464/44303 [56:18<3:27:09,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9465/44303 [56:18<3:26:57,  2.81it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9465/44303 [56:18<3:26:57,  2.81it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9466/44303 [56:18<3:27:09,  2.80it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9466/44303 [56:18<3:27:09,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9467/44303 [56:18<3:27:00,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9467/44303 [56:19<3:27:00,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9468/44303 [56:19<3:26:59,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9468/44303 [56:19<3:26:59,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9469/44303 [56:19<3:27:37,  2.80it/s, loss=0.0409]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9469/44303 [56:19<3:27:37,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9470/44303 [56:19<3:27:12,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9470/44303 [56:20<3:27:12,  2.80it/s, loss=0.0334]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9471/44303 [56:20<3:26:46,  2.81it/s, loss=0.0334]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9471/44303 [56:20<3:26:46,  2.81it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9472/44303 [56:20<3:27:19,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9472/44303 [56:21<3:27:19,  2.80it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9473/44303 [56:21<3:26:30,  2.81it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9473/44303 [56:21<3:26:30,  2.81it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9474/44303 [56:21<3:26:50,  2.81it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9474/44303 [56:21<3:26:50,  2.81it/s, loss=0.0773]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9475/44303 [56:21<3:26:30,  2.81it/s, loss=0.0773]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9475/44303 [56:22<3:26:30,  2.81it/s, loss=0.039] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9476/44303 [56:22<3:26:24,  2.81it/s, loss=0.039]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9476/44303 [56:22<3:26:24,  2.81it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9477/44303 [56:22<3:25:52,  2.82it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9477/44303 [56:22<3:25:52,  2.82it/s, loss=0.0317]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9478/44303 [56:22<3:26:32,  2.81it/s, loss=0.0317]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9478/44303 [56:23<3:26:32,  2.81it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9479/44303 [56:23<3:27:17,  2.80it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9479/44303 [56:23<3:27:17,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9480/44303 [56:23<3:26:50,  2.81it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9480/44303 [56:23<3:26:50,  2.81it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9481/44303 [56:23<3:27:02,  2.80it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9481/44303 [56:24<3:27:02,  2.80it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9482/44303 [56:24<3:27:34,  2.80it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9482/44303 [56:24<3:27:34,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9483/44303 [56:24<3:27:13,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9483/44303 [56:24<3:27:13,  2.80it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9484/44303 [56:24<3:27:24,  2.80it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9484/44303 [56:25<3:27:24,  2.80it/s, loss=0.0372]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9485/44303 [56:25<3:27:15,  2.80it/s, loss=0.0372]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9485/44303 [56:25<3:27:15,  2.80it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9486/44303 [56:25<3:27:15,  2.80it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9486/44303 [56:26<3:27:15,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9487/44303 [56:26<3:27:56,  2.79it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9487/44303 [56:26<3:27:56,  2.79it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9488/44303 [56:26<3:27:28,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9488/44303 [56:26<3:27:28,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9489/44303 [56:26<3:27:18,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9489/44303 [56:27<3:27:18,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9490/44303 [56:27<3:27:28,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9490/44303 [56:27<3:27:28,  2.80it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9491/44303 [56:27<3:27:50,  2.79it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9491/44303 [56:27<3:27:50,  2.79it/s, loss=0.0412]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9492/44303 [56:27<3:27:19,  2.80it/s, loss=0.0412]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9492/44303 [56:28<3:27:19,  2.80it/s, loss=0.112] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9493/44303 [56:28<3:28:00,  2.79it/s, loss=0.112]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9493/44303 [56:28<3:28:00,  2.79it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9494/44303 [56:28<3:27:08,  2.80it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9494/44303 [56:28<3:27:08,  2.80it/s, loss=0.117] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9495/44303 [56:28<3:27:04,  2.80it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9495/44303 [56:29<3:27:04,  2.80it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9496/44303 [56:29<3:28:17,  2.79it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9496/44303 [56:29<3:28:17,  2.79it/s, loss=0.107] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9497/44303 [56:29<3:27:35,  2.79it/s, loss=0.107]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9497/44303 [56:29<3:27:35,  2.79it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9498/44303 [56:29<3:27:07,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9498/44303 [56:30<3:27:07,  2.80it/s, loss=0.076] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9499/44303 [56:30<3:27:47,  2.79it/s, loss=0.076]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9499/44303 [56:30<3:27:47,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9500/44303 [56:30<3:27:10,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9500/44303 [56:31<3:27:10,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9501/44303 [56:31<3:27:27,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9501/44303 [56:31<3:27:27,  2.80it/s, loss=0.0712]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9502/44303 [56:31<3:28:08,  2.79it/s, loss=0.0712]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9502/44303 [56:31<3:28:08,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9503/44303 [56:31<3:28:03,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9503/44303 [56:32<3:28:03,  2.79it/s, loss=0.0701]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9504/44303 [56:32<3:27:32,  2.79it/s, loss=0.0701]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9504/44303 [56:32<3:27:32,  2.79it/s, loss=0.1]   \u001b[A\n","Training Epoch 1:  21%|██▏       | 9505/44303 [56:32<3:28:03,  2.79it/s, loss=0.1]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9505/44303 [56:32<3:28:03,  2.79it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9506/44303 [56:32<3:27:32,  2.79it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9506/44303 [56:33<3:27:32,  2.79it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9507/44303 [56:33<3:27:11,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9507/44303 [56:33<3:27:11,  2.80it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9508/44303 [56:33<3:27:43,  2.79it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9508/44303 [56:33<3:27:43,  2.79it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9509/44303 [56:33<3:27:11,  2.80it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9509/44303 [56:34<3:27:11,  2.80it/s, loss=0.054] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9510/44303 [56:34<3:27:38,  2.79it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9510/44303 [56:34<3:27:38,  2.79it/s, loss=0.0804]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9511/44303 [56:34<3:27:39,  2.79it/s, loss=0.0804]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9511/44303 [56:34<3:27:39,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9512/44303 [56:34<3:27:04,  2.80it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9512/44303 [56:35<3:27:04,  2.80it/s, loss=0.0802]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9513/44303 [56:35<3:27:38,  2.79it/s, loss=0.0802]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9513/44303 [56:35<3:27:38,  2.79it/s, loss=0.046] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9514/44303 [56:35<3:27:33,  2.79it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9514/44303 [56:36<3:27:33,  2.79it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9515/44303 [56:36<3:26:45,  2.80it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9515/44303 [56:36<3:26:45,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9516/44303 [56:36<3:26:46,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9516/44303 [56:36<3:26:46,  2.80it/s, loss=0.115] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9517/44303 [56:36<3:26:34,  2.81it/s, loss=0.115]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9517/44303 [56:37<3:26:34,  2.81it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9518/44303 [56:37<3:27:10,  2.80it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9518/44303 [56:37<3:27:10,  2.80it/s, loss=0.076] \u001b[A\n","Training Epoch 1:  21%|██▏       | 9519/44303 [56:37<3:27:59,  2.79it/s, loss=0.076]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9519/44303 [56:37<3:27:59,  2.79it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9520/44303 [56:37<3:27:01,  2.80it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9520/44303 [56:38<3:27:01,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9521/44303 [56:38<3:27:07,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9521/44303 [56:38<3:27:07,  2.80it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9522/44303 [56:38<3:27:43,  2.79it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9522/44303 [56:38<3:27:43,  2.79it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9523/44303 [56:38<3:27:16,  2.80it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9523/44303 [56:39<3:27:16,  2.80it/s, loss=0.0321]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9524/44303 [56:39<3:27:30,  2.79it/s, loss=0.0321]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9524/44303 [56:39<3:27:30,  2.79it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9525/44303 [56:39<3:27:46,  2.79it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  21%|██▏       | 9525/44303 [56:39<3:27:46,  2.79it/s, loss=0.077] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9526/44303 [56:39<3:27:24,  2.79it/s, loss=0.077]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9526/44303 [56:40<3:27:24,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9527/44303 [56:40<3:27:10,  2.80it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9527/44303 [56:40<3:27:10,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9528/44303 [56:40<3:28:00,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9528/44303 [56:41<3:28:00,  2.79it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9529/44303 [56:41<3:27:06,  2.80it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9529/44303 [56:41<3:27:06,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9530/44303 [56:41<3:27:02,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9530/44303 [56:41<3:27:02,  2.80it/s, loss=0.0786]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9531/44303 [56:41<3:27:25,  2.79it/s, loss=0.0786]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9531/44303 [56:42<3:27:25,  2.79it/s, loss=0.0255]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9532/44303 [56:42<3:26:28,  2.81it/s, loss=0.0255]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9532/44303 [56:42<3:26:28,  2.81it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9533/44303 [56:42<3:26:49,  2.80it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9533/44303 [56:42<3:26:49,  2.80it/s, loss=0.0244]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9534/44303 [56:42<3:27:34,  2.79it/s, loss=0.0244]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9534/44303 [56:43<3:27:34,  2.79it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9535/44303 [56:43<3:26:43,  2.80it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9535/44303 [56:43<3:26:43,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9536/44303 [56:43<3:27:06,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9536/44303 [56:43<3:27:06,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9537/44303 [56:43<3:27:16,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9537/44303 [56:44<3:27:16,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9538/44303 [56:44<3:26:57,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9538/44303 [56:44<3:26:57,  2.80it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9539/44303 [56:44<3:27:02,  2.80it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9539/44303 [56:44<3:27:02,  2.80it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9540/44303 [56:44<3:26:20,  2.81it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9540/44303 [56:45<3:26:20,  2.81it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9541/44303 [56:45<3:26:30,  2.81it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9541/44303 [56:45<3:26:30,  2.81it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9542/44303 [56:45<3:27:03,  2.80it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9542/44303 [56:46<3:27:03,  2.80it/s, loss=0.127] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9543/44303 [56:46<3:26:24,  2.81it/s, loss=0.127]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9543/44303 [56:46<3:26:24,  2.81it/s, loss=0.067]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9544/44303 [56:46<3:27:04,  2.80it/s, loss=0.067]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9544/44303 [56:46<3:27:04,  2.80it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9545/44303 [56:46<3:27:03,  2.80it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9545/44303 [56:47<3:27:03,  2.80it/s, loss=0.0481]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9546/44303 [56:47<3:27:01,  2.80it/s, loss=0.0481]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9546/44303 [56:47<3:27:01,  2.80it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9547/44303 [56:47<3:27:19,  2.79it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9547/44303 [56:47<3:27:19,  2.79it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9548/44303 [56:47<3:26:27,  2.81it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9548/44303 [56:48<3:26:27,  2.81it/s, loss=0.121] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9549/44303 [56:48<3:26:41,  2.80it/s, loss=0.121]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9549/44303 [56:48<3:26:41,  2.80it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9550/44303 [56:48<3:27:17,  2.79it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9550/44303 [56:48<3:27:17,  2.79it/s, loss=0.0308]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9551/44303 [56:48<3:26:35,  2.80it/s, loss=0.0308]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9551/44303 [56:49<3:26:35,  2.80it/s, loss=0.0334]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9552/44303 [56:49<3:26:32,  2.80it/s, loss=0.0334]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9552/44303 [56:49<3:26:32,  2.80it/s, loss=0.0266]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9553/44303 [56:49<3:26:21,  2.81it/s, loss=0.0266]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9553/44303 [56:49<3:26:21,  2.81it/s, loss=0.0743]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9554/44303 [56:49<3:26:06,  2.81it/s, loss=0.0743]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9554/44303 [56:50<3:26:06,  2.81it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9555/44303 [56:50<3:26:00,  2.81it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9555/44303 [56:50<3:26:00,  2.81it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9556/44303 [56:50<3:26:01,  2.81it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9556/44303 [56:51<3:26:01,  2.81it/s, loss=0.0296]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9557/44303 [56:51<3:26:42,  2.80it/s, loss=0.0296]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9557/44303 [56:51<3:26:42,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9558/44303 [56:51<3:26:33,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9558/44303 [56:51<3:26:33,  2.80it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9559/44303 [56:51<3:26:50,  2.80it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9559/44303 [56:52<3:26:50,  2.80it/s, loss=0.0679]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9560/44303 [56:52<3:26:07,  2.81it/s, loss=0.0679]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9560/44303 [56:52<3:26:07,  2.81it/s, loss=0.0733]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9561/44303 [56:52<3:26:36,  2.80it/s, loss=0.0733]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9561/44303 [56:52<3:26:36,  2.80it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9562/44303 [56:52<3:25:45,  2.81it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9562/44303 [56:53<3:25:45,  2.81it/s, loss=0.116] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9563/44303 [56:53<3:25:58,  2.81it/s, loss=0.116]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9563/44303 [56:53<3:25:58,  2.81it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9564/44303 [56:53<3:25:51,  2.81it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9564/44303 [56:53<3:25:51,  2.81it/s, loss=0.105] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9565/44303 [56:53<3:25:58,  2.81it/s, loss=0.105]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9565/44303 [56:54<3:25:58,  2.81it/s, loss=0.0305]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9566/44303 [56:54<3:25:52,  2.81it/s, loss=0.0305]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9566/44303 [56:54<3:25:52,  2.81it/s, loss=0.1]   \u001b[A\n","Training Epoch 1:  22%|██▏       | 9567/44303 [56:54<3:26:07,  2.81it/s, loss=0.1]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9567/44303 [56:54<3:26:07,  2.81it/s, loss=0.0727]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9568/44303 [56:54<3:26:37,  2.80it/s, loss=0.0727]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9568/44303 [56:55<3:26:37,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9569/44303 [56:55<3:26:32,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9569/44303 [56:55<3:26:32,  2.80it/s, loss=0.083] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9570/44303 [56:55<3:26:20,  2.81it/s, loss=0.083]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9570/44303 [56:56<3:26:20,  2.81it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9571/44303 [56:56<3:27:01,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9571/44303 [56:56<3:27:01,  2.80it/s, loss=0.0919]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9572/44303 [56:56<3:26:07,  2.81it/s, loss=0.0919]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9572/44303 [56:56<3:26:07,  2.81it/s, loss=0.069] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9573/44303 [56:56<3:26:33,  2.80it/s, loss=0.069]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9573/44303 [56:57<3:26:33,  2.80it/s, loss=0.0884]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9574/44303 [56:57<3:25:47,  2.81it/s, loss=0.0884]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9574/44303 [56:57<3:25:47,  2.81it/s, loss=0.0461]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9575/44303 [56:57<3:26:11,  2.81it/s, loss=0.0461]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9575/44303 [56:57<3:26:11,  2.81it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9576/44303 [56:57<3:25:42,  2.81it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9576/44303 [56:58<3:25:42,  2.81it/s, loss=0.0982]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9577/44303 [56:58<3:25:59,  2.81it/s, loss=0.0982]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9577/44303 [56:58<3:25:59,  2.81it/s, loss=0.0997]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9578/44303 [56:58<3:25:58,  2.81it/s, loss=0.0997]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9578/44303 [56:58<3:25:58,  2.81it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9579/44303 [56:58<3:25:38,  2.81it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9579/44303 [56:59<3:25:38,  2.81it/s, loss=0.0295]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9580/44303 [56:59<3:25:27,  2.82it/s, loss=0.0295]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9580/44303 [56:59<3:25:27,  2.82it/s, loss=0.157] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9581/44303 [56:59<3:26:15,  2.81it/s, loss=0.157]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9581/44303 [56:59<3:26:15,  2.81it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9582/44303 [56:59<3:26:48,  2.80it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9582/44303 [57:00<3:26:48,  2.80it/s, loss=0.0313]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9583/44303 [57:00<3:26:50,  2.80it/s, loss=0.0313]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9583/44303 [57:00<3:26:50,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9584/44303 [57:00<3:27:02,  2.79it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9584/44303 [57:01<3:27:02,  2.79it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9585/44303 [57:01<3:26:55,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9585/44303 [57:01<3:26:55,  2.80it/s, loss=0.0908]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9586/44303 [57:01<3:26:44,  2.80it/s, loss=0.0908]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9586/44303 [57:01<3:26:44,  2.80it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9587/44303 [57:01<3:26:08,  2.81it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9587/44303 [57:02<3:26:08,  2.81it/s, loss=0.134] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9588/44303 [57:02<3:26:20,  2.80it/s, loss=0.134]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9588/44303 [57:02<3:26:20,  2.80it/s, loss=0.0291]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9589/44303 [57:02<3:26:26,  2.80it/s, loss=0.0291]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9589/44303 [57:02<3:26:26,  2.80it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9590/44303 [57:02<3:26:41,  2.80it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9590/44303 [57:03<3:26:41,  2.80it/s, loss=0.0856]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9591/44303 [57:03<3:26:08,  2.81it/s, loss=0.0856]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9591/44303 [57:03<3:26:08,  2.81it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9592/44303 [57:03<3:26:16,  2.80it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9592/44303 [57:03<3:26:16,  2.80it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9593/44303 [57:03<3:26:25,  2.80it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9593/44303 [57:04<3:26:25,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9594/44303 [57:04<3:26:28,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9594/44303 [57:04<3:26:28,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9595/44303 [57:04<3:26:37,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9595/44303 [57:04<3:26:37,  2.80it/s, loss=0.0868]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9596/44303 [57:04<3:26:11,  2.81it/s, loss=0.0868]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9596/44303 [57:05<3:26:11,  2.81it/s, loss=0.0318]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9597/44303 [57:05<3:26:39,  2.80it/s, loss=0.0318]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9597/44303 [57:05<3:26:39,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9598/44303 [57:05<3:27:37,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9598/44303 [57:06<3:27:37,  2.79it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9599/44303 [57:06<3:26:36,  2.80it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9599/44303 [57:06<3:26:36,  2.80it/s, loss=0.0873]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9600/44303 [57:06<3:27:02,  2.79it/s, loss=0.0873]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9600/44303 [57:06<3:27:02,  2.79it/s, loss=0.0975]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9601/44303 [57:06<3:26:07,  2.81it/s, loss=0.0975]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9601/44303 [57:07<3:26:07,  2.81it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9602/44303 [57:07<3:26:14,  2.80it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9602/44303 [57:07<3:26:14,  2.80it/s, loss=0.0281]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9603/44303 [57:07<3:26:18,  2.80it/s, loss=0.0281]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9603/44303 [57:07<3:26:18,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9604/44303 [57:07<3:26:11,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9604/44303 [57:08<3:26:11,  2.80it/s, loss=0.0726]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9605/44303 [57:08<3:26:35,  2.80it/s, loss=0.0726]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9605/44303 [57:08<3:26:35,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9606/44303 [57:08<3:26:17,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9606/44303 [57:08<3:26:17,  2.80it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9607/44303 [57:08<3:26:37,  2.80it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9607/44303 [57:09<3:26:37,  2.80it/s, loss=0.0299]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9608/44303 [57:09<3:25:45,  2.81it/s, loss=0.0299]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9608/44303 [57:09<3:25:45,  2.81it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9609/44303 [57:09<3:25:46,  2.81it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9609/44303 [57:09<3:25:46,  2.81it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9610/44303 [57:09<3:26:33,  2.80it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9610/44303 [57:10<3:26:33,  2.80it/s, loss=0.0856]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9611/44303 [57:10<3:26:07,  2.81it/s, loss=0.0856]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9611/44303 [57:10<3:26:07,  2.81it/s, loss=0.0387]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9612/44303 [57:10<3:26:16,  2.80it/s, loss=0.0387]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9612/44303 [57:11<3:26:16,  2.80it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9613/44303 [57:11<3:26:14,  2.80it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9613/44303 [57:11<3:26:14,  2.80it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9614/44303 [57:11<3:26:14,  2.80it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9614/44303 [57:11<3:26:14,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9615/44303 [57:11<3:26:14,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9615/44303 [57:12<3:26:14,  2.80it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9616/44303 [57:12<3:26:40,  2.80it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9616/44303 [57:12<3:26:40,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9617/44303 [57:12<3:26:34,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9617/44303 [57:12<3:26:34,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9618/44303 [57:12<3:26:24,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9618/44303 [57:13<3:26:24,  2.80it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9619/44303 [57:13<3:25:54,  2.81it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9619/44303 [57:13<3:25:54,  2.81it/s, loss=0.248] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9620/44303 [57:13<3:26:19,  2.80it/s, loss=0.248]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9620/44303 [57:13<3:26:19,  2.80it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9621/44303 [57:13<3:25:41,  2.81it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9621/44303 [57:14<3:25:41,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9622/44303 [57:14<3:25:55,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9622/44303 [57:14<3:25:55,  2.81it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9623/44303 [57:14<3:26:03,  2.81it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9623/44303 [57:14<3:26:03,  2.81it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9624/44303 [57:14<3:25:42,  2.81it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9624/44303 [57:15<3:25:42,  2.81it/s, loss=0.0775]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9625/44303 [57:15<3:26:09,  2.80it/s, loss=0.0775]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9625/44303 [57:15<3:26:09,  2.80it/s, loss=0.025] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9626/44303 [57:15<3:25:48,  2.81it/s, loss=0.025]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9626/44303 [57:16<3:25:48,  2.81it/s, loss=0.0881]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9627/44303 [57:16<3:25:42,  2.81it/s, loss=0.0881]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9627/44303 [57:16<3:25:42,  2.81it/s, loss=0.0692]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9628/44303 [57:16<3:25:05,  2.82it/s, loss=0.0692]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9628/44303 [57:16<3:25:05,  2.82it/s, loss=0.139] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9629/44303 [57:16<3:25:48,  2.81it/s, loss=0.139]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9629/44303 [57:17<3:25:48,  2.81it/s, loss=0.127]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9630/44303 [57:17<3:26:23,  2.80it/s, loss=0.127]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9630/44303 [57:17<3:26:23,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9631/44303 [57:17<3:26:22,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9631/44303 [57:17<3:26:22,  2.80it/s, loss=0.0419]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9632/44303 [57:17<3:26:34,  2.80it/s, loss=0.0419]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9632/44303 [57:18<3:26:34,  2.80it/s, loss=0.0934]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9633/44303 [57:18<3:26:32,  2.80it/s, loss=0.0934]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9633/44303 [57:18<3:26:32,  2.80it/s, loss=0.113] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9634/44303 [57:18<3:26:29,  2.80it/s, loss=0.113]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9634/44303 [57:18<3:26:29,  2.80it/s, loss=0.0928]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9635/44303 [57:18<3:26:54,  2.79it/s, loss=0.0928]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9635/44303 [57:19<3:26:54,  2.79it/s, loss=0.0345]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9636/44303 [57:19<3:26:25,  2.80it/s, loss=0.0345]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9636/44303 [57:19<3:26:25,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9637/44303 [57:19<3:25:36,  2.81it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9637/44303 [57:19<3:25:36,  2.81it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9638/44303 [57:19<3:25:38,  2.81it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9638/44303 [57:20<3:25:38,  2.81it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9639/44303 [57:20<3:25:38,  2.81it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9639/44303 [57:20<3:25:38,  2.81it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9640/44303 [57:20<3:26:49,  2.79it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9640/44303 [57:21<3:26:49,  2.79it/s, loss=0.0887]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9641/44303 [57:21<3:26:20,  2.80it/s, loss=0.0887]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9641/44303 [57:21<3:26:20,  2.80it/s, loss=0.067] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9642/44303 [57:21<3:25:58,  2.80it/s, loss=0.067]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9642/44303 [57:21<3:25:58,  2.80it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9643/44303 [57:21<3:26:21,  2.80it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9643/44303 [57:22<3:26:21,  2.80it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9644/44303 [57:22<3:25:42,  2.81it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9644/44303 [57:22<3:25:42,  2.81it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9645/44303 [57:22<3:26:06,  2.80it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9645/44303 [57:22<3:26:06,  2.80it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9646/44303 [57:22<3:25:24,  2.81it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9646/44303 [57:23<3:25:24,  2.81it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9647/44303 [57:23<3:25:24,  2.81it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9647/44303 [57:23<3:25:24,  2.81it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9648/44303 [57:23<3:25:16,  2.81it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9648/44303 [57:23<3:25:16,  2.81it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9649/44303 [57:23<3:25:17,  2.81it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9649/44303 [57:24<3:25:17,  2.81it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9650/44303 [57:24<3:26:25,  2.80it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9650/44303 [57:24<3:26:25,  2.80it/s, loss=0.0885]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9651/44303 [57:24<3:25:55,  2.80it/s, loss=0.0885]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9651/44303 [57:24<3:25:55,  2.80it/s, loss=0.0761]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9652/44303 [57:24<3:26:36,  2.80it/s, loss=0.0761]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9652/44303 [57:25<3:26:36,  2.80it/s, loss=0.05]  \u001b[A\n","Training Epoch 1:  22%|██▏       | 9653/44303 [57:25<3:26:47,  2.79it/s, loss=0.05]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9653/44303 [57:25<3:26:47,  2.79it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9654/44303 [57:25<3:26:17,  2.80it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9654/44303 [57:26<3:26:17,  2.80it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9655/44303 [57:26<3:26:24,  2.80it/s, loss=0.0494]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9655/44303 [57:26<3:26:24,  2.80it/s, loss=0.0265]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9656/44303 [57:26<3:26:18,  2.80it/s, loss=0.0265]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9656/44303 [57:26<3:26:18,  2.80it/s, loss=0.0893]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9657/44303 [57:26<3:25:55,  2.80it/s, loss=0.0893]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9657/44303 [57:27<3:25:55,  2.80it/s, loss=0.0364]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9658/44303 [57:27<3:25:43,  2.81it/s, loss=0.0364]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9658/44303 [57:27<3:25:43,  2.81it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9659/44303 [57:27<3:25:58,  2.80it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9659/44303 [57:27<3:25:58,  2.80it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9660/44303 [57:27<3:26:20,  2.80it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9660/44303 [57:28<3:26:20,  2.80it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9661/44303 [57:28<3:26:05,  2.80it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9661/44303 [57:28<3:26:05,  2.80it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9662/44303 [57:28<3:25:35,  2.81it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9662/44303 [57:28<3:25:35,  2.81it/s, loss=0.055] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9663/44303 [57:28<3:26:18,  2.80it/s, loss=0.055]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9663/44303 [57:29<3:26:18,  2.80it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9664/44303 [57:29<3:26:04,  2.80it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9664/44303 [57:29<3:26:04,  2.80it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9665/44303 [57:29<3:25:49,  2.80it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9665/44303 [57:29<3:25:49,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9666/44303 [57:29<3:26:45,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9666/44303 [57:30<3:26:45,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9667/44303 [57:30<3:26:57,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9667/44303 [57:30<3:26:57,  2.79it/s, loss=0.0598]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9668/44303 [57:30<3:26:10,  2.80it/s, loss=0.0598]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9668/44303 [57:31<3:26:10,  2.80it/s, loss=0.036] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9669/44303 [57:31<3:26:29,  2.80it/s, loss=0.036]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9669/44303 [57:31<3:26:29,  2.80it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9670/44303 [57:31<3:26:38,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9670/44303 [57:31<3:26:38,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9671/44303 [57:31<3:25:38,  2.81it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9671/44303 [57:32<3:25:38,  2.81it/s, loss=0.0637]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9672/44303 [57:32<3:26:38,  2.79it/s, loss=0.0637]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9672/44303 [57:32<3:26:38,  2.79it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9673/44303 [57:32<3:25:36,  2.81it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9673/44303 [57:32<3:25:36,  2.81it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9674/44303 [57:32<3:26:00,  2.80it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9674/44303 [57:33<3:26:00,  2.80it/s, loss=0.075] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9675/44303 [57:33<3:26:06,  2.80it/s, loss=0.075]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9675/44303 [57:33<3:26:06,  2.80it/s, loss=0.0823]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9676/44303 [57:33<3:25:40,  2.81it/s, loss=0.0823]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9676/44303 [57:33<3:25:40,  2.81it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9677/44303 [57:33<3:26:07,  2.80it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9677/44303 [57:34<3:26:07,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9678/44303 [57:34<3:26:23,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9678/44303 [57:34<3:26:23,  2.80it/s, loss=0.0715]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9679/44303 [57:34<3:26:21,  2.80it/s, loss=0.0715]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9679/44303 [57:34<3:26:21,  2.80it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9680/44303 [57:34<3:26:52,  2.79it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9680/44303 [57:35<3:26:52,  2.79it/s, loss=0.0444]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9681/44303 [57:35<3:27:14,  2.78it/s, loss=0.0444]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9681/44303 [57:35<3:27:14,  2.78it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9682/44303 [57:35<3:26:13,  2.80it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9682/44303 [57:36<3:26:13,  2.80it/s, loss=0.0883]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9683/44303 [57:36<3:26:44,  2.79it/s, loss=0.0883]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9683/44303 [57:36<3:26:44,  2.79it/s, loss=0.0355]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9684/44303 [57:36<3:26:21,  2.80it/s, loss=0.0355]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9684/44303 [57:36<3:26:21,  2.80it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9685/44303 [57:36<3:26:10,  2.80it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9685/44303 [57:37<3:26:10,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9686/44303 [57:37<3:26:12,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9686/44303 [57:37<3:26:12,  2.80it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9687/44303 [57:37<3:25:30,  2.81it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9687/44303 [57:37<3:25:30,  2.81it/s, loss=0.0788]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9688/44303 [57:37<3:25:27,  2.81it/s, loss=0.0788]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9688/44303 [57:38<3:25:27,  2.81it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9689/44303 [57:38<3:25:23,  2.81it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9689/44303 [57:38<3:25:23,  2.81it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9690/44303 [57:38<3:25:53,  2.80it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9690/44303 [57:38<3:25:53,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9691/44303 [57:38<3:25:48,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9691/44303 [57:39<3:25:48,  2.80it/s, loss=0.0317]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9692/44303 [57:39<3:25:31,  2.81it/s, loss=0.0317]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9692/44303 [57:39<3:25:31,  2.81it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9693/44303 [57:39<3:25:48,  2.80it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9693/44303 [57:39<3:25:48,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9694/44303 [57:39<3:25:49,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9694/44303 [57:40<3:25:49,  2.80it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9695/44303 [57:40<3:25:52,  2.80it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9695/44303 [57:40<3:25:52,  2.80it/s, loss=0.0861]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9696/44303 [57:40<3:26:22,  2.79it/s, loss=0.0861]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9696/44303 [57:41<3:26:22,  2.79it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9697/44303 [57:41<3:26:39,  2.79it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9697/44303 [57:41<3:26:39,  2.79it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9698/44303 [57:41<3:25:44,  2.80it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9698/44303 [57:41<3:25:44,  2.80it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9699/44303 [57:41<3:26:29,  2.79it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9699/44303 [57:42<3:26:29,  2.79it/s, loss=0.0935]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9700/44303 [57:42<3:26:16,  2.80it/s, loss=0.0935]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9700/44303 [57:42<3:26:16,  2.80it/s, loss=0.0356]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9701/44303 [57:42<3:25:39,  2.80it/s, loss=0.0356]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9701/44303 [57:42<3:25:39,  2.80it/s, loss=0.0977]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9702/44303 [57:42<3:26:32,  2.79it/s, loss=0.0977]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9702/44303 [57:43<3:26:32,  2.79it/s, loss=0.0911]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9703/44303 [57:43<3:25:27,  2.81it/s, loss=0.0911]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9703/44303 [57:43<3:25:27,  2.81it/s, loss=0.0276]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9704/44303 [57:43<3:25:48,  2.80it/s, loss=0.0276]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9704/44303 [57:43<3:25:48,  2.80it/s, loss=0.028] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9705/44303 [57:43<3:26:41,  2.79it/s, loss=0.028]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9705/44303 [57:44<3:26:41,  2.79it/s, loss=0.08] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9706/44303 [57:44<3:25:53,  2.80it/s, loss=0.08]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9706/44303 [57:44<3:25:53,  2.80it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9707/44303 [57:44<3:25:54,  2.80it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9707/44303 [57:44<3:25:54,  2.80it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9708/44303 [57:44<3:26:36,  2.79it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9708/44303 [57:45<3:26:36,  2.79it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9709/44303 [57:45<3:25:46,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9709/44303 [57:45<3:25:46,  2.80it/s, loss=0.0267]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9710/44303 [57:45<3:26:09,  2.80it/s, loss=0.0267]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9710/44303 [57:46<3:26:09,  2.80it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9711/44303 [57:46<3:26:37,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9711/44303 [57:46<3:26:37,  2.79it/s, loss=0.0641]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9712/44303 [57:46<3:25:59,  2.80it/s, loss=0.0641]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9712/44303 [57:46<3:25:59,  2.80it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9713/44303 [57:46<3:26:02,  2.80it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9713/44303 [57:47<3:26:02,  2.80it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9714/44303 [57:47<3:26:19,  2.79it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9714/44303 [57:47<3:26:19,  2.79it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9715/44303 [57:47<3:25:23,  2.81it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9715/44303 [57:47<3:25:23,  2.81it/s, loss=0.0313]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9716/44303 [57:47<3:26:15,  2.79it/s, loss=0.0313]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9716/44303 [57:48<3:26:15,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9717/44303 [57:48<3:26:37,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9717/44303 [57:48<3:26:37,  2.79it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9718/44303 [57:48<3:26:08,  2.80it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9718/44303 [57:48<3:26:08,  2.80it/s, loss=0.0706]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9719/44303 [57:48<3:26:01,  2.80it/s, loss=0.0706]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9719/44303 [57:49<3:26:01,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9720/44303 [57:49<3:26:00,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9720/44303 [57:49<3:26:00,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9721/44303 [57:49<3:25:33,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9721/44303 [57:49<3:25:33,  2.80it/s, loss=0.0429]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9722/44303 [57:49<3:25:45,  2.80it/s, loss=0.0429]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9722/44303 [57:50<3:25:45,  2.80it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9723/44303 [57:50<3:25:31,  2.80it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9723/44303 [57:50<3:25:31,  2.80it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9724/44303 [57:50<3:26:02,  2.80it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9724/44303 [57:51<3:26:02,  2.80it/s, loss=0.0968]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9725/44303 [57:51<3:26:43,  2.79it/s, loss=0.0968]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9725/44303 [57:51<3:26:43,  2.79it/s, loss=0.0641]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9726/44303 [57:51<3:26:28,  2.79it/s, loss=0.0641]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9726/44303 [57:51<3:26:28,  2.79it/s, loss=0.0458]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9727/44303 [57:51<3:27:05,  2.78it/s, loss=0.0458]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9727/44303 [57:52<3:27:05,  2.78it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9728/44303 [57:52<3:26:44,  2.79it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9728/44303 [57:52<3:26:44,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9729/44303 [57:52<3:26:17,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9729/44303 [57:52<3:26:17,  2.79it/s, loss=0.0361]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9730/44303 [57:52<3:26:03,  2.80it/s, loss=0.0361]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9730/44303 [57:53<3:26:03,  2.80it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9731/44303 [57:53<3:26:17,  2.79it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9731/44303 [57:53<3:26:17,  2.79it/s, loss=0.0289]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9732/44303 [57:53<3:26:29,  2.79it/s, loss=0.0289]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9732/44303 [57:53<3:26:29,  2.79it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9733/44303 [57:53<3:26:12,  2.79it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9733/44303 [57:54<3:26:12,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9734/44303 [57:54<3:26:46,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9734/44303 [57:54<3:26:46,  2.79it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9735/44303 [57:54<3:26:07,  2.79it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9735/44303 [57:54<3:26:07,  2.79it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9736/44303 [57:54<3:26:15,  2.79it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9736/44303 [57:55<3:26:15,  2.79it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9737/44303 [57:55<3:26:16,  2.79it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9737/44303 [57:55<3:26:16,  2.79it/s, loss=0.0812]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9738/44303 [57:55<3:25:54,  2.80it/s, loss=0.0812]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9738/44303 [57:56<3:25:54,  2.80it/s, loss=0.046] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9739/44303 [57:56<3:25:28,  2.80it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9739/44303 [57:56<3:25:28,  2.80it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9740/44303 [57:56<3:26:05,  2.80it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9740/44303 [57:56<3:26:05,  2.80it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9741/44303 [57:56<3:24:40,  2.81it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9741/44303 [57:57<3:24:40,  2.81it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9742/44303 [57:57<3:25:12,  2.81it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9742/44303 [57:57<3:25:12,  2.81it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9743/44303 [57:57<3:25:26,  2.80it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9743/44303 [57:57<3:25:26,  2.80it/s, loss=0.147] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9744/44303 [57:57<3:25:30,  2.80it/s, loss=0.147]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9744/44303 [57:58<3:25:30,  2.80it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9745/44303 [57:58<3:25:40,  2.80it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9745/44303 [57:58<3:25:40,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9746/44303 [57:58<3:26:05,  2.79it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9746/44303 [57:58<3:26:05,  2.79it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9747/44303 [57:58<3:25:51,  2.80it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9747/44303 [57:59<3:25:51,  2.80it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9748/44303 [57:59<3:26:13,  2.79it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9748/44303 [57:59<3:26:13,  2.79it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9749/44303 [57:59<3:26:00,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9749/44303 [57:59<3:26:00,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9750/44303 [57:59<3:26:06,  2.79it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9750/44303 [58:00<3:26:06,  2.79it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9751/44303 [58:00<3:26:31,  2.79it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9751/44303 [58:00<3:26:31,  2.79it/s, loss=0.276] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9752/44303 [58:00<3:26:33,  2.79it/s, loss=0.276]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9752/44303 [58:01<3:26:33,  2.79it/s, loss=0.0347]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9753/44303 [58:01<3:26:33,  2.79it/s, loss=0.0347]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9753/44303 [58:01<3:26:33,  2.79it/s, loss=0.0349]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9754/44303 [58:01<3:26:17,  2.79it/s, loss=0.0349]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9754/44303 [58:01<3:26:17,  2.79it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9755/44303 [58:01<3:25:25,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9755/44303 [58:02<3:25:25,  2.80it/s, loss=0.116] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9756/44303 [58:02<3:25:14,  2.81it/s, loss=0.116]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9756/44303 [58:02<3:25:14,  2.81it/s, loss=0.057]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9757/44303 [58:02<3:25:05,  2.81it/s, loss=0.057]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9757/44303 [58:02<3:25:05,  2.81it/s, loss=0.0737]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9758/44303 [58:02<3:24:53,  2.81it/s, loss=0.0737]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9758/44303 [58:03<3:24:53,  2.81it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9759/44303 [58:03<3:24:51,  2.81it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9759/44303 [58:03<3:24:51,  2.81it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9760/44303 [58:03<3:24:57,  2.81it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9760/44303 [58:03<3:24:57,  2.81it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9761/44303 [58:03<3:25:33,  2.80it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9761/44303 [58:04<3:25:33,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9762/44303 [58:04<3:25:17,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9762/44303 [58:04<3:25:17,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9763/44303 [58:04<3:25:36,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9763/44303 [58:04<3:25:36,  2.80it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9764/44303 [58:04<3:24:43,  2.81it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9764/44303 [58:05<3:24:43,  2.81it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9765/44303 [58:05<3:25:25,  2.80it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9765/44303 [58:05<3:25:25,  2.80it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9766/44303 [58:05<3:24:58,  2.81it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9766/44303 [58:06<3:24:58,  2.81it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9767/44303 [58:06<3:25:00,  2.81it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9767/44303 [58:06<3:25:00,  2.81it/s, loss=0.0961]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9768/44303 [58:06<3:25:38,  2.80it/s, loss=0.0961]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9768/44303 [58:06<3:25:38,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9769/44303 [58:06<3:25:33,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9769/44303 [58:07<3:25:33,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9770/44303 [58:07<3:25:49,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9770/44303 [58:07<3:25:49,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9771/44303 [58:07<3:25:25,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9771/44303 [58:07<3:25:25,  2.80it/s, loss=0.0854]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9772/44303 [58:07<3:25:58,  2.79it/s, loss=0.0854]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9772/44303 [58:08<3:25:58,  2.79it/s, loss=0.022] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9773/44303 [58:08<3:25:52,  2.80it/s, loss=0.022]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9773/44303 [58:08<3:25:52,  2.80it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9774/44303 [58:08<3:25:25,  2.80it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9774/44303 [58:08<3:25:25,  2.80it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9775/44303 [58:08<3:25:29,  2.80it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9775/44303 [58:09<3:25:29,  2.80it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9776/44303 [58:09<3:26:12,  2.79it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9776/44303 [58:09<3:26:12,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9777/44303 [58:09<3:26:06,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9777/44303 [58:09<3:26:06,  2.79it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9778/44303 [58:09<3:26:49,  2.78it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9778/44303 [58:10<3:26:49,  2.78it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9779/44303 [58:10<3:26:31,  2.79it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9779/44303 [58:10<3:26:31,  2.79it/s, loss=0.0349]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9780/44303 [58:10<3:25:41,  2.80it/s, loss=0.0349]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9780/44303 [58:11<3:25:41,  2.80it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9781/44303 [58:11<3:26:00,  2.79it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9781/44303 [58:11<3:26:00,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9782/44303 [58:11<3:25:53,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9782/44303 [58:11<3:25:53,  2.79it/s, loss=0.0937]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9783/44303 [58:11<3:25:47,  2.80it/s, loss=0.0937]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9783/44303 [58:12<3:25:47,  2.80it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9784/44303 [58:12<3:26:26,  2.79it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9784/44303 [58:12<3:26:26,  2.79it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9785/44303 [58:12<3:25:06,  2.80it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9785/44303 [58:12<3:25:06,  2.80it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9786/44303 [58:12<3:25:53,  2.79it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9786/44303 [58:13<3:25:53,  2.79it/s, loss=0.0888]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9787/44303 [58:13<3:26:09,  2.79it/s, loss=0.0888]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9787/44303 [58:13<3:26:09,  2.79it/s, loss=0.095] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9788/44303 [58:13<3:25:40,  2.80it/s, loss=0.095]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9788/44303 [58:13<3:25:40,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9789/44303 [58:13<3:25:50,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9789/44303 [58:14<3:25:50,  2.79it/s, loss=0.052] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9790/44303 [58:14<3:26:25,  2.79it/s, loss=0.052]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9790/44303 [58:14<3:26:25,  2.79it/s, loss=0.0419]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9791/44303 [58:14<3:25:30,  2.80it/s, loss=0.0419]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9791/44303 [58:14<3:25:30,  2.80it/s, loss=0.0701]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9792/44303 [58:14<3:25:33,  2.80it/s, loss=0.0701]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9792/44303 [58:15<3:25:33,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9793/44303 [58:15<3:25:37,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9793/44303 [58:15<3:25:37,  2.80it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9794/44303 [58:15<3:25:19,  2.80it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9794/44303 [58:16<3:25:19,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9795/44303 [58:16<3:26:00,  2.79it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9795/44303 [58:16<3:26:00,  2.79it/s, loss=0.0615]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9796/44303 [58:16<3:25:40,  2.80it/s, loss=0.0615]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9796/44303 [58:16<3:25:40,  2.80it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9797/44303 [58:16<3:26:17,  2.79it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9797/44303 [58:17<3:26:17,  2.79it/s, loss=0.03]  \u001b[A\n","Training Epoch 1:  22%|██▏       | 9798/44303 [58:17<3:26:08,  2.79it/s, loss=0.03]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9798/44303 [58:17<3:26:08,  2.79it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9799/44303 [58:17<3:25:46,  2.79it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9799/44303 [58:17<3:25:46,  2.79it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9800/44303 [58:17<3:25:12,  2.80it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9800/44303 [58:18<3:25:12,  2.80it/s, loss=0.038] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9801/44303 [58:18<3:25:14,  2.80it/s, loss=0.038]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9801/44303 [58:18<3:25:14,  2.80it/s, loss=0.0696]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9802/44303 [58:18<3:24:58,  2.81it/s, loss=0.0696]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9802/44303 [58:18<3:24:58,  2.81it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9803/44303 [58:18<3:25:23,  2.80it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9803/44303 [58:19<3:25:23,  2.80it/s, loss=0.0929]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9804/44303 [58:19<3:25:40,  2.80it/s, loss=0.0929]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9804/44303 [58:19<3:25:40,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9805/44303 [58:19<3:25:50,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9805/44303 [58:19<3:25:50,  2.79it/s, loss=0.068] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9806/44303 [58:19<3:25:47,  2.79it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9806/44303 [58:20<3:25:47,  2.79it/s, loss=0.0962]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9807/44303 [58:20<3:26:00,  2.79it/s, loss=0.0962]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9807/44303 [58:20<3:26:00,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9808/44303 [58:20<3:26:01,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9808/44303 [58:21<3:26:01,  2.79it/s, loss=0.0902]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9809/44303 [58:21<3:25:29,  2.80it/s, loss=0.0902]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9809/44303 [58:21<3:25:29,  2.80it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9810/44303 [58:21<3:26:03,  2.79it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9810/44303 [58:21<3:26:03,  2.79it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9811/44303 [58:21<3:26:06,  2.79it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9811/44303 [58:22<3:26:06,  2.79it/s, loss=0.0782]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9812/44303 [58:22<3:25:43,  2.79it/s, loss=0.0782]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9812/44303 [58:22<3:25:43,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9813/44303 [58:22<3:26:06,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9813/44303 [58:22<3:26:06,  2.79it/s, loss=0.0497]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9814/44303 [58:22<3:25:42,  2.79it/s, loss=0.0497]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9814/44303 [58:23<3:25:42,  2.79it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9815/44303 [58:23<3:26:05,  2.79it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9815/44303 [58:23<3:26:05,  2.79it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9816/44303 [58:23<3:25:59,  2.79it/s, loss=0.0369]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9816/44303 [58:23<3:25:59,  2.79it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9817/44303 [58:23<3:26:09,  2.79it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9817/44303 [58:24<3:26:09,  2.79it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9818/44303 [58:24<3:25:45,  2.79it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9818/44303 [58:24<3:25:45,  2.79it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9819/44303 [58:24<3:25:15,  2.80it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9819/44303 [58:24<3:25:15,  2.80it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9820/44303 [58:24<3:25:31,  2.80it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9820/44303 [58:25<3:25:31,  2.80it/s, loss=0.0517]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9821/44303 [58:25<3:25:58,  2.79it/s, loss=0.0517]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9821/44303 [58:25<3:25:58,  2.79it/s, loss=0.0407]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9822/44303 [58:25<3:25:52,  2.79it/s, loss=0.0407]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9822/44303 [58:26<3:25:52,  2.79it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9823/44303 [58:26<3:25:45,  2.79it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9823/44303 [58:26<3:25:45,  2.79it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9824/44303 [58:26<3:25:54,  2.79it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9824/44303 [58:26<3:25:54,  2.79it/s, loss=0.0339]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9825/44303 [58:26<3:25:50,  2.79it/s, loss=0.0339]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9825/44303 [58:27<3:25:50,  2.79it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9826/44303 [58:27<3:25:55,  2.79it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9826/44303 [58:27<3:25:55,  2.79it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9827/44303 [58:27<3:25:25,  2.80it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9827/44303 [58:27<3:25:25,  2.80it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9828/44303 [58:27<3:25:09,  2.80it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9828/44303 [58:28<3:25:09,  2.80it/s, loss=0.0691]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9829/44303 [58:28<3:25:17,  2.80it/s, loss=0.0691]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9829/44303 [58:28<3:25:17,  2.80it/s, loss=0.0323]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9830/44303 [58:28<3:24:49,  2.81it/s, loss=0.0323]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9830/44303 [58:28<3:24:49,  2.81it/s, loss=0.0834]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9831/44303 [58:28<3:25:16,  2.80it/s, loss=0.0834]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9831/44303 [58:29<3:25:16,  2.80it/s, loss=0.0258]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9832/44303 [58:29<3:25:35,  2.79it/s, loss=0.0258]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9832/44303 [58:29<3:25:35,  2.79it/s, loss=0.163] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9833/44303 [58:29<3:25:13,  2.80it/s, loss=0.163]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9833/44303 [58:29<3:25:13,  2.80it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9834/44303 [58:29<3:25:25,  2.80it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9834/44303 [58:30<3:25:25,  2.80it/s, loss=0.0465]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9835/44303 [58:30<3:25:43,  2.79it/s, loss=0.0465]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9835/44303 [58:30<3:25:43,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9836/44303 [58:30<3:25:39,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9836/44303 [58:31<3:25:39,  2.79it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9837/44303 [58:31<3:25:18,  2.80it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9837/44303 [58:31<3:25:18,  2.80it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9838/44303 [58:31<3:25:53,  2.79it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9838/44303 [58:31<3:25:53,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9839/44303 [58:31<3:26:02,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9839/44303 [58:32<3:26:02,  2.79it/s, loss=0.106] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9840/44303 [58:32<3:25:48,  2.79it/s, loss=0.106]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9840/44303 [58:32<3:25:48,  2.79it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9841/44303 [58:32<3:26:15,  2.78it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9841/44303 [58:32<3:26:15,  2.78it/s, loss=0.0807]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9842/44303 [58:32<3:26:41,  2.78it/s, loss=0.0807]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9842/44303 [58:33<3:26:41,  2.78it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9843/44303 [58:33<3:25:50,  2.79it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9843/44303 [58:33<3:25:50,  2.79it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9844/44303 [58:33<3:25:52,  2.79it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9844/44303 [58:33<3:25:52,  2.79it/s, loss=0.0346]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9845/44303 [58:33<3:25:50,  2.79it/s, loss=0.0346]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9845/44303 [58:34<3:25:50,  2.79it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9846/44303 [58:34<3:25:35,  2.79it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9846/44303 [58:34<3:25:35,  2.79it/s, loss=0.0926]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9847/44303 [58:34<3:25:11,  2.80it/s, loss=0.0926]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9847/44303 [58:35<3:25:11,  2.80it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9848/44303 [58:35<3:25:39,  2.79it/s, loss=0.0794]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9848/44303 [58:35<3:25:39,  2.79it/s, loss=0.0716]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9849/44303 [58:35<3:25:43,  2.79it/s, loss=0.0716]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9849/44303 [58:35<3:25:43,  2.79it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9850/44303 [58:35<3:25:35,  2.79it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9850/44303 [58:36<3:25:35,  2.79it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9851/44303 [58:36<3:25:47,  2.79it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9851/44303 [58:36<3:25:47,  2.79it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9852/44303 [58:36<3:25:44,  2.79it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9852/44303 [58:36<3:25:44,  2.79it/s, loss=0.0609]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9853/44303 [58:36<3:25:20,  2.80it/s, loss=0.0609]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9853/44303 [58:37<3:25:20,  2.80it/s, loss=0.0671]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9854/44303 [58:37<3:25:50,  2.79it/s, loss=0.0671]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9854/44303 [58:37<3:25:50,  2.79it/s, loss=0.0683]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9855/44303 [58:37<3:25:57,  2.79it/s, loss=0.0683]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9855/44303 [58:37<3:25:57,  2.79it/s, loss=0.0593]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9856/44303 [58:37<3:25:21,  2.80it/s, loss=0.0593]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9856/44303 [58:38<3:25:21,  2.80it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9857/44303 [58:38<3:25:46,  2.79it/s, loss=0.0586]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9857/44303 [58:38<3:25:46,  2.79it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9858/44303 [58:38<3:25:55,  2.79it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9858/44303 [58:38<3:25:55,  2.79it/s, loss=0.0754]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9859/44303 [58:38<3:25:38,  2.79it/s, loss=0.0754]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9859/44303 [58:39<3:25:38,  2.79it/s, loss=0.0681]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9860/44303 [58:39<3:25:41,  2.79it/s, loss=0.0681]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9860/44303 [58:39<3:25:41,  2.79it/s, loss=0.058] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9861/44303 [58:39<3:26:24,  2.78it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9861/44303 [58:40<3:26:24,  2.78it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9862/44303 [58:40<3:25:51,  2.79it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9862/44303 [58:40<3:25:51,  2.79it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9863/44303 [58:40<3:24:53,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9863/44303 [58:40<3:24:53,  2.80it/s, loss=0.054] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9864/44303 [58:40<3:25:22,  2.79it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9864/44303 [58:41<3:25:22,  2.79it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9865/44303 [58:41<3:24:57,  2.80it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9865/44303 [58:41<3:24:57,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9866/44303 [58:41<3:24:55,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9866/44303 [58:41<3:24:55,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9867/44303 [58:41<3:25:50,  2.79it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9867/44303 [58:42<3:25:50,  2.79it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9868/44303 [58:42<3:25:43,  2.79it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9868/44303 [58:42<3:25:43,  2.79it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9869/44303 [58:42<3:26:02,  2.79it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9869/44303 [58:42<3:26:02,  2.79it/s, loss=0.0724]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9870/44303 [58:42<3:25:51,  2.79it/s, loss=0.0724]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9870/44303 [58:43<3:25:51,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9871/44303 [58:43<3:25:33,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9871/44303 [58:43<3:25:33,  2.79it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9872/44303 [58:43<3:24:57,  2.80it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9872/44303 [58:43<3:24:57,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9873/44303 [58:43<3:25:26,  2.79it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9873/44303 [58:44<3:25:26,  2.79it/s, loss=0.0913]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9874/44303 [58:44<3:25:39,  2.79it/s, loss=0.0913]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9874/44303 [58:44<3:25:39,  2.79it/s, loss=0.0363]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9875/44303 [58:44<3:25:06,  2.80it/s, loss=0.0363]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9875/44303 [58:45<3:25:06,  2.80it/s, loss=0.0451]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9876/44303 [58:45<3:25:35,  2.79it/s, loss=0.0451]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9876/44303 [58:45<3:25:35,  2.79it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9877/44303 [58:45<3:25:57,  2.79it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9877/44303 [58:45<3:25:57,  2.79it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9878/44303 [58:45<3:25:47,  2.79it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9878/44303 [58:46<3:25:47,  2.79it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9879/44303 [58:46<3:25:26,  2.79it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9879/44303 [58:46<3:25:26,  2.79it/s, loss=0.0713]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9880/44303 [58:46<3:24:49,  2.80it/s, loss=0.0713]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9880/44303 [58:46<3:24:49,  2.80it/s, loss=0.0945]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9881/44303 [58:46<3:25:00,  2.80it/s, loss=0.0945]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9881/44303 [58:47<3:25:00,  2.80it/s, loss=0.0292]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9882/44303 [58:47<3:25:21,  2.79it/s, loss=0.0292]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9882/44303 [58:47<3:25:21,  2.79it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9883/44303 [58:47<3:24:46,  2.80it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9883/44303 [58:47<3:24:46,  2.80it/s, loss=0.0378]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9884/44303 [58:47<3:24:45,  2.80it/s, loss=0.0378]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9884/44303 [58:48<3:24:45,  2.80it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9885/44303 [58:48<3:25:00,  2.80it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9885/44303 [58:48<3:25:00,  2.80it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9886/44303 [58:48<3:24:41,  2.80it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9886/44303 [58:48<3:24:41,  2.80it/s, loss=0.0901]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9887/44303 [58:48<3:24:54,  2.80it/s, loss=0.0901]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9887/44303 [58:49<3:24:54,  2.80it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9888/44303 [58:49<3:24:22,  2.81it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9888/44303 [58:49<3:24:22,  2.81it/s, loss=0.0956]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9889/44303 [58:49<3:24:36,  2.80it/s, loss=0.0956]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9889/44303 [58:50<3:24:36,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9890/44303 [58:50<3:25:08,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9890/44303 [58:50<3:25:08,  2.80it/s, loss=0.0587]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9891/44303 [58:50<3:24:24,  2.81it/s, loss=0.0587]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9891/44303 [58:50<3:24:24,  2.81it/s, loss=0.068] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9892/44303 [58:50<3:24:50,  2.80it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9892/44303 [58:51<3:24:50,  2.80it/s, loss=0.0529]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9893/44303 [58:51<3:24:44,  2.80it/s, loss=0.0529]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9893/44303 [58:51<3:24:44,  2.80it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9894/44303 [58:51<3:24:18,  2.81it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9894/44303 [58:51<3:24:18,  2.81it/s, loss=0.0805]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9895/44303 [58:51<3:25:05,  2.80it/s, loss=0.0805]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9895/44303 [58:52<3:25:05,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9896/44303 [58:52<3:24:29,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9896/44303 [58:52<3:24:29,  2.80it/s, loss=0.0795]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9897/44303 [58:52<3:24:27,  2.80it/s, loss=0.0795]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9897/44303 [58:52<3:24:27,  2.80it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9898/44303 [58:52<3:24:39,  2.80it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9898/44303 [58:53<3:24:39,  2.80it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9899/44303 [58:53<3:24:03,  2.81it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9899/44303 [58:53<3:24:03,  2.81it/s, loss=0.0826]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9900/44303 [58:53<3:24:47,  2.80it/s, loss=0.0826]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9900/44303 [58:53<3:24:47,  2.80it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9901/44303 [58:53<3:24:12,  2.81it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9901/44303 [58:54<3:24:12,  2.81it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9902/44303 [58:54<3:24:11,  2.81it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9902/44303 [58:54<3:24:11,  2.81it/s, loss=0.0232]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9903/44303 [58:54<3:25:04,  2.80it/s, loss=0.0232]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9903/44303 [58:55<3:25:04,  2.80it/s, loss=0.0881]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9904/44303 [58:55<3:24:44,  2.80it/s, loss=0.0881]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9904/44303 [58:55<3:24:44,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9905/44303 [58:55<3:25:13,  2.79it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9905/44303 [58:55<3:25:13,  2.79it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9906/44303 [58:55<3:25:28,  2.79it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9906/44303 [58:56<3:25:28,  2.79it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9907/44303 [58:56<3:24:52,  2.80it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9907/44303 [58:56<3:24:52,  2.80it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9908/44303 [58:56<3:24:57,  2.80it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9908/44303 [58:56<3:24:57,  2.80it/s, loss=0.0287]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9909/44303 [58:56<3:24:20,  2.81it/s, loss=0.0287]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9909/44303 [58:57<3:24:20,  2.81it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9910/44303 [58:57<3:24:40,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9910/44303 [58:57<3:24:40,  2.80it/s, loss=0.045] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9911/44303 [58:57<3:25:35,  2.79it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9911/44303 [58:57<3:25:35,  2.79it/s, loss=0.151]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9912/44303 [58:57<3:25:29,  2.79it/s, loss=0.151]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9912/44303 [58:58<3:25:29,  2.79it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9913/44303 [58:58<3:25:22,  2.79it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9913/44303 [58:58<3:25:22,  2.79it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9914/44303 [58:58<3:25:26,  2.79it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9914/44303 [58:58<3:25:26,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9915/44303 [58:58<3:25:39,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9915/44303 [58:59<3:25:39,  2.79it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9916/44303 [58:59<3:24:35,  2.80it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9916/44303 [58:59<3:24:35,  2.80it/s, loss=0.0146]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9917/44303 [58:59<3:25:12,  2.79it/s, loss=0.0146]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9917/44303 [59:00<3:25:12,  2.79it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9918/44303 [59:00<3:24:17,  2.81it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9918/44303 [59:00<3:24:17,  2.81it/s, loss=0.0744]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9919/44303 [59:00<3:24:10,  2.81it/s, loss=0.0744]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9919/44303 [59:00<3:24:10,  2.81it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9920/44303 [59:00<3:24:16,  2.81it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9920/44303 [59:01<3:24:16,  2.81it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9921/44303 [59:01<3:24:18,  2.80it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9921/44303 [59:01<3:24:18,  2.80it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9922/44303 [59:01<3:24:32,  2.80it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9922/44303 [59:01<3:24:32,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9923/44303 [59:01<3:24:46,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9923/44303 [59:02<3:24:46,  2.80it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9924/44303 [59:02<3:24:41,  2.80it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9924/44303 [59:02<3:24:41,  2.80it/s, loss=0.0724]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9925/44303 [59:02<3:24:59,  2.80it/s, loss=0.0724]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9925/44303 [59:02<3:24:59,  2.80it/s, loss=0.0344]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9926/44303 [59:02<3:24:24,  2.80it/s, loss=0.0344]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9926/44303 [59:03<3:24:24,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9927/44303 [59:03<3:24:29,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9927/44303 [59:03<3:24:29,  2.80it/s, loss=0.0928]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9928/44303 [59:03<3:25:09,  2.79it/s, loss=0.0928]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9928/44303 [59:03<3:25:09,  2.79it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9929/44303 [59:03<3:24:36,  2.80it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9929/44303 [59:04<3:24:36,  2.80it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9930/44303 [59:04<3:25:04,  2.79it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9930/44303 [59:04<3:25:04,  2.79it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9931/44303 [59:04<3:24:53,  2.80it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9931/44303 [59:05<3:24:53,  2.80it/s, loss=0.069] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9932/44303 [59:05<3:25:14,  2.79it/s, loss=0.069]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9932/44303 [59:05<3:25:14,  2.79it/s, loss=0.0454]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9933/44303 [59:05<3:25:00,  2.79it/s, loss=0.0454]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9933/44303 [59:05<3:25:00,  2.79it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9934/44303 [59:05<3:25:12,  2.79it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9934/44303 [59:06<3:25:12,  2.79it/s, loss=0.0331]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9935/44303 [59:06<3:24:26,  2.80it/s, loss=0.0331]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9935/44303 [59:06<3:24:26,  2.80it/s, loss=0.036] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9936/44303 [59:06<3:25:11,  2.79it/s, loss=0.036]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9936/44303 [59:06<3:25:11,  2.79it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9937/44303 [59:06<3:25:18,  2.79it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9937/44303 [59:07<3:25:18,  2.79it/s, loss=0.0743]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9938/44303 [59:07<3:25:15,  2.79it/s, loss=0.0743]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9938/44303 [59:07<3:25:15,  2.79it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9939/44303 [59:07<3:25:53,  2.78it/s, loss=0.0309]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9939/44303 [59:07<3:25:53,  2.78it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9940/44303 [59:07<3:25:26,  2.79it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9940/44303 [59:08<3:25:26,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9941/44303 [59:08<3:25:12,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9941/44303 [59:08<3:25:12,  2.79it/s, loss=0.0461]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9942/44303 [59:08<3:25:42,  2.78it/s, loss=0.0461]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9942/44303 [59:09<3:25:42,  2.78it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9943/44303 [59:09<3:26:03,  2.78it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9943/44303 [59:09<3:26:03,  2.78it/s, loss=0.0923]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9944/44303 [59:09<3:25:36,  2.79it/s, loss=0.0923]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9944/44303 [59:09<3:25:36,  2.79it/s, loss=0.0376]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9945/44303 [59:09<3:25:08,  2.79it/s, loss=0.0376]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9945/44303 [59:10<3:25:08,  2.79it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9946/44303 [59:10<3:25:27,  2.79it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9946/44303 [59:10<3:25:27,  2.79it/s, loss=0.116] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9947/44303 [59:10<3:24:36,  2.80it/s, loss=0.116]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9947/44303 [59:10<3:24:36,  2.80it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9948/44303 [59:10<3:24:09,  2.80it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9948/44303 [59:11<3:24:09,  2.80it/s, loss=0.11]  \u001b[A\n","Training Epoch 1:  22%|██▏       | 9949/44303 [59:11<3:24:28,  2.80it/s, loss=0.11]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9949/44303 [59:11<3:24:28,  2.80it/s, loss=0.0649]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9950/44303 [59:11<3:24:15,  2.80it/s, loss=0.0649]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9950/44303 [59:11<3:24:15,  2.80it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9951/44303 [59:11<3:24:36,  2.80it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9951/44303 [59:12<3:24:36,  2.80it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9952/44303 [59:12<3:24:01,  2.81it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9952/44303 [59:12<3:24:01,  2.81it/s, loss=0.0432]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9953/44303 [59:12<3:24:36,  2.80it/s, loss=0.0432]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9953/44303 [59:12<3:24:36,  2.80it/s, loss=0.0434]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9954/44303 [59:12<3:24:09,  2.80it/s, loss=0.0434]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9954/44303 [59:13<3:24:09,  2.80it/s, loss=0.056] \u001b[A\n","Training Epoch 1:  22%|██▏       | 9955/44303 [59:13<3:24:22,  2.80it/s, loss=0.056]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9955/44303 [59:13<3:24:22,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9956/44303 [59:13<3:24:42,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9956/44303 [59:13<3:24:42,  2.80it/s, loss=0.0868]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9957/44303 [59:13<3:24:31,  2.80it/s, loss=0.0868]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9957/44303 [59:14<3:24:31,  2.80it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9958/44303 [59:14<3:25:10,  2.79it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9958/44303 [59:14<3:25:10,  2.79it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9959/44303 [59:14<3:25:08,  2.79it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9959/44303 [59:15<3:25:08,  2.79it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9960/44303 [59:15<3:24:39,  2.80it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9960/44303 [59:15<3:24:39,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9961/44303 [59:15<3:25:13,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9961/44303 [59:15<3:25:13,  2.79it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9962/44303 [59:15<3:25:01,  2.79it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9962/44303 [59:16<3:25:01,  2.79it/s, loss=0.0784]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9963/44303 [59:16<3:24:33,  2.80it/s, loss=0.0784]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9963/44303 [59:16<3:24:33,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9964/44303 [59:16<3:25:02,  2.79it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9964/44303 [59:16<3:25:02,  2.79it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9965/44303 [59:16<3:25:06,  2.79it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9965/44303 [59:17<3:25:06,  2.79it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9966/44303 [59:17<3:24:19,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9966/44303 [59:17<3:24:19,  2.80it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9967/44303 [59:17<3:24:27,  2.80it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9967/44303 [59:17<3:24:27,  2.80it/s, loss=0.0351]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9968/44303 [59:17<3:24:33,  2.80it/s, loss=0.0351]\u001b[A\n","Training Epoch 1:  22%|██▏       | 9968/44303 [59:18<3:24:33,  2.80it/s, loss=0.0796]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9969/44303 [59:18<3:24:15,  2.80it/s, loss=0.0796]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9969/44303 [59:18<3:24:15,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9970/44303 [59:18<3:24:10,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9970/44303 [59:19<3:24:10,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9971/44303 [59:19<3:24:06,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9971/44303 [59:19<3:24:06,  2.80it/s, loss=0.0649]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9972/44303 [59:19<3:24:24,  2.80it/s, loss=0.0649]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9972/44303 [59:19<3:24:24,  2.80it/s, loss=0.085] \u001b[A\n","Training Epoch 1:  23%|██▎       | 9973/44303 [59:19<3:24:02,  2.80it/s, loss=0.085]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9973/44303 [59:20<3:24:02,  2.80it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9974/44303 [59:20<3:24:22,  2.80it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9974/44303 [59:20<3:24:22,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9975/44303 [59:20<3:25:08,  2.79it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9975/44303 [59:20<3:25:08,  2.79it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9976/44303 [59:20<3:24:50,  2.79it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9976/44303 [59:21<3:24:50,  2.79it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9977/44303 [59:21<3:24:56,  2.79it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9977/44303 [59:21<3:24:56,  2.79it/s, loss=0.0403]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9978/44303 [59:21<3:25:29,  2.78it/s, loss=0.0403]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9978/44303 [59:21<3:25:29,  2.78it/s, loss=0.0644]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9979/44303 [59:21<3:25:17,  2.79it/s, loss=0.0644]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9979/44303 [59:22<3:25:17,  2.79it/s, loss=0.0481]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9980/44303 [59:22<3:24:29,  2.80it/s, loss=0.0481]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9980/44303 [59:22<3:24:29,  2.80it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9981/44303 [59:22<3:24:50,  2.79it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9981/44303 [59:22<3:24:50,  2.79it/s, loss=0.0864]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9982/44303 [59:22<3:24:28,  2.80it/s, loss=0.0864]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9982/44303 [59:23<3:24:28,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9983/44303 [59:23<3:24:21,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9983/44303 [59:23<3:24:21,  2.80it/s, loss=0.0304]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9984/44303 [59:23<3:24:33,  2.80it/s, loss=0.0304]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9984/44303 [59:24<3:24:33,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9985/44303 [59:24<3:23:50,  2.81it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9985/44303 [59:24<3:23:50,  2.81it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9986/44303 [59:24<3:23:53,  2.81it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9986/44303 [59:24<3:23:53,  2.81it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9987/44303 [59:24<3:24:23,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9987/44303 [59:25<3:24:23,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9988/44303 [59:25<3:24:14,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9988/44303 [59:25<3:24:14,  2.80it/s, loss=0.0939]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9989/44303 [59:25<3:24:23,  2.80it/s, loss=0.0939]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9989/44303 [59:25<3:24:23,  2.80it/s, loss=0.0307]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9990/44303 [59:25<3:24:27,  2.80it/s, loss=0.0307]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9990/44303 [59:26<3:24:27,  2.80it/s, loss=0.131] \u001b[A\n","Training Epoch 1:  23%|██▎       | 9991/44303 [59:26<3:23:59,  2.80it/s, loss=0.131]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9991/44303 [59:26<3:23:59,  2.80it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9992/44303 [59:26<3:24:21,  2.80it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9992/44303 [59:26<3:24:21,  2.80it/s, loss=0.0458]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9993/44303 [59:26<3:23:39,  2.81it/s, loss=0.0458]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9993/44303 [59:27<3:23:39,  2.81it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9994/44303 [59:27<3:24:12,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9994/44303 [59:27<3:24:12,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9995/44303 [59:27<3:24:26,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9995/44303 [59:27<3:24:26,  2.80it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9996/44303 [59:27<3:23:48,  2.81it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9996/44303 [59:28<3:23:48,  2.81it/s, loss=0.0992]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9997/44303 [59:28<3:24:27,  2.80it/s, loss=0.0992]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9997/44303 [59:28<3:24:27,  2.80it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9998/44303 [59:28<3:24:34,  2.79it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9998/44303 [59:29<3:24:34,  2.79it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9999/44303 [59:29<3:23:43,  2.81it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  23%|██▎       | 9999/44303 [59:29<3:23:43,  2.81it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10000/44303 [59:29<3:24:05,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10000/44303 [59:29<3:24:05,  2.80it/s, loss=0.108] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10001/44303 [59:29<3:24:53,  2.79it/s, loss=0.108]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10001/44303 [59:30<3:24:53,  2.79it/s, loss=0.077]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10002/44303 [59:30<3:24:34,  2.79it/s, loss=0.077]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10002/44303 [59:30<3:24:34,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10003/44303 [59:30<3:25:13,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10003/44303 [59:30<3:25:13,  2.79it/s, loss=0.084] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10004/44303 [59:30<3:24:49,  2.79it/s, loss=0.084]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10004/44303 [59:31<3:24:49,  2.79it/s, loss=0.0866]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10005/44303 [59:31<3:24:26,  2.80it/s, loss=0.0866]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10005/44303 [59:31<3:24:26,  2.80it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10006/44303 [59:31<3:25:03,  2.79it/s, loss=0.0448]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10006/44303 [59:31<3:25:03,  2.79it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10007/44303 [59:31<3:24:31,  2.79it/s, loss=0.0447]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10007/44303 [59:32<3:24:31,  2.79it/s, loss=0.0811]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10008/44303 [59:32<3:24:49,  2.79it/s, loss=0.0811]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10008/44303 [59:32<3:24:49,  2.79it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10009/44303 [59:32<3:24:52,  2.79it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10009/44303 [59:32<3:24:52,  2.79it/s, loss=0.059] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10010/44303 [59:32<3:24:59,  2.79it/s, loss=0.059]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10010/44303 [59:33<3:24:59,  2.79it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10011/44303 [59:33<3:24:37,  2.79it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10011/44303 [59:33<3:24:37,  2.79it/s, loss=0.108]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10012/44303 [59:33<3:25:03,  2.79it/s, loss=0.108]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10012/44303 [59:34<3:25:03,  2.79it/s, loss=0.0638]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10013/44303 [59:34<3:24:58,  2.79it/s, loss=0.0638]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10013/44303 [59:34<3:24:58,  2.79it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10014/44303 [59:34<3:24:40,  2.79it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10014/44303 [59:34<3:24:40,  2.79it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10015/44303 [59:34<3:24:19,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10015/44303 [59:35<3:24:19,  2.80it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10016/44303 [59:35<3:24:34,  2.79it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10016/44303 [59:35<3:24:34,  2.79it/s, loss=0.045] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10017/44303 [59:35<3:23:59,  2.80it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10017/44303 [59:35<3:23:59,  2.80it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10018/44303 [59:35<3:24:02,  2.80it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10018/44303 [59:36<3:24:02,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10019/44303 [59:36<3:24:09,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10019/44303 [59:36<3:24:09,  2.80it/s, loss=0.0851]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10020/44303 [59:36<3:23:43,  2.80it/s, loss=0.0851]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10020/44303 [59:36<3:23:43,  2.80it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10021/44303 [59:36<3:24:39,  2.79it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10021/44303 [59:37<3:24:39,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10022/44303 [59:37<3:24:57,  2.79it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10022/44303 [59:37<3:24:57,  2.79it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10023/44303 [59:37<3:24:19,  2.80it/s, loss=0.0857]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10023/44303 [59:37<3:24:19,  2.80it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10024/44303 [59:37<3:24:11,  2.80it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10024/44303 [59:38<3:24:11,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10025/44303 [59:38<3:24:53,  2.79it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10025/44303 [59:38<3:24:53,  2.79it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10026/44303 [59:38<3:23:50,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10026/44303 [59:39<3:23:50,  2.80it/s, loss=0.035] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10027/44303 [59:39<3:24:24,  2.79it/s, loss=0.035]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10027/44303 [59:39<3:24:24,  2.79it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10028/44303 [59:39<3:24:49,  2.79it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10028/44303 [59:39<3:24:49,  2.79it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10029/44303 [59:39<3:24:11,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10029/44303 [59:40<3:24:11,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10030/44303 [59:40<3:24:26,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10030/44303 [59:40<3:24:26,  2.79it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10031/44303 [59:40<3:24:39,  2.79it/s, loss=0.0682]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10031/44303 [59:40<3:24:39,  2.79it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10032/44303 [59:40<3:24:26,  2.79it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10032/44303 [59:41<3:24:26,  2.79it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10033/44303 [59:41<3:24:18,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10033/44303 [59:41<3:24:18,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10034/44303 [59:41<3:24:44,  2.79it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10034/44303 [59:41<3:24:44,  2.79it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10035/44303 [59:41<3:23:54,  2.80it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10035/44303 [59:42<3:23:54,  2.80it/s, loss=0.0767]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10036/44303 [59:42<3:23:33,  2.81it/s, loss=0.0767]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10036/44303 [59:42<3:23:33,  2.81it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10037/44303 [59:42<3:24:04,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10037/44303 [59:42<3:24:04,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10038/44303 [59:42<3:23:46,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10038/44303 [59:43<3:23:46,  2.80it/s, loss=0.0653]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10039/44303 [59:43<3:23:48,  2.80it/s, loss=0.0653]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10039/44303 [59:43<3:23:48,  2.80it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10040/44303 [59:43<3:23:08,  2.81it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10040/44303 [59:44<3:23:08,  2.81it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10041/44303 [59:44<3:23:31,  2.81it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10041/44303 [59:44<3:23:31,  2.81it/s, loss=0.0404]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10042/44303 [59:44<3:23:07,  2.81it/s, loss=0.0404]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10042/44303 [59:44<3:23:07,  2.81it/s, loss=0.0722]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10043/44303 [59:44<3:23:50,  2.80it/s, loss=0.0722]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10043/44303 [59:45<3:23:50,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10044/44303 [59:45<3:23:37,  2.80it/s, loss=0.0657]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10044/44303 [59:45<3:23:37,  2.80it/s, loss=0.0303]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10045/44303 [59:45<3:22:48,  2.82it/s, loss=0.0303]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10045/44303 [59:45<3:22:48,  2.82it/s, loss=0.067] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10046/44303 [59:45<3:23:19,  2.81it/s, loss=0.067]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10046/44303 [59:46<3:23:19,  2.81it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10047/44303 [59:46<3:23:12,  2.81it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10047/44303 [59:46<3:23:12,  2.81it/s, loss=0.0892]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10048/44303 [59:46<3:23:15,  2.81it/s, loss=0.0892]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10048/44303 [59:46<3:23:15,  2.81it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10049/44303 [59:46<3:22:53,  2.81it/s, loss=0.0685]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10049/44303 [59:47<3:22:53,  2.81it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10050/44303 [59:47<3:22:53,  2.81it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10050/44303 [59:47<3:22:53,  2.81it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10051/44303 [59:47<3:23:40,  2.80it/s, loss=0.0821]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10051/44303 [59:47<3:23:40,  2.80it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10052/44303 [59:47<3:23:23,  2.81it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10052/44303 [59:48<3:23:23,  2.81it/s, loss=0.049] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10053/44303 [59:48<3:23:25,  2.81it/s, loss=0.049]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10053/44303 [59:48<3:23:25,  2.81it/s, loss=0.1]  \u001b[A\n","Training Epoch 1:  23%|██▎       | 10054/44303 [59:48<3:24:19,  2.79it/s, loss=0.1]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10054/44303 [59:49<3:24:19,  2.79it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10055/44303 [59:49<3:23:25,  2.81it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10055/44303 [59:49<3:23:25,  2.81it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10056/44303 [59:49<3:23:57,  2.80it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10056/44303 [59:49<3:23:57,  2.80it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10057/44303 [59:49<3:24:01,  2.80it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10057/44303 [59:50<3:24:01,  2.80it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10058/44303 [59:50<3:23:46,  2.80it/s, loss=0.0602]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10058/44303 [59:50<3:23:46,  2.80it/s, loss=0.034] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10059/44303 [59:50<3:24:29,  2.79it/s, loss=0.034]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10059/44303 [59:50<3:24:29,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10060/44303 [59:50<3:24:11,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10060/44303 [59:51<3:24:11,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10061/44303 [59:51<3:23:41,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10061/44303 [59:51<3:23:41,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10062/44303 [59:51<3:24:23,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10062/44303 [59:51<3:24:23,  2.79it/s, loss=0.0344]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10063/44303 [59:51<3:24:26,  2.79it/s, loss=0.0344]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10063/44303 [59:52<3:24:26,  2.79it/s, loss=0.0236]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10064/44303 [59:52<3:23:40,  2.80it/s, loss=0.0236]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10064/44303 [59:52<3:23:40,  2.80it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10065/44303 [59:52<3:23:47,  2.80it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10065/44303 [59:52<3:23:47,  2.80it/s, loss=0.07]  \u001b[A\n","Training Epoch 1:  23%|██▎       | 10066/44303 [59:52<3:23:21,  2.81it/s, loss=0.07]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10066/44303 [59:53<3:23:21,  2.81it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10067/44303 [59:53<3:23:50,  2.80it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10067/44303 [59:53<3:23:50,  2.80it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10068/44303 [59:53<3:23:54,  2.80it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10068/44303 [59:54<3:23:54,  2.80it/s, loss=0.0946]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10069/44303 [59:54<3:23:44,  2.80it/s, loss=0.0946]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10069/44303 [59:54<3:23:44,  2.80it/s, loss=0.0354]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10070/44303 [59:54<3:24:21,  2.79it/s, loss=0.0354]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10070/44303 [59:54<3:24:21,  2.79it/s, loss=0.0985]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10071/44303 [59:54<3:24:10,  2.79it/s, loss=0.0985]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10071/44303 [59:55<3:24:10,  2.79it/s, loss=0.0986]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10072/44303 [59:55<3:24:14,  2.79it/s, loss=0.0986]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10072/44303 [59:55<3:24:14,  2.79it/s, loss=0.0209]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10073/44303 [59:55<3:24:19,  2.79it/s, loss=0.0209]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10073/44303 [59:55<3:24:19,  2.79it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10074/44303 [59:55<3:24:34,  2.79it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10074/44303 [59:56<3:24:34,  2.79it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10075/44303 [59:56<3:23:47,  2.80it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10075/44303 [59:56<3:23:47,  2.80it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10076/44303 [59:56<3:24:04,  2.80it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10076/44303 [59:56<3:24:04,  2.80it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10077/44303 [59:56<3:24:15,  2.79it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10077/44303 [59:57<3:24:15,  2.79it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10078/44303 [59:57<3:24:19,  2.79it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10078/44303 [59:57<3:24:19,  2.79it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10079/44303 [59:57<3:23:49,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10079/44303 [59:57<3:23:49,  2.80it/s, loss=0.0257]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10080/44303 [59:57<3:24:21,  2.79it/s, loss=0.0257]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10080/44303 [59:58<3:24:21,  2.79it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10081/44303 [59:58<3:23:19,  2.81it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10081/44303 [59:58<3:23:19,  2.81it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10082/44303 [59:58<3:23:26,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10082/44303 [59:59<3:23:26,  2.80it/s, loss=0.0246]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10083/44303 [59:59<3:23:39,  2.80it/s, loss=0.0246]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10083/44303 [59:59<3:23:39,  2.80it/s, loss=0.066] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10084/44303 [59:59<3:23:24,  2.80it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10084/44303 [59:59<3:23:24,  2.80it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10085/44303 [59:59<3:23:39,  2.80it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10085/44303 [1:00:00<3:23:39,  2.80it/s, loss=0.0677]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10086/44303 [1:00:00<3:23:03,  2.81it/s, loss=0.0677]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10086/44303 [1:00:00<3:23:03,  2.81it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10087/44303 [1:00:00<3:23:37,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10087/44303 [1:00:00<3:23:37,  2.80it/s, loss=0.041] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10088/44303 [1:00:00<3:23:37,  2.80it/s, loss=0.041]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10088/44303 [1:00:01<3:23:37,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10089/44303 [1:00:01<3:23:21,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10089/44303 [1:00:01<3:23:21,  2.80it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10090/44303 [1:00:01<3:23:33,  2.80it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10090/44303 [1:00:01<3:23:33,  2.80it/s, loss=0.116] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10091/44303 [1:00:01<3:23:03,  2.81it/s, loss=0.116]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10091/44303 [1:00:02<3:23:03,  2.81it/s, loss=0.0932]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10092/44303 [1:00:02<3:23:56,  2.80it/s, loss=0.0932]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10092/44303 [1:00:02<3:23:56,  2.80it/s, loss=0.042] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10093/44303 [1:00:02<3:23:31,  2.80it/s, loss=0.042]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10093/44303 [1:00:02<3:23:31,  2.80it/s, loss=0.0716]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10094/44303 [1:00:02<3:23:07,  2.81it/s, loss=0.0716]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10094/44303 [1:00:03<3:23:07,  2.81it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10095/44303 [1:00:03<3:23:02,  2.81it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10095/44303 [1:00:03<3:23:02,  2.81it/s, loss=0.0469]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10096/44303 [1:00:03<3:23:04,  2.81it/s, loss=0.0469]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10096/44303 [1:00:04<3:23:04,  2.81it/s, loss=0.0327]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10097/44303 [1:00:04<3:23:19,  2.80it/s, loss=0.0327]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10097/44303 [1:00:04<3:23:19,  2.80it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10098/44303 [1:00:04<3:23:36,  2.80it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10098/44303 [1:00:04<3:23:36,  2.80it/s, loss=0.0978]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10099/44303 [1:00:04<3:23:20,  2.80it/s, loss=0.0978]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10099/44303 [1:00:05<3:23:20,  2.80it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10100/44303 [1:00:05<3:23:35,  2.80it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10100/44303 [1:00:05<3:23:35,  2.80it/s, loss=0.0999]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10101/44303 [1:00:05<3:23:19,  2.80it/s, loss=0.0999]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10101/44303 [1:00:05<3:23:19,  2.80it/s, loss=0.026] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10102/44303 [1:00:05<3:22:41,  2.81it/s, loss=0.026]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10102/44303 [1:00:06<3:22:41,  2.81it/s, loss=0.0793]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10103/44303 [1:00:06<3:23:10,  2.81it/s, loss=0.0793]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10103/44303 [1:00:06<3:23:10,  2.81it/s, loss=0.0789]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10104/44303 [1:00:06<3:23:16,  2.80it/s, loss=0.0789]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10104/44303 [1:00:06<3:23:16,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10105/44303 [1:00:06<3:23:47,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10105/44303 [1:00:07<3:23:47,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10106/44303 [1:00:07<3:24:01,  2.79it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10106/44303 [1:00:07<3:24:01,  2.79it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10107/44303 [1:00:07<3:22:50,  2.81it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10107/44303 [1:00:07<3:22:50,  2.81it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10108/44303 [1:00:07<3:23:26,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10108/44303 [1:00:08<3:23:26,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10109/44303 [1:00:08<3:24:15,  2.79it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10109/44303 [1:00:08<3:24:15,  2.79it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10110/44303 [1:00:08<3:23:18,  2.80it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10110/44303 [1:00:09<3:23:18,  2.80it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10111/44303 [1:00:09<3:24:03,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10111/44303 [1:00:09<3:24:03,  2.79it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10112/44303 [1:00:09<3:24:30,  2.79it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10112/44303 [1:00:09<3:24:30,  2.79it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10113/44303 [1:00:09<3:23:54,  2.79it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10113/44303 [1:00:10<3:23:54,  2.79it/s, loss=0.0797]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10114/44303 [1:00:10<3:24:28,  2.79it/s, loss=0.0797]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10114/44303 [1:00:10<3:24:28,  2.79it/s, loss=0.046] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10115/44303 [1:00:10<3:24:26,  2.79it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10115/44303 [1:00:10<3:24:26,  2.79it/s, loss=0.039]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10116/44303 [1:00:10<3:24:39,  2.78it/s, loss=0.039]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10116/44303 [1:00:11<3:24:39,  2.78it/s, loss=0.0814]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10117/44303 [1:00:11<3:24:25,  2.79it/s, loss=0.0814]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10117/44303 [1:00:11<3:24:25,  2.79it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10118/44303 [1:00:11<3:24:03,  2.79it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10118/44303 [1:00:11<3:24:03,  2.79it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10119/44303 [1:00:11<3:23:58,  2.79it/s, loss=0.0583]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10119/44303 [1:00:12<3:23:58,  2.79it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10120/44303 [1:00:12<3:23:11,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10120/44303 [1:00:12<3:23:11,  2.80it/s, loss=0.063] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10121/44303 [1:00:12<3:23:48,  2.80it/s, loss=0.063]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10121/44303 [1:00:12<3:23:48,  2.80it/s, loss=0.0916]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10122/44303 [1:00:12<3:22:47,  2.81it/s, loss=0.0916]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10122/44303 [1:00:13<3:22:47,  2.81it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10123/44303 [1:00:13<3:23:19,  2.80it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10123/44303 [1:00:13<3:23:19,  2.80it/s, loss=0.0618]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10124/44303 [1:00:13<3:22:34,  2.81it/s, loss=0.0618]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10124/44303 [1:00:14<3:22:34,  2.81it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10125/44303 [1:00:14<3:23:00,  2.81it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10125/44303 [1:00:14<3:23:00,  2.81it/s, loss=0.0423]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10126/44303 [1:00:14<3:22:41,  2.81it/s, loss=0.0423]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10126/44303 [1:00:14<3:22:41,  2.81it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10127/44303 [1:00:14<3:22:53,  2.81it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10127/44303 [1:00:15<3:22:53,  2.81it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10128/44303 [1:00:15<3:23:52,  2.79it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10128/44303 [1:00:15<3:23:52,  2.79it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10129/44303 [1:00:15<3:23:19,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10129/44303 [1:00:15<3:23:19,  2.80it/s, loss=0.0924]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10130/44303 [1:00:15<3:23:50,  2.79it/s, loss=0.0924]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10130/44303 [1:00:16<3:23:50,  2.79it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10131/44303 [1:00:16<3:24:09,  2.79it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10131/44303 [1:00:16<3:24:09,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10132/44303 [1:00:16<3:23:44,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10132/44303 [1:00:16<3:23:44,  2.80it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10133/44303 [1:00:16<3:23:55,  2.79it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10133/44303 [1:00:17<3:23:55,  2.79it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10134/44303 [1:00:17<3:23:07,  2.80it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10134/44303 [1:00:17<3:23:07,  2.80it/s, loss=0.053] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10135/44303 [1:00:17<3:23:05,  2.80it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10135/44303 [1:00:17<3:23:05,  2.80it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10136/44303 [1:00:17<3:24:09,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10136/44303 [1:00:18<3:24:09,  2.79it/s, loss=0.0811]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10137/44303 [1:00:18<3:24:01,  2.79it/s, loss=0.0811]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10137/44303 [1:00:18<3:24:01,  2.79it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10138/44303 [1:00:18<3:24:00,  2.79it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10138/44303 [1:00:19<3:24:00,  2.79it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10139/44303 [1:00:19<3:24:13,  2.79it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10139/44303 [1:00:19<3:24:13,  2.79it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10140/44303 [1:00:19<3:24:03,  2.79it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10140/44303 [1:00:19<3:24:03,  2.79it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10141/44303 [1:00:19<3:23:19,  2.80it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10141/44303 [1:00:20<3:23:19,  2.80it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10142/44303 [1:00:20<3:23:57,  2.79it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10142/44303 [1:00:20<3:23:57,  2.79it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10143/44303 [1:00:20<3:22:57,  2.81it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10143/44303 [1:00:20<3:22:57,  2.81it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10144/44303 [1:00:20<3:23:04,  2.80it/s, loss=0.0483]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10144/44303 [1:00:21<3:23:04,  2.80it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10145/44303 [1:00:21<3:22:37,  2.81it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10145/44303 [1:00:21<3:22:37,  2.81it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10146/44303 [1:00:21<3:22:52,  2.81it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10146/44303 [1:00:21<3:22:52,  2.81it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10147/44303 [1:00:21<3:22:26,  2.81it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10147/44303 [1:00:22<3:22:26,  2.81it/s, loss=0.0849]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10148/44303 [1:00:22<3:22:49,  2.81it/s, loss=0.0849]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10148/44303 [1:00:22<3:22:49,  2.81it/s, loss=0.0985]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10149/44303 [1:00:22<3:22:12,  2.82it/s, loss=0.0985]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10149/44303 [1:00:22<3:22:12,  2.82it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10150/44303 [1:00:22<3:22:50,  2.81it/s, loss=0.0415]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10150/44303 [1:00:23<3:22:50,  2.81it/s, loss=0.036] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10151/44303 [1:00:23<3:22:50,  2.81it/s, loss=0.036]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10151/44303 [1:00:23<3:22:50,  2.81it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10152/44303 [1:00:23<3:22:56,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10152/44303 [1:00:24<3:22:56,  2.80it/s, loss=0.0883]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10153/44303 [1:00:24<3:23:33,  2.80it/s, loss=0.0883]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10153/44303 [1:00:24<3:23:33,  2.80it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10154/44303 [1:00:24<3:23:29,  2.80it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10154/44303 [1:00:24<3:23:29,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10155/44303 [1:00:24<3:23:37,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10155/44303 [1:00:25<3:23:37,  2.79it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10156/44303 [1:00:25<3:23:48,  2.79it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10156/44303 [1:00:25<3:23:48,  2.79it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10157/44303 [1:00:25<3:23:20,  2.80it/s, loss=0.0642]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10157/44303 [1:00:25<3:23:20,  2.80it/s, loss=0.0436]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10158/44303 [1:00:25<3:23:13,  2.80it/s, loss=0.0436]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10158/44303 [1:00:26<3:23:13,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10159/44303 [1:00:26<3:23:26,  2.80it/s, loss=0.0506]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10159/44303 [1:00:26<3:23:26,  2.80it/s, loss=0.0949]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10160/44303 [1:00:26<3:23:55,  2.79it/s, loss=0.0949]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10160/44303 [1:00:26<3:23:55,  2.79it/s, loss=0.0437]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10161/44303 [1:00:26<3:24:32,  2.78it/s, loss=0.0437]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10161/44303 [1:00:27<3:24:32,  2.78it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10162/44303 [1:00:27<3:24:14,  2.79it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10162/44303 [1:00:27<3:24:14,  2.79it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10163/44303 [1:00:27<3:24:02,  2.79it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10163/44303 [1:00:27<3:24:02,  2.79it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10164/44303 [1:00:27<3:24:01,  2.79it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10164/44303 [1:00:28<3:24:01,  2.79it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10165/44303 [1:00:28<3:24:20,  2.78it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10165/44303 [1:00:28<3:24:20,  2.78it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10166/44303 [1:00:28<3:23:07,  2.80it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10166/44303 [1:00:29<3:23:07,  2.80it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10167/44303 [1:00:29<3:23:46,  2.79it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10167/44303 [1:00:29<3:23:46,  2.79it/s, loss=0.051] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10168/44303 [1:00:29<3:23:46,  2.79it/s, loss=0.051]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10168/44303 [1:00:29<3:23:46,  2.79it/s, loss=0.0406]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10169/44303 [1:00:29<3:23:34,  2.79it/s, loss=0.0406]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10169/44303 [1:00:30<3:23:34,  2.79it/s, loss=0.0633]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10170/44303 [1:00:30<3:24:04,  2.79it/s, loss=0.0633]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10170/44303 [1:00:30<3:24:04,  2.79it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10171/44303 [1:00:30<3:23:47,  2.79it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10171/44303 [1:00:30<3:23:47,  2.79it/s, loss=0.0984]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10172/44303 [1:00:30<3:23:37,  2.79it/s, loss=0.0984]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10172/44303 [1:00:31<3:23:37,  2.79it/s, loss=0.0668]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10173/44303 [1:00:31<3:24:32,  2.78it/s, loss=0.0668]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10173/44303 [1:00:31<3:24:32,  2.78it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10174/44303 [1:00:31<3:24:08,  2.79it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10174/44303 [1:00:31<3:24:08,  2.79it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10175/44303 [1:00:31<3:23:50,  2.79it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10175/44303 [1:00:32<3:23:50,  2.79it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10176/44303 [1:00:32<3:23:22,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10176/44303 [1:00:32<3:23:22,  2.80it/s, loss=0.0734]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10177/44303 [1:00:32<3:23:13,  2.80it/s, loss=0.0734]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10177/44303 [1:00:32<3:23:13,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10178/44303 [1:00:32<3:23:08,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10178/44303 [1:00:33<3:23:08,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10179/44303 [1:00:33<3:23:26,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10179/44303 [1:00:33<3:23:26,  2.80it/s, loss=0.0288]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10180/44303 [1:00:33<3:23:45,  2.79it/s, loss=0.0288]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10180/44303 [1:00:34<3:23:45,  2.79it/s, loss=0.068] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10181/44303 [1:00:34<3:22:41,  2.81it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10181/44303 [1:00:34<3:22:41,  2.81it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10182/44303 [1:00:34<3:22:48,  2.80it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10182/44303 [1:00:34<3:22:48,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10183/44303 [1:00:34<3:22:37,  2.81it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10183/44303 [1:00:35<3:22:37,  2.81it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10184/44303 [1:00:35<3:22:25,  2.81it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10184/44303 [1:00:35<3:22:25,  2.81it/s, loss=0.0435]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10185/44303 [1:00:35<3:22:25,  2.81it/s, loss=0.0435]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10185/44303 [1:00:35<3:22:25,  2.81it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10186/44303 [1:00:35<3:23:12,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10186/44303 [1:00:36<3:23:12,  2.80it/s, loss=0.066] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10187/44303 [1:00:36<3:23:22,  2.80it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10187/44303 [1:00:36<3:23:22,  2.80it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10188/44303 [1:00:36<3:23:52,  2.79it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10188/44303 [1:00:36<3:23:52,  2.79it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10189/44303 [1:00:36<3:23:29,  2.79it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10189/44303 [1:00:37<3:23:29,  2.79it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10190/44303 [1:00:37<3:22:57,  2.80it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10190/44303 [1:00:37<3:22:57,  2.80it/s, loss=0.0344]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10191/44303 [1:00:37<3:23:34,  2.79it/s, loss=0.0344]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10191/44303 [1:00:37<3:23:34,  2.79it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10192/44303 [1:00:37<3:23:00,  2.80it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10192/44303 [1:00:38<3:23:00,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10193/44303 [1:00:38<3:23:15,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10193/44303 [1:00:38<3:23:15,  2.80it/s, loss=0.0382]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10194/44303 [1:00:38<3:23:47,  2.79it/s, loss=0.0382]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10194/44303 [1:00:39<3:23:47,  2.79it/s, loss=0.0819]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10195/44303 [1:00:39<3:23:34,  2.79it/s, loss=0.0819]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10195/44303 [1:00:39<3:23:34,  2.79it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10196/44303 [1:00:39<3:23:35,  2.79it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10196/44303 [1:00:39<3:23:35,  2.79it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10197/44303 [1:00:39<3:23:24,  2.79it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10197/44303 [1:00:40<3:23:24,  2.79it/s, loss=0.0585]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10198/44303 [1:00:40<3:23:04,  2.80it/s, loss=0.0585]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10198/44303 [1:00:40<3:23:04,  2.80it/s, loss=0.069] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10199/44303 [1:00:40<3:23:06,  2.80it/s, loss=0.069]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10199/44303 [1:00:40<3:23:06,  2.80it/s, loss=0.122]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10200/44303 [1:00:40<3:23:10,  2.80it/s, loss=0.122]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10200/44303 [1:00:41<3:23:10,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10201/44303 [1:00:41<3:22:58,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10201/44303 [1:00:41<3:22:58,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10202/44303 [1:00:41<3:22:47,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10202/44303 [1:00:41<3:22:47,  2.80it/s, loss=0.0595]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10203/44303 [1:00:41<3:22:11,  2.81it/s, loss=0.0595]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10203/44303 [1:00:42<3:22:11,  2.81it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10204/44303 [1:00:42<3:22:11,  2.81it/s, loss=0.0558]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10204/44303 [1:00:42<3:22:11,  2.81it/s, loss=0.0284]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10205/44303 [1:00:42<3:22:39,  2.80it/s, loss=0.0284]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10205/44303 [1:00:42<3:22:39,  2.80it/s, loss=0.0432]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10206/44303 [1:00:42<3:22:21,  2.81it/s, loss=0.0432]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10206/44303 [1:00:43<3:22:21,  2.81it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10207/44303 [1:00:43<3:23:01,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10207/44303 [1:00:43<3:23:01,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10208/44303 [1:00:43<3:22:49,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10208/44303 [1:00:44<3:22:49,  2.80it/s, loss=0.0781]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10209/44303 [1:00:44<3:22:46,  2.80it/s, loss=0.0781]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10209/44303 [1:00:44<3:22:46,  2.80it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10210/44303 [1:00:44<3:23:22,  2.79it/s, loss=0.0512]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10210/44303 [1:00:44<3:23:22,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10211/44303 [1:00:44<3:23:46,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10211/44303 [1:00:45<3:23:46,  2.79it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10212/44303 [1:00:45<3:22:51,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10212/44303 [1:00:45<3:22:51,  2.80it/s, loss=0.0936]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10213/44303 [1:00:45<3:23:04,  2.80it/s, loss=0.0936]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10213/44303 [1:00:45<3:23:04,  2.80it/s, loss=0.115] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10214/44303 [1:00:45<3:22:22,  2.81it/s, loss=0.115]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10214/44303 [1:00:46<3:22:22,  2.81it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10215/44303 [1:00:46<3:22:28,  2.81it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10215/44303 [1:00:46<3:22:28,  2.81it/s, loss=0.048] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10216/44303 [1:00:46<3:21:51,  2.81it/s, loss=0.048]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10216/44303 [1:00:46<3:21:51,  2.81it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10217/44303 [1:00:46<3:23:04,  2.80it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10217/44303 [1:00:47<3:23:04,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10218/44303 [1:00:47<3:23:06,  2.80it/s, loss=0.0584]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10218/44303 [1:00:47<3:23:06,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10219/44303 [1:00:47<3:22:36,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10219/44303 [1:00:47<3:22:36,  2.80it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10220/44303 [1:00:47<3:22:51,  2.80it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10220/44303 [1:00:48<3:22:51,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10221/44303 [1:00:48<3:22:56,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10221/44303 [1:00:48<3:22:56,  2.80it/s, loss=0.0851]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10222/44303 [1:00:48<3:22:23,  2.81it/s, loss=0.0851]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10222/44303 [1:00:49<3:22:23,  2.81it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10223/44303 [1:00:49<3:22:34,  2.80it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10223/44303 [1:00:49<3:22:34,  2.80it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10224/44303 [1:00:49<3:22:12,  2.81it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10224/44303 [1:00:49<3:22:12,  2.81it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10225/44303 [1:00:49<3:22:21,  2.81it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10225/44303 [1:00:50<3:22:21,  2.81it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10226/44303 [1:00:50<3:23:02,  2.80it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10226/44303 [1:00:50<3:23:02,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10227/44303 [1:00:50<3:22:31,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10227/44303 [1:00:50<3:22:31,  2.80it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10228/44303 [1:00:50<3:22:15,  2.81it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10228/44303 [1:00:51<3:22:15,  2.81it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10229/44303 [1:00:51<3:22:09,  2.81it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10229/44303 [1:00:51<3:22:09,  2.81it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10230/44303 [1:00:51<3:22:30,  2.80it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10230/44303 [1:00:51<3:22:30,  2.80it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10231/44303 [1:00:51<3:22:50,  2.80it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10231/44303 [1:00:52<3:22:50,  2.80it/s, loss=0.0724]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10232/44303 [1:00:52<3:22:22,  2.81it/s, loss=0.0724]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10232/44303 [1:00:52<3:22:22,  2.81it/s, loss=0.0603]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10233/44303 [1:00:52<3:22:44,  2.80it/s, loss=0.0603]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10233/44303 [1:00:52<3:22:44,  2.80it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10234/44303 [1:00:52<3:22:28,  2.80it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10234/44303 [1:00:53<3:22:28,  2.80it/s, loss=0.0356]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10235/44303 [1:00:53<3:21:56,  2.81it/s, loss=0.0356]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10235/44303 [1:00:53<3:21:56,  2.81it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10236/44303 [1:00:53<3:22:44,  2.80it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10236/44303 [1:00:54<3:22:44,  2.80it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10237/44303 [1:00:54<3:22:53,  2.80it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10237/44303 [1:00:54<3:22:53,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10238/44303 [1:00:54<3:22:44,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10238/44303 [1:00:54<3:22:44,  2.80it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10239/44303 [1:00:54<3:24:01,  2.78it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10239/44303 [1:00:55<3:24:01,  2.78it/s, loss=0.0593]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10240/44303 [1:00:55<3:22:55,  2.80it/s, loss=0.0593]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10240/44303 [1:00:55<3:22:55,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10241/44303 [1:00:55<3:22:45,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10241/44303 [1:00:55<3:22:45,  2.80it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10242/44303 [1:00:55<3:23:33,  2.79it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10242/44303 [1:00:56<3:23:33,  2.79it/s, loss=0.0767]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10243/44303 [1:00:56<3:23:32,  2.79it/s, loss=0.0767]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10243/44303 [1:00:56<3:23:32,  2.79it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10244/44303 [1:00:56<3:22:57,  2.80it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10244/44303 [1:00:56<3:22:57,  2.80it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10245/44303 [1:00:56<3:23:24,  2.79it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10245/44303 [1:00:57<3:23:24,  2.79it/s, loss=0.0806]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10246/44303 [1:00:57<3:23:38,  2.79it/s, loss=0.0806]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10246/44303 [1:00:57<3:23:38,  2.79it/s, loss=0.0818]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10247/44303 [1:00:57<3:23:08,  2.79it/s, loss=0.0818]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10247/44303 [1:00:57<3:23:08,  2.79it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10248/44303 [1:00:57<3:23:29,  2.79it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10248/44303 [1:00:58<3:23:29,  2.79it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10249/44303 [1:00:58<3:23:30,  2.79it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10249/44303 [1:00:58<3:23:30,  2.79it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10250/44303 [1:00:58<3:22:43,  2.80it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10250/44303 [1:00:59<3:22:43,  2.80it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10251/44303 [1:00:59<3:23:05,  2.79it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10251/44303 [1:00:59<3:23:05,  2.79it/s, loss=0.0658]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10252/44303 [1:00:59<3:23:43,  2.79it/s, loss=0.0658]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10252/44303 [1:00:59<3:23:43,  2.79it/s, loss=0.0372]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10253/44303 [1:00:59<3:23:07,  2.79it/s, loss=0.0372]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10253/44303 [1:01:00<3:23:07,  2.79it/s, loss=0.0893]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10254/44303 [1:01:00<3:22:50,  2.80it/s, loss=0.0893]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10254/44303 [1:01:00<3:22:50,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10255/44303 [1:01:00<3:23:32,  2.79it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10255/44303 [1:01:00<3:23:32,  2.79it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10256/44303 [1:01:00<3:22:02,  2.81it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10256/44303 [1:01:01<3:22:02,  2.81it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10257/44303 [1:01:01<3:22:21,  2.80it/s, loss=0.0735]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10257/44303 [1:01:01<3:22:21,  2.80it/s, loss=0.0681]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10258/44303 [1:01:01<3:22:30,  2.80it/s, loss=0.0681]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10258/44303 [1:01:01<3:22:30,  2.80it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10259/44303 [1:01:01<3:22:27,  2.80it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10259/44303 [1:01:02<3:22:27,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10260/44303 [1:01:02<3:22:52,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10260/44303 [1:01:02<3:22:52,  2.80it/s, loss=0.0876]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10261/44303 [1:01:02<3:22:33,  2.80it/s, loss=0.0876]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10261/44303 [1:01:02<3:22:33,  2.80it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10262/44303 [1:01:02<3:22:50,  2.80it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10262/44303 [1:01:03<3:22:50,  2.80it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10263/44303 [1:01:03<3:22:51,  2.80it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10263/44303 [1:01:03<3:22:51,  2.80it/s, loss=0.055] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10264/44303 [1:01:03<3:22:15,  2.80it/s, loss=0.055]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10264/44303 [1:01:04<3:22:15,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10265/44303 [1:01:04<3:23:03,  2.79it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10265/44303 [1:01:04<3:23:03,  2.79it/s, loss=0.066] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10266/44303 [1:01:04<3:23:08,  2.79it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10266/44303 [1:01:04<3:23:08,  2.79it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10267/44303 [1:01:04<3:22:59,  2.79it/s, loss=0.0411]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10267/44303 [1:01:05<3:22:59,  2.79it/s, loss=0.0301]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10268/44303 [1:01:05<3:23:01,  2.79it/s, loss=0.0301]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10268/44303 [1:01:05<3:23:01,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10269/44303 [1:01:05<3:22:31,  2.80it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10269/44303 [1:01:05<3:22:31,  2.80it/s, loss=0.116] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10270/44303 [1:01:05<3:22:32,  2.80it/s, loss=0.116]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10270/44303 [1:01:06<3:22:32,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10271/44303 [1:01:06<3:22:48,  2.80it/s, loss=0.0463]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10271/44303 [1:01:06<3:22:48,  2.80it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10272/44303 [1:01:06<3:23:08,  2.79it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10272/44303 [1:01:06<3:23:08,  2.79it/s, loss=0.0755]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10273/44303 [1:01:06<3:23:02,  2.79it/s, loss=0.0755]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10273/44303 [1:01:07<3:23:02,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10274/44303 [1:01:07<3:23:18,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10274/44303 [1:01:07<3:23:18,  2.79it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10275/44303 [1:01:07<3:23:31,  2.79it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10275/44303 [1:01:08<3:23:31,  2.79it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10276/44303 [1:01:08<3:23:48,  2.78it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10276/44303 [1:01:08<3:23:48,  2.78it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10277/44303 [1:01:08<3:23:49,  2.78it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10277/44303 [1:01:08<3:23:49,  2.78it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10278/44303 [1:01:08<3:23:42,  2.78it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10278/44303 [1:01:09<3:23:42,  2.78it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10279/44303 [1:01:09<3:22:57,  2.79it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10279/44303 [1:01:09<3:22:57,  2.79it/s, loss=0.036] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10280/44303 [1:01:09<3:22:22,  2.80it/s, loss=0.036]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10280/44303 [1:01:09<3:22:22,  2.80it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10281/44303 [1:01:09<3:22:25,  2.80it/s, loss=0.0862]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10281/44303 [1:01:10<3:22:25,  2.80it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10282/44303 [1:01:10<3:22:04,  2.81it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10282/44303 [1:01:10<3:22:04,  2.81it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10283/44303 [1:01:10<3:22:02,  2.81it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10283/44303 [1:01:10<3:22:02,  2.81it/s, loss=0.0232]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10284/44303 [1:01:10<3:21:49,  2.81it/s, loss=0.0232]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10284/44303 [1:01:11<3:21:49,  2.81it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10285/44303 [1:01:11<3:22:17,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10285/44303 [1:01:11<3:22:17,  2.80it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10286/44303 [1:01:11<3:22:39,  2.80it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10286/44303 [1:01:11<3:22:39,  2.80it/s, loss=0.0355]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10287/44303 [1:01:11<3:22:10,  2.80it/s, loss=0.0355]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10287/44303 [1:01:12<3:22:10,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10288/44303 [1:01:12<3:22:07,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10288/44303 [1:01:12<3:22:07,  2.80it/s, loss=0.049] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10289/44303 [1:01:12<3:23:25,  2.79it/s, loss=0.049]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10289/44303 [1:01:13<3:23:25,  2.79it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10290/44303 [1:01:13<3:22:36,  2.80it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10290/44303 [1:01:13<3:22:36,  2.80it/s, loss=0.0812]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10291/44303 [1:01:13<3:23:18,  2.79it/s, loss=0.0812]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10291/44303 [1:01:13<3:23:18,  2.79it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10292/44303 [1:01:13<3:22:37,  2.80it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10292/44303 [1:01:14<3:22:37,  2.80it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10293/44303 [1:01:14<3:22:17,  2.80it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10293/44303 [1:01:14<3:22:17,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10294/44303 [1:01:14<3:22:35,  2.80it/s, loss=0.0379]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10294/44303 [1:01:14<3:22:35,  2.80it/s, loss=0.0269]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10295/44303 [1:01:14<3:21:49,  2.81it/s, loss=0.0269]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10295/44303 [1:01:15<3:21:49,  2.81it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10296/44303 [1:01:15<3:22:04,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10296/44303 [1:01:15<3:22:04,  2.80it/s, loss=0.0323]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10297/44303 [1:01:15<3:22:12,  2.80it/s, loss=0.0323]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10297/44303 [1:01:15<3:22:12,  2.80it/s, loss=0.0732]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10298/44303 [1:01:15<3:21:46,  2.81it/s, loss=0.0732]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10298/44303 [1:01:16<3:21:46,  2.81it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10299/44303 [1:01:16<3:22:10,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10299/44303 [1:01:16<3:22:10,  2.80it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10300/44303 [1:01:16<3:21:40,  2.81it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10300/44303 [1:01:16<3:21:40,  2.81it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10301/44303 [1:01:16<3:22:06,  2.80it/s, loss=0.0613]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10301/44303 [1:01:17<3:22:06,  2.80it/s, loss=0.0239]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10302/44303 [1:01:17<3:21:42,  2.81it/s, loss=0.0239]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10302/44303 [1:01:17<3:21:42,  2.81it/s, loss=0.0601]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10303/44303 [1:01:17<3:21:52,  2.81it/s, loss=0.0601]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10303/44303 [1:01:18<3:21:52,  2.81it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10304/44303 [1:01:18<3:21:59,  2.81it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10304/44303 [1:01:18<3:21:59,  2.81it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10305/44303 [1:01:18<3:21:42,  2.81it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10305/44303 [1:01:18<3:21:42,  2.81it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10306/44303 [1:01:18<3:22:23,  2.80it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10306/44303 [1:01:19<3:22:23,  2.80it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10307/44303 [1:01:19<3:22:17,  2.80it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10307/44303 [1:01:19<3:22:17,  2.80it/s, loss=0.0824]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10308/44303 [1:01:19<3:22:15,  2.80it/s, loss=0.0824]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10308/44303 [1:01:19<3:22:15,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10309/44303 [1:01:19<3:22:46,  2.79it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10309/44303 [1:01:20<3:22:46,  2.79it/s, loss=0.0406]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10310/44303 [1:01:20<3:23:12,  2.79it/s, loss=0.0406]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10310/44303 [1:01:20<3:23:12,  2.79it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10311/44303 [1:01:20<3:22:17,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10311/44303 [1:01:20<3:22:17,  2.80it/s, loss=0.043] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10312/44303 [1:01:20<3:22:55,  2.79it/s, loss=0.043]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10312/44303 [1:01:21<3:22:55,  2.79it/s, loss=0.106]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10313/44303 [1:01:21<3:21:56,  2.81it/s, loss=0.106]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10313/44303 [1:01:21<3:21:56,  2.81it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10314/44303 [1:01:21<3:21:56,  2.81it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10314/44303 [1:01:21<3:21:56,  2.81it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10315/44303 [1:01:21<3:22:16,  2.80it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10315/44303 [1:01:22<3:22:16,  2.80it/s, loss=0.0307]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10316/44303 [1:01:22<3:22:08,  2.80it/s, loss=0.0307]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10316/44303 [1:01:22<3:22:08,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10317/44303 [1:01:22<3:22:06,  2.80it/s, loss=0.0725]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10317/44303 [1:01:23<3:22:06,  2.80it/s, loss=0.0879]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10318/44303 [1:01:23<3:22:16,  2.80it/s, loss=0.0879]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10318/44303 [1:01:23<3:22:16,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10319/44303 [1:01:23<3:22:20,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10319/44303 [1:01:23<3:22:20,  2.80it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10320/44303 [1:01:23<3:22:54,  2.79it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10320/44303 [1:01:24<3:22:54,  2.79it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10321/44303 [1:01:24<3:22:12,  2.80it/s, loss=0.0654]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10321/44303 [1:01:24<3:22:12,  2.80it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10322/44303 [1:01:24<3:22:57,  2.79it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10322/44303 [1:01:24<3:22:57,  2.79it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10323/44303 [1:01:24<3:22:17,  2.80it/s, loss=0.0374]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10323/44303 [1:01:25<3:22:17,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10324/44303 [1:01:25<3:21:52,  2.81it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10324/44303 [1:01:25<3:21:52,  2.81it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10325/44303 [1:01:25<3:22:36,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10325/44303 [1:01:25<3:22:36,  2.80it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10326/44303 [1:01:25<3:21:51,  2.81it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10326/44303 [1:01:26<3:21:51,  2.81it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10327/44303 [1:01:26<3:22:00,  2.80it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10327/44303 [1:01:26<3:22:00,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10328/44303 [1:01:26<3:21:52,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10328/44303 [1:01:26<3:21:52,  2.80it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10329/44303 [1:01:26<3:22:06,  2.80it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10329/44303 [1:01:27<3:22:06,  2.80it/s, loss=0.0293]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10330/44303 [1:01:27<3:21:56,  2.80it/s, loss=0.0293]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10330/44303 [1:01:27<3:21:56,  2.80it/s, loss=0.0789]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10331/44303 [1:01:27<3:21:45,  2.81it/s, loss=0.0789]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10331/44303 [1:01:28<3:21:45,  2.81it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10332/44303 [1:01:28<3:22:13,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10332/44303 [1:01:28<3:22:13,  2.80it/s, loss=0.066] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10333/44303 [1:01:28<3:21:41,  2.81it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10333/44303 [1:01:28<3:21:41,  2.81it/s, loss=0.26] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10334/44303 [1:01:28<3:22:09,  2.80it/s, loss=0.26]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10334/44303 [1:01:29<3:22:09,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10335/44303 [1:01:29<3:22:45,  2.79it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10335/44303 [1:01:29<3:22:45,  2.79it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10336/44303 [1:01:29<3:21:55,  2.80it/s, loss=0.0459]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10336/44303 [1:01:29<3:21:55,  2.80it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10337/44303 [1:01:29<3:22:07,  2.80it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10337/44303 [1:01:30<3:22:07,  2.80it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10338/44303 [1:01:30<3:21:34,  2.81it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10338/44303 [1:01:30<3:21:34,  2.81it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10339/44303 [1:01:30<3:22:22,  2.80it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10339/44303 [1:01:30<3:22:22,  2.80it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10340/44303 [1:01:30<3:22:33,  2.79it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10340/44303 [1:01:31<3:22:33,  2.79it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10341/44303 [1:01:31<3:22:12,  2.80it/s, loss=0.0589]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10341/44303 [1:01:31<3:22:12,  2.80it/s, loss=0.053] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10342/44303 [1:01:31<3:22:51,  2.79it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10342/44303 [1:01:31<3:22:51,  2.79it/s, loss=0.047]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10343/44303 [1:01:31<3:22:46,  2.79it/s, loss=0.047]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10343/44303 [1:01:32<3:22:46,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10344/44303 [1:01:32<3:23:04,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10344/44303 [1:01:32<3:23:04,  2.79it/s, loss=0.0252]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10345/44303 [1:01:32<3:22:59,  2.79it/s, loss=0.0252]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10345/44303 [1:01:33<3:22:59,  2.79it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10346/44303 [1:01:33<3:23:06,  2.79it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10346/44303 [1:01:33<3:23:06,  2.79it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10347/44303 [1:01:33<3:22:09,  2.80it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10347/44303 [1:01:33<3:22:09,  2.80it/s, loss=0.041] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10348/44303 [1:01:33<3:22:24,  2.80it/s, loss=0.041]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10348/44303 [1:01:34<3:22:24,  2.80it/s, loss=0.0981]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10349/44303 [1:01:34<3:22:37,  2.79it/s, loss=0.0981]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10349/44303 [1:01:34<3:22:37,  2.79it/s, loss=0.0798]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10350/44303 [1:01:34<3:21:30,  2.81it/s, loss=0.0798]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10350/44303 [1:01:34<3:21:30,  2.81it/s, loss=0.041] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10351/44303 [1:01:34<3:22:04,  2.80it/s, loss=0.041]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10351/44303 [1:01:35<3:22:04,  2.80it/s, loss=0.0271]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10352/44303 [1:01:35<3:21:39,  2.81it/s, loss=0.0271]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10352/44303 [1:01:35<3:21:39,  2.81it/s, loss=0.0384]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10353/44303 [1:01:35<3:22:18,  2.80it/s, loss=0.0384]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10353/44303 [1:01:35<3:22:18,  2.80it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10354/44303 [1:01:35<3:22:54,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10354/44303 [1:01:36<3:22:54,  2.79it/s, loss=0.08]  \u001b[A\n","Training Epoch 1:  23%|██▎       | 10355/44303 [1:01:36<3:21:56,  2.80it/s, loss=0.08]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10355/44303 [1:01:36<3:21:56,  2.80it/s, loss=0.0661]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10356/44303 [1:01:36<3:22:49,  2.79it/s, loss=0.0661]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10356/44303 [1:01:36<3:22:49,  2.79it/s, loss=0.124] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10357/44303 [1:01:36<3:22:38,  2.79it/s, loss=0.124]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10357/44303 [1:01:37<3:22:38,  2.79it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10358/44303 [1:01:37<3:22:35,  2.79it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10358/44303 [1:01:37<3:22:35,  2.79it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10359/44303 [1:01:37<3:22:52,  2.79it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10359/44303 [1:01:38<3:22:52,  2.79it/s, loss=0.103] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10360/44303 [1:01:38<3:22:21,  2.80it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10360/44303 [1:01:38<3:22:21,  2.80it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10361/44303 [1:01:38<3:21:58,  2.80it/s, loss=0.0774]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10361/44303 [1:01:38<3:21:58,  2.80it/s, loss=0.057] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10362/44303 [1:01:38<3:22:25,  2.79it/s, loss=0.057]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10362/44303 [1:01:39<3:22:25,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10363/44303 [1:01:39<3:22:11,  2.80it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10363/44303 [1:01:39<3:22:11,  2.80it/s, loss=0.049] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10364/44303 [1:01:39<3:22:04,  2.80it/s, loss=0.049]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10364/44303 [1:01:39<3:22:04,  2.80it/s, loss=0.0513]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10365/44303 [1:01:39<3:22:55,  2.79it/s, loss=0.0513]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10365/44303 [1:01:40<3:22:55,  2.79it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10366/44303 [1:01:40<3:22:43,  2.79it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10366/44303 [1:01:40<3:22:43,  2.79it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10367/44303 [1:01:40<3:22:18,  2.80it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10367/44303 [1:01:40<3:22:18,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10368/44303 [1:01:40<3:22:41,  2.79it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10368/44303 [1:01:41<3:22:41,  2.79it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10369/44303 [1:01:41<3:22:03,  2.80it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10369/44303 [1:01:41<3:22:03,  2.80it/s, loss=0.0937]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10370/44303 [1:01:41<3:21:42,  2.80it/s, loss=0.0937]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10370/44303 [1:01:41<3:21:42,  2.80it/s, loss=0.0869]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10371/44303 [1:01:41<3:22:16,  2.80it/s, loss=0.0869]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10371/44303 [1:01:42<3:22:16,  2.80it/s, loss=0.0288]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10372/44303 [1:01:42<3:21:47,  2.80it/s, loss=0.0288]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10372/44303 [1:01:42<3:21:47,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10373/44303 [1:01:42<3:22:15,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10373/44303 [1:01:43<3:22:15,  2.80it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10374/44303 [1:01:43<3:22:18,  2.80it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10374/44303 [1:01:43<3:22:18,  2.80it/s, loss=0.0904]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10375/44303 [1:01:43<3:21:59,  2.80it/s, loss=0.0904]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10375/44303 [1:01:43<3:21:59,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10376/44303 [1:01:43<3:22:18,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10376/44303 [1:01:44<3:22:18,  2.80it/s, loss=0.059] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10377/44303 [1:01:44<3:22:09,  2.80it/s, loss=0.059]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10377/44303 [1:01:44<3:22:09,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10378/44303 [1:01:44<3:21:52,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10378/44303 [1:01:44<3:21:52,  2.80it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10379/44303 [1:01:44<3:22:31,  2.79it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10379/44303 [1:01:45<3:22:31,  2.79it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10380/44303 [1:01:45<3:21:30,  2.81it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10380/44303 [1:01:45<3:21:30,  2.81it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10381/44303 [1:01:45<3:20:58,  2.81it/s, loss=0.0362]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10381/44303 [1:01:45<3:20:58,  2.81it/s, loss=0.04]  \u001b[A\n","Training Epoch 1:  23%|██▎       | 10382/44303 [1:01:45<3:21:32,  2.81it/s, loss=0.04]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10382/44303 [1:01:46<3:21:32,  2.81it/s, loss=0.0991]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10383/44303 [1:01:46<3:21:45,  2.80it/s, loss=0.0991]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10383/44303 [1:01:46<3:21:45,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10384/44303 [1:01:46<3:21:38,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10384/44303 [1:01:46<3:21:38,  2.80it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10385/44303 [1:01:46<3:21:44,  2.80it/s, loss=0.0538]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10385/44303 [1:01:47<3:21:44,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10386/44303 [1:01:47<3:22:02,  2.80it/s, loss=0.0468]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10386/44303 [1:01:47<3:22:02,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10387/44303 [1:01:47<3:21:40,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10387/44303 [1:01:48<3:21:40,  2.80it/s, loss=0.046] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10388/44303 [1:01:48<3:21:25,  2.81it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10388/44303 [1:01:48<3:21:25,  2.81it/s, loss=0.112]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10389/44303 [1:01:48<3:21:59,  2.80it/s, loss=0.112]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10389/44303 [1:01:48<3:21:59,  2.80it/s, loss=0.0435]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10390/44303 [1:01:48<3:22:04,  2.80it/s, loss=0.0435]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10390/44303 [1:01:49<3:22:04,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10391/44303 [1:01:49<3:21:43,  2.80it/s, loss=0.0524]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10391/44303 [1:01:49<3:21:43,  2.80it/s, loss=0.0259]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10392/44303 [1:01:49<3:22:01,  2.80it/s, loss=0.0259]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10392/44303 [1:01:49<3:22:01,  2.80it/s, loss=0.0808]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10393/44303 [1:01:49<3:21:37,  2.80it/s, loss=0.0808]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10393/44303 [1:01:50<3:21:37,  2.80it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10394/44303 [1:01:50<3:21:19,  2.81it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10394/44303 [1:01:50<3:21:19,  2.81it/s, loss=0.0924]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10395/44303 [1:01:50<3:21:55,  2.80it/s, loss=0.0924]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10395/44303 [1:01:50<3:21:55,  2.80it/s, loss=0.0441]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10396/44303 [1:01:50<3:21:35,  2.80it/s, loss=0.0441]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10396/44303 [1:01:51<3:21:35,  2.80it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10397/44303 [1:01:51<3:22:24,  2.79it/s, loss=0.0425]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10397/44303 [1:01:51<3:22:24,  2.79it/s, loss=0.0638]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10398/44303 [1:01:51<3:22:07,  2.80it/s, loss=0.0638]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10398/44303 [1:01:51<3:22:07,  2.80it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10399/44303 [1:01:51<3:21:46,  2.80it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10399/44303 [1:01:52<3:21:46,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10400/44303 [1:01:52<3:22:14,  2.79it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10400/44303 [1:01:52<3:22:14,  2.79it/s, loss=0.0427]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10401/44303 [1:01:52<3:21:16,  2.81it/s, loss=0.0427]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10401/44303 [1:01:53<3:21:16,  2.81it/s, loss=0.0405]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10402/44303 [1:01:53<3:20:55,  2.81it/s, loss=0.0405]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10402/44303 [1:01:53<3:20:55,  2.81it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10403/44303 [1:01:53<3:21:34,  2.80it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10403/44303 [1:01:53<3:21:34,  2.80it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10404/44303 [1:01:53<3:21:02,  2.81it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10404/44303 [1:01:54<3:21:02,  2.81it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10405/44303 [1:01:54<3:21:51,  2.80it/s, loss=0.0456]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10405/44303 [1:01:54<3:21:51,  2.80it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  23%|██▎       | 10406/44303 [1:01:54<3:20:51,  2.81it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10406/44303 [1:01:54<3:20:51,  2.81it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10407/44303 [1:01:54<3:21:23,  2.81it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10407/44303 [1:01:55<3:21:23,  2.81it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10408/44303 [1:01:55<3:21:24,  2.80it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10408/44303 [1:01:55<3:21:24,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10409/44303 [1:01:55<3:21:21,  2.81it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10409/44303 [1:01:55<3:21:21,  2.81it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10410/44303 [1:01:55<3:22:03,  2.80it/s, loss=0.0457]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10410/44303 [1:01:56<3:22:03,  2.80it/s, loss=0.0963]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10411/44303 [1:01:56<3:21:31,  2.80it/s, loss=0.0963]\u001b[A\n","Training Epoch 1:  23%|██▎       | 10411/44303 [1:01:56<3:21:31,  2.80it/s, loss=0.0775]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10412/44303 [1:01:56<3:21:54,  2.80it/s, loss=0.0775]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10412/44303 [1:01:56<3:21:54,  2.80it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10413/44303 [1:01:56<3:22:14,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10413/44303 [1:01:57<3:22:14,  2.79it/s, loss=0.0382]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10414/44303 [1:01:57<3:22:19,  2.79it/s, loss=0.0382]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10414/44303 [1:01:57<3:22:19,  2.79it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10415/44303 [1:01:57<3:21:29,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10415/44303 [1:01:58<3:21:29,  2.80it/s, loss=0.0436]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10416/44303 [1:01:58<3:22:05,  2.79it/s, loss=0.0436]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10416/44303 [1:01:58<3:22:05,  2.79it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10417/44303 [1:01:58<3:21:23,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10417/44303 [1:01:58<3:21:23,  2.80it/s, loss=0.0789]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10418/44303 [1:01:58<3:21:27,  2.80it/s, loss=0.0789]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10418/44303 [1:01:59<3:21:27,  2.80it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10419/44303 [1:01:59<3:22:06,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10419/44303 [1:01:59<3:22:06,  2.79it/s, loss=0.06]  \u001b[A\n","Training Epoch 1:  24%|██▎       | 10420/44303 [1:01:59<3:21:41,  2.80it/s, loss=0.06]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10420/44303 [1:01:59<3:21:41,  2.80it/s, loss=0.0445]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10421/44303 [1:01:59<3:21:59,  2.80it/s, loss=0.0445]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10421/44303 [1:02:00<3:21:59,  2.80it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10422/44303 [1:02:00<3:21:09,  2.81it/s, loss=0.0736]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10422/44303 [1:02:00<3:21:09,  2.81it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10423/44303 [1:02:00<3:21:28,  2.80it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10423/44303 [1:02:00<3:21:28,  2.80it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10424/44303 [1:02:00<3:21:55,  2.80it/s, loss=0.0414]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10424/44303 [1:02:01<3:21:55,  2.80it/s, loss=0.142] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10425/44303 [1:02:01<3:21:59,  2.80it/s, loss=0.142]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10425/44303 [1:02:01<3:21:59,  2.80it/s, loss=0.136]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10426/44303 [1:02:01<3:21:52,  2.80it/s, loss=0.136]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10426/44303 [1:02:01<3:21:52,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10427/44303 [1:02:01<3:22:34,  2.79it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10427/44303 [1:02:02<3:22:34,  2.79it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10428/44303 [1:02:02<3:22:08,  2.79it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10428/44303 [1:02:02<3:22:08,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10429/44303 [1:02:02<3:22:03,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10429/44303 [1:02:03<3:22:03,  2.79it/s, loss=0.0726]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10430/44303 [1:02:03<3:22:13,  2.79it/s, loss=0.0726]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10430/44303 [1:02:03<3:22:13,  2.79it/s, loss=0.0939]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10431/44303 [1:02:03<3:22:17,  2.79it/s, loss=0.0939]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10431/44303 [1:02:03<3:22:17,  2.79it/s, loss=0.0807]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10432/44303 [1:02:03<3:22:39,  2.79it/s, loss=0.0807]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10432/44303 [1:02:04<3:22:39,  2.79it/s, loss=0.068] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10433/44303 [1:02:04<3:22:30,  2.79it/s, loss=0.068]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10433/44303 [1:02:04<3:22:30,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10434/44303 [1:02:04<3:22:10,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10434/44303 [1:02:04<3:22:10,  2.79it/s, loss=0.0407]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10435/44303 [1:02:04<3:21:48,  2.80it/s, loss=0.0407]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10435/44303 [1:02:05<3:21:48,  2.80it/s, loss=0.0444]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10436/44303 [1:02:05<3:22:17,  2.79it/s, loss=0.0444]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10436/44303 [1:02:05<3:22:17,  2.79it/s, loss=0.0295]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10437/44303 [1:02:05<3:21:54,  2.80it/s, loss=0.0295]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10437/44303 [1:02:05<3:21:54,  2.80it/s, loss=0.0902]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10438/44303 [1:02:05<3:21:42,  2.80it/s, loss=0.0902]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10438/44303 [1:02:06<3:21:42,  2.80it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10439/44303 [1:02:06<3:22:12,  2.79it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10439/44303 [1:02:06<3:22:12,  2.79it/s, loss=0.0354]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10440/44303 [1:02:06<3:22:21,  2.79it/s, loss=0.0354]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10440/44303 [1:02:06<3:22:21,  2.79it/s, loss=0.0941]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10441/44303 [1:02:06<3:21:28,  2.80it/s, loss=0.0941]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10441/44303 [1:02:07<3:21:28,  2.80it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10442/44303 [1:02:07<3:21:52,  2.80it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10442/44303 [1:02:07<3:21:52,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10443/44303 [1:02:07<3:21:51,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10443/44303 [1:02:08<3:21:51,  2.80it/s, loss=0.0808]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10444/44303 [1:02:08<3:22:08,  2.79it/s, loss=0.0808]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10444/44303 [1:02:08<3:22:08,  2.79it/s, loss=0.0536]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10445/44303 [1:02:08<3:22:16,  2.79it/s, loss=0.0536]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10445/44303 [1:02:08<3:22:16,  2.79it/s, loss=0.0229]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10446/44303 [1:02:08<3:22:53,  2.78it/s, loss=0.0229]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10446/44303 [1:02:09<3:22:53,  2.78it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10447/44303 [1:02:09<3:22:23,  2.79it/s, loss=0.0664]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10447/44303 [1:02:09<3:22:23,  2.79it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10448/44303 [1:02:09<3:22:02,  2.79it/s, loss=0.0525]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10448/44303 [1:02:09<3:22:02,  2.79it/s, loss=0.0731]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10449/44303 [1:02:09<3:22:05,  2.79it/s, loss=0.0731]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10449/44303 [1:02:10<3:22:05,  2.79it/s, loss=0.043] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10450/44303 [1:02:10<3:21:18,  2.80it/s, loss=0.043]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10450/44303 [1:02:10<3:21:18,  2.80it/s, loss=0.0658]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10451/44303 [1:02:10<3:21:36,  2.80it/s, loss=0.0658]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10451/44303 [1:02:10<3:21:36,  2.80it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10452/44303 [1:02:10<3:21:33,  2.80it/s, loss=0.0493]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10452/44303 [1:02:11<3:21:33,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10453/44303 [1:02:11<3:21:14,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10453/44303 [1:02:11<3:21:14,  2.80it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10454/44303 [1:02:11<3:21:46,  2.80it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10454/44303 [1:02:11<3:21:46,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10455/44303 [1:02:11<3:21:41,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10455/44303 [1:02:12<3:21:41,  2.80it/s, loss=0.0888]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10456/44303 [1:02:12<3:22:04,  2.79it/s, loss=0.0888]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10456/44303 [1:02:12<3:22:04,  2.79it/s, loss=0.0976]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10457/44303 [1:02:12<3:22:08,  2.79it/s, loss=0.0976]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10457/44303 [1:02:13<3:22:08,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10458/44303 [1:02:13<3:22:08,  2.79it/s, loss=0.0594]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10458/44303 [1:02:13<3:22:08,  2.79it/s, loss=0.0233]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10459/44303 [1:02:13<3:21:15,  2.80it/s, loss=0.0233]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10459/44303 [1:02:13<3:21:15,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10460/44303 [1:02:13<3:21:53,  2.79it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10460/44303 [1:02:14<3:21:53,  2.79it/s, loss=0.0894]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10461/44303 [1:02:14<3:21:49,  2.79it/s, loss=0.0894]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10461/44303 [1:02:14<3:21:49,  2.79it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10462/44303 [1:02:14<3:21:53,  2.79it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10462/44303 [1:02:14<3:21:53,  2.79it/s, loss=0.0423]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10463/44303 [1:02:14<3:21:56,  2.79it/s, loss=0.0423]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10463/44303 [1:02:15<3:21:56,  2.79it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10464/44303 [1:02:15<3:21:52,  2.79it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10464/44303 [1:02:15<3:21:52,  2.79it/s, loss=0.0299]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10465/44303 [1:02:15<3:21:18,  2.80it/s, loss=0.0299]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10465/44303 [1:02:15<3:21:18,  2.80it/s, loss=0.0829]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10466/44303 [1:02:15<3:22:04,  2.79it/s, loss=0.0829]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10466/44303 [1:02:16<3:22:04,  2.79it/s, loss=0.0916]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10467/44303 [1:02:16<3:21:54,  2.79it/s, loss=0.0916]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10467/44303 [1:02:16<3:21:54,  2.79it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10468/44303 [1:02:16<3:21:36,  2.80it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10468/44303 [1:02:16<3:21:36,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10469/44303 [1:02:16<3:21:56,  2.79it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10469/44303 [1:02:17<3:21:56,  2.79it/s, loss=0.0366]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10470/44303 [1:02:17<3:22:08,  2.79it/s, loss=0.0366]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10470/44303 [1:02:17<3:22:08,  2.79it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10471/44303 [1:02:17<3:21:47,  2.79it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10471/44303 [1:02:18<3:21:47,  2.79it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10472/44303 [1:02:18<3:21:43,  2.80it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10472/44303 [1:02:18<3:21:43,  2.80it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10473/44303 [1:02:18<3:22:14,  2.79it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10473/44303 [1:02:18<3:22:14,  2.79it/s, loss=0.047] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10474/44303 [1:02:18<3:21:56,  2.79it/s, loss=0.047]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10474/44303 [1:02:19<3:21:56,  2.79it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10475/44303 [1:02:19<3:21:40,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10475/44303 [1:02:19<3:21:40,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10476/44303 [1:02:19<3:22:07,  2.79it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10476/44303 [1:02:19<3:22:07,  2.79it/s, loss=0.0812]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10477/44303 [1:02:19<3:21:29,  2.80it/s, loss=0.0812]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10477/44303 [1:02:20<3:21:29,  2.80it/s, loss=0.065] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10478/44303 [1:02:20<3:21:33,  2.80it/s, loss=0.065]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10478/44303 [1:02:20<3:21:33,  2.80it/s, loss=0.0403]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10479/44303 [1:02:20<3:22:00,  2.79it/s, loss=0.0403]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10479/44303 [1:02:20<3:22:00,  2.79it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10480/44303 [1:02:20<3:21:53,  2.79it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10480/44303 [1:02:21<3:21:53,  2.79it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10481/44303 [1:02:21<3:21:08,  2.80it/s, loss=0.0471]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10481/44303 [1:02:21<3:21:08,  2.80it/s, loss=0.028] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10482/44303 [1:02:21<3:22:23,  2.79it/s, loss=0.028]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10482/44303 [1:02:21<3:22:23,  2.79it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10483/44303 [1:02:21<3:21:56,  2.79it/s, loss=0.0518]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10483/44303 [1:02:22<3:21:56,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10484/44303 [1:02:22<3:21:52,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10484/44303 [1:02:22<3:21:52,  2.79it/s, loss=0.055] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10485/44303 [1:02:22<3:22:27,  2.78it/s, loss=0.055]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10485/44303 [1:02:23<3:22:27,  2.78it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10486/44303 [1:02:23<3:22:15,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10486/44303 [1:02:23<3:22:15,  2.79it/s, loss=0.038] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10487/44303 [1:02:23<3:21:24,  2.80it/s, loss=0.038]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10487/44303 [1:02:23<3:21:24,  2.80it/s, loss=0.0683]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10488/44303 [1:02:23<3:21:43,  2.79it/s, loss=0.0683]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10488/44303 [1:02:24<3:21:43,  2.79it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10489/44303 [1:02:24<3:21:23,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10489/44303 [1:02:24<3:21:23,  2.80it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10490/44303 [1:02:24<3:21:09,  2.80it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10490/44303 [1:02:24<3:21:09,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10491/44303 [1:02:24<3:21:32,  2.80it/s, loss=0.0478]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10491/44303 [1:02:25<3:21:32,  2.80it/s, loss=0.0853]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10492/44303 [1:02:25<3:20:34,  2.81it/s, loss=0.0853]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10492/44303 [1:02:25<3:20:34,  2.81it/s, loss=0.0255]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10493/44303 [1:02:25<3:21:20,  2.80it/s, loss=0.0255]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10493/44303 [1:02:25<3:21:20,  2.80it/s, loss=0.058] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10494/44303 [1:02:25<3:20:54,  2.80it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10494/44303 [1:02:26<3:20:54,  2.80it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10495/44303 [1:02:26<3:20:50,  2.81it/s, loss=0.0418]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10495/44303 [1:02:26<3:20:50,  2.81it/s, loss=0.0291]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10496/44303 [1:02:26<3:21:36,  2.79it/s, loss=0.0291]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10496/44303 [1:02:26<3:21:36,  2.79it/s, loss=0.0819]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10497/44303 [1:02:26<3:21:13,  2.80it/s, loss=0.0819]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10497/44303 [1:02:27<3:21:13,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10498/44303 [1:02:27<3:21:41,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10498/44303 [1:02:27<3:21:41,  2.79it/s, loss=0.0915]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10499/44303 [1:02:27<3:22:16,  2.79it/s, loss=0.0915]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10499/44303 [1:02:28<3:22:16,  2.79it/s, loss=0.065] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10500/44303 [1:02:28<3:21:03,  2.80it/s, loss=0.065]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10500/44303 [1:02:28<3:21:03,  2.80it/s, loss=0.0704]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10501/44303 [1:02:28<3:21:03,  2.80it/s, loss=0.0704]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10501/44303 [1:02:28<3:21:03,  2.80it/s, loss=0.042] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10502/44303 [1:02:28<3:21:06,  2.80it/s, loss=0.042]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10502/44303 [1:02:29<3:21:06,  2.80it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10503/44303 [1:02:29<3:20:56,  2.80it/s, loss=0.066]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10503/44303 [1:02:29<3:20:56,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10504/44303 [1:02:29<3:21:08,  2.80it/s, loss=0.0521]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10504/44303 [1:02:29<3:21:08,  2.80it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10505/44303 [1:02:29<3:21:30,  2.80it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10505/44303 [1:02:30<3:21:30,  2.80it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10506/44303 [1:02:30<3:21:09,  2.80it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10506/44303 [1:02:30<3:21:09,  2.80it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10507/44303 [1:02:30<3:20:46,  2.81it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10507/44303 [1:02:30<3:20:46,  2.81it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10508/44303 [1:02:30<3:20:50,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10508/44303 [1:02:31<3:20:50,  2.80it/s, loss=0.0598]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10509/44303 [1:02:31<3:21:31,  2.79it/s, loss=0.0598]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10509/44303 [1:02:31<3:21:31,  2.79it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10510/44303 [1:02:31<3:20:37,  2.81it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10510/44303 [1:02:31<3:20:37,  2.81it/s, loss=0.0826]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10511/44303 [1:02:31<3:21:06,  2.80it/s, loss=0.0826]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10511/44303 [1:02:32<3:21:06,  2.80it/s, loss=0.061] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10512/44303 [1:02:32<3:21:31,  2.79it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10512/44303 [1:02:32<3:21:31,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10513/44303 [1:02:32<3:21:19,  2.80it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10513/44303 [1:02:33<3:21:19,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10514/44303 [1:02:33<3:21:35,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10514/44303 [1:02:33<3:21:35,  2.79it/s, loss=0.0412]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10515/44303 [1:02:33<3:22:15,  2.78it/s, loss=0.0412]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10515/44303 [1:02:33<3:22:15,  2.78it/s, loss=0.0938]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10516/44303 [1:02:33<3:21:23,  2.80it/s, loss=0.0938]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10516/44303 [1:02:34<3:21:23,  2.80it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10517/44303 [1:02:34<3:22:06,  2.79it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10517/44303 [1:02:34<3:22:06,  2.79it/s, loss=0.0366]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10518/44303 [1:02:34<3:21:48,  2.79it/s, loss=0.0366]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10518/44303 [1:02:34<3:21:48,  2.79it/s, loss=0.041] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10519/44303 [1:02:34<3:21:09,  2.80it/s, loss=0.041]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10519/44303 [1:02:35<3:21:09,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10520/44303 [1:02:35<3:21:40,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10520/44303 [1:02:35<3:21:40,  2.79it/s, loss=0.101] \u001b[A\n","Training Epoch 1:  24%|██▎       | 10521/44303 [1:02:35<3:20:55,  2.80it/s, loss=0.101]\u001b[A\n","Training Epoch 1:  24%|██▎       | 10521/44303 [1:02:35<3:20:55,  2.80it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10522/44303 [1:02:35<3:21:40,  2.79it/s, loss=0.0573]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10522/44303 [1:02:36<3:21:40,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10523/44303 [1:02:36<3:21:42,  2.79it/s, loss=0.0547]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10523/44303 [1:02:36<3:21:42,  2.79it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10524/44303 [1:02:36<3:21:16,  2.80it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10524/44303 [1:02:37<3:21:16,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10525/44303 [1:02:37<3:21:02,  2.80it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10525/44303 [1:02:37<3:21:02,  2.80it/s, loss=0.0298]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10526/44303 [1:02:37<3:20:57,  2.80it/s, loss=0.0298]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10526/44303 [1:02:37<3:20:57,  2.80it/s, loss=0.0569]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10527/44303 [1:02:37<3:20:55,  2.80it/s, loss=0.0569]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10527/44303 [1:02:38<3:20:55,  2.80it/s, loss=0.0314]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10528/44303 [1:02:38<3:21:30,  2.79it/s, loss=0.0314]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10528/44303 [1:02:38<3:21:30,  2.79it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10529/44303 [1:02:38<3:20:39,  2.81it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10529/44303 [1:02:38<3:20:39,  2.81it/s, loss=0.0911]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10530/44303 [1:02:38<3:21:03,  2.80it/s, loss=0.0911]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10530/44303 [1:02:39<3:21:03,  2.80it/s, loss=0.053] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10531/44303 [1:02:39<3:20:43,  2.80it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10531/44303 [1:02:39<3:20:43,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10532/44303 [1:02:39<3:20:33,  2.81it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10532/44303 [1:02:39<3:20:33,  2.81it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10533/44303 [1:02:39<3:20:20,  2.81it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10533/44303 [1:02:40<3:20:20,  2.81it/s, loss=0.0574]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10534/44303 [1:02:40<3:20:20,  2.81it/s, loss=0.0574]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10534/44303 [1:02:40<3:20:20,  2.81it/s, loss=0.0741]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10535/44303 [1:02:40<3:21:01,  2.80it/s, loss=0.0741]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10535/44303 [1:02:40<3:21:01,  2.80it/s, loss=0.104] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10536/44303 [1:02:40<3:21:00,  2.80it/s, loss=0.104]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10536/44303 [1:02:41<3:21:00,  2.80it/s, loss=0.0363]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10537/44303 [1:02:41<3:21:32,  2.79it/s, loss=0.0363]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10537/44303 [1:02:41<3:21:32,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10538/44303 [1:02:41<3:21:42,  2.79it/s, loss=0.0626]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10538/44303 [1:02:42<3:21:42,  2.79it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10539/44303 [1:02:42<3:21:11,  2.80it/s, loss=0.0466]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10539/44303 [1:02:42<3:21:11,  2.80it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10540/44303 [1:02:42<3:21:29,  2.79it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10540/44303 [1:02:42<3:21:29,  2.79it/s, loss=0.065] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10541/44303 [1:02:42<3:21:34,  2.79it/s, loss=0.065]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10541/44303 [1:02:43<3:21:34,  2.79it/s, loss=0.0965]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10542/44303 [1:02:43<3:21:26,  2.79it/s, loss=0.0965]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10542/44303 [1:02:43<3:21:26,  2.79it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10543/44303 [1:02:43<3:21:33,  2.79it/s, loss=0.0762]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10543/44303 [1:02:43<3:21:33,  2.79it/s, loss=0.0337]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10544/44303 [1:02:43<3:21:35,  2.79it/s, loss=0.0337]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10544/44303 [1:02:44<3:21:35,  2.79it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10545/44303 [1:02:44<3:21:29,  2.79it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10545/44303 [1:02:44<3:21:29,  2.79it/s, loss=0.0596]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10546/44303 [1:02:44<3:21:33,  2.79it/s, loss=0.0596]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10546/44303 [1:02:44<3:21:33,  2.79it/s, loss=0.056] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10547/44303 [1:02:44<3:21:42,  2.79it/s, loss=0.056]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10547/44303 [1:02:45<3:21:42,  2.79it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10548/44303 [1:02:45<3:20:50,  2.80it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10548/44303 [1:02:45<3:20:50,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10549/44303 [1:02:45<3:20:46,  2.80it/s, loss=0.0576]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10549/44303 [1:02:45<3:20:46,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10550/44303 [1:02:45<3:20:43,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10550/44303 [1:02:46<3:20:43,  2.80it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10551/44303 [1:02:46<3:20:27,  2.81it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10551/44303 [1:02:46<3:20:27,  2.81it/s, loss=0.0422]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10552/44303 [1:02:46<3:19:54,  2.81it/s, loss=0.0422]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10552/44303 [1:02:47<3:19:54,  2.81it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10553/44303 [1:02:47<3:20:03,  2.81it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10553/44303 [1:02:47<3:20:03,  2.81it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10554/44303 [1:02:47<3:19:36,  2.82it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10554/44303 [1:02:47<3:19:36,  2.82it/s, loss=0.0644]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10555/44303 [1:02:47<3:19:48,  2.81it/s, loss=0.0644]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10555/44303 [1:02:48<3:19:48,  2.81it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10556/44303 [1:02:48<3:20:36,  2.80it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10556/44303 [1:02:48<3:20:36,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10557/44303 [1:02:48<3:20:23,  2.81it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10557/44303 [1:02:48<3:20:23,  2.81it/s, loss=0.04]  \u001b[A\n","Training Epoch 1:  24%|██▍       | 10558/44303 [1:02:48<3:20:30,  2.80it/s, loss=0.04]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10558/44303 [1:02:49<3:20:30,  2.80it/s, loss=0.0785]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10559/44303 [1:02:49<3:20:07,  2.81it/s, loss=0.0785]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10559/44303 [1:02:49<3:20:07,  2.81it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10560/44303 [1:02:49<3:20:36,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10560/44303 [1:02:49<3:20:36,  2.80it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10561/44303 [1:02:49<3:20:50,  2.80it/s, loss=0.0408]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10561/44303 [1:02:50<3:20:50,  2.80it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10562/44303 [1:02:50<3:20:21,  2.81it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10562/44303 [1:02:50<3:20:21,  2.81it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10563/44303 [1:02:50<3:20:34,  2.80it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10563/44303 [1:02:50<3:20:34,  2.80it/s, loss=0.0365]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10564/44303 [1:02:50<3:20:41,  2.80it/s, loss=0.0365]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10564/44303 [1:02:51<3:20:41,  2.80it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10565/44303 [1:02:51<3:20:20,  2.81it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10565/44303 [1:02:51<3:20:20,  2.81it/s, loss=0.045] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10566/44303 [1:02:51<3:20:54,  2.80it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10566/44303 [1:02:51<3:20:54,  2.80it/s, loss=0.0866]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10567/44303 [1:02:52<3:20:31,  2.80it/s, loss=0.0866]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10567/44303 [1:02:52<3:20:31,  2.80it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10568/44303 [1:02:52<3:20:40,  2.80it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10568/44303 [1:02:52<3:20:40,  2.80it/s, loss=0.0316]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10569/44303 [1:02:52<3:21:03,  2.80it/s, loss=0.0316]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10569/44303 [1:02:53<3:21:03,  2.80it/s, loss=0.0593]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10570/44303 [1:02:53<3:20:16,  2.81it/s, loss=0.0593]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10570/44303 [1:02:53<3:20:16,  2.81it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10571/44303 [1:02:53<3:20:16,  2.81it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10571/44303 [1:02:53<3:20:16,  2.81it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10572/44303 [1:02:53<3:20:58,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10572/44303 [1:02:54<3:20:58,  2.80it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10573/44303 [1:02:54<3:20:33,  2.80it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10573/44303 [1:02:54<3:20:33,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10574/44303 [1:02:54<3:20:41,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10574/44303 [1:02:54<3:20:41,  2.80it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10575/44303 [1:02:54<3:20:13,  2.81it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10575/44303 [1:02:55<3:20:13,  2.81it/s, loss=0.0692]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10576/44303 [1:02:55<3:20:39,  2.80it/s, loss=0.0692]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10576/44303 [1:02:55<3:20:39,  2.80it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10577/44303 [1:02:55<3:20:56,  2.80it/s, loss=0.0449]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10577/44303 [1:02:55<3:20:56,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10578/44303 [1:02:55<3:20:43,  2.80it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10578/44303 [1:02:56<3:20:43,  2.80it/s, loss=0.0271]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10579/44303 [1:02:56<3:20:50,  2.80it/s, loss=0.0271]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10579/44303 [1:02:56<3:20:50,  2.80it/s, loss=0.0403]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10580/44303 [1:02:56<3:20:52,  2.80it/s, loss=0.0403]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10580/44303 [1:02:56<3:20:52,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10581/44303 [1:02:56<3:20:27,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10581/44303 [1:02:57<3:20:27,  2.80it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10582/44303 [1:02:57<3:20:47,  2.80it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10582/44303 [1:02:57<3:20:47,  2.80it/s, loss=0.0388]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10583/44303 [1:02:57<3:19:58,  2.81it/s, loss=0.0388]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10583/44303 [1:02:58<3:19:58,  2.81it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10584/44303 [1:02:58<3:20:25,  2.80it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10584/44303 [1:02:58<3:20:25,  2.80it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10585/44303 [1:02:58<3:20:02,  2.81it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10585/44303 [1:02:58<3:20:02,  2.81it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10586/44303 [1:02:58<3:20:04,  2.81it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10586/44303 [1:02:59<3:20:04,  2.81it/s, loss=0.0443]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10587/44303 [1:02:59<3:20:09,  2.81it/s, loss=0.0443]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10587/44303 [1:02:59<3:20:09,  2.81it/s, loss=0.0809]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10588/44303 [1:02:59<3:20:24,  2.80it/s, loss=0.0809]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10588/44303 [1:02:59<3:20:24,  2.80it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10589/44303 [1:02:59<3:20:19,  2.80it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10589/44303 [1:03:00<3:20:19,  2.80it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10590/44303 [1:03:00<3:21:22,  2.79it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10590/44303 [1:03:00<3:21:22,  2.79it/s, loss=0.058] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10591/44303 [1:03:00<3:20:31,  2.80it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10591/44303 [1:03:00<3:20:31,  2.80it/s, loss=0.0264]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10592/44303 [1:03:00<3:21:25,  2.79it/s, loss=0.0264]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10592/44303 [1:03:01<3:21:25,  2.79it/s, loss=0.0595]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10593/44303 [1:03:01<3:21:25,  2.79it/s, loss=0.0595]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10593/44303 [1:03:01<3:21:25,  2.79it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10594/44303 [1:03:01<3:21:23,  2.79it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10594/44303 [1:03:02<3:21:23,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10595/44303 [1:03:02<3:21:26,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10595/44303 [1:03:02<3:21:26,  2.79it/s, loss=0.0819]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10596/44303 [1:03:02<3:21:24,  2.79it/s, loss=0.0819]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10596/44303 [1:03:02<3:21:24,  2.79it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10597/44303 [1:03:02<3:21:21,  2.79it/s, loss=0.0666]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10597/44303 [1:03:03<3:21:21,  2.79it/s, loss=0.0427]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10598/44303 [1:03:03<3:21:13,  2.79it/s, loss=0.0427]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10598/44303 [1:03:03<3:21:13,  2.79it/s, loss=0.0469]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10599/44303 [1:03:03<3:21:46,  2.78it/s, loss=0.0469]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10599/44303 [1:03:03<3:21:46,  2.78it/s, loss=0.0831]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10600/44303 [1:03:03<3:21:00,  2.79it/s, loss=0.0831]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10600/44303 [1:03:04<3:21:00,  2.79it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10601/44303 [1:03:04<3:20:12,  2.81it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10601/44303 [1:03:04<3:20:12,  2.81it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10602/44303 [1:03:04<3:20:59,  2.79it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10602/44303 [1:03:04<3:20:59,  2.79it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10603/44303 [1:03:04<3:20:47,  2.80it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10603/44303 [1:03:05<3:20:47,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10604/44303 [1:03:05<3:21:05,  2.79it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10604/44303 [1:03:05<3:21:05,  2.79it/s, loss=0.0715]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10605/44303 [1:03:05<3:21:35,  2.79it/s, loss=0.0715]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10605/44303 [1:03:05<3:21:35,  2.79it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10606/44303 [1:03:05<3:21:13,  2.79it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10606/44303 [1:03:06<3:21:13,  2.79it/s, loss=0.0239]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10607/44303 [1:03:06<3:20:45,  2.80it/s, loss=0.0239]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10607/44303 [1:03:06<3:20:45,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10608/44303 [1:03:06<3:21:18,  2.79it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10608/44303 [1:03:07<3:21:18,  2.79it/s, loss=0.022] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10609/44303 [1:03:07<3:20:50,  2.80it/s, loss=0.022]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10609/44303 [1:03:07<3:20:50,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10610/44303 [1:03:07<3:20:28,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10610/44303 [1:03:07<3:20:28,  2.80it/s, loss=0.065] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10611/44303 [1:03:07<3:21:13,  2.79it/s, loss=0.065]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10611/44303 [1:03:08<3:21:13,  2.79it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10612/44303 [1:03:08<3:20:53,  2.80it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10612/44303 [1:03:08<3:20:53,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10613/44303 [1:03:08<3:20:34,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10613/44303 [1:03:08<3:20:34,  2.80it/s, loss=0.0885]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10614/44303 [1:03:08<3:21:02,  2.79it/s, loss=0.0885]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10614/44303 [1:03:09<3:21:02,  2.79it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10615/44303 [1:03:09<3:21:39,  2.78it/s, loss=0.0396]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10615/44303 [1:03:09<3:21:39,  2.78it/s, loss=0.061] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10616/44303 [1:03:09<3:20:51,  2.80it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10616/44303 [1:03:09<3:20:51,  2.80it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10617/44303 [1:03:09<3:20:45,  2.80it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10617/44303 [1:03:10<3:20:45,  2.80it/s, loss=0.0342]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10618/44303 [1:03:10<3:21:03,  2.79it/s, loss=0.0342]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10618/44303 [1:03:10<3:21:03,  2.79it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10619/44303 [1:03:10<3:20:00,  2.81it/s, loss=0.0426]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10619/44303 [1:03:10<3:20:00,  2.81it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10620/44303 [1:03:10<3:20:41,  2.80it/s, loss=0.0752]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10620/44303 [1:03:11<3:20:41,  2.80it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10621/44303 [1:03:11<3:21:09,  2.79it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10621/44303 [1:03:11<3:21:09,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10622/44303 [1:03:11<3:20:30,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10622/44303 [1:03:12<3:20:30,  2.80it/s, loss=0.0693]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10623/44303 [1:03:12<3:20:46,  2.80it/s, loss=0.0693]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10623/44303 [1:03:12<3:20:46,  2.80it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10624/44303 [1:03:12<3:20:27,  2.80it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10624/44303 [1:03:12<3:20:27,  2.80it/s, loss=0.107] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10625/44303 [1:03:12<3:20:11,  2.80it/s, loss=0.107]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10625/44303 [1:03:13<3:20:11,  2.80it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10626/44303 [1:03:13<3:21:04,  2.79it/s, loss=0.0549]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10626/44303 [1:03:13<3:21:04,  2.79it/s, loss=0.0436]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10627/44303 [1:03:13<3:20:38,  2.80it/s, loss=0.0436]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10627/44303 [1:03:13<3:20:38,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10628/44303 [1:03:13<3:20:31,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10628/44303 [1:03:14<3:20:31,  2.80it/s, loss=0.0952]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10629/44303 [1:03:14<3:20:54,  2.79it/s, loss=0.0952]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10629/44303 [1:03:14<3:20:54,  2.79it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10630/44303 [1:03:14<3:21:03,  2.79it/s, loss=0.0336]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10630/44303 [1:03:14<3:21:03,  2.79it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10631/44303 [1:03:14<3:20:35,  2.80it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10631/44303 [1:03:15<3:20:35,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10632/44303 [1:03:15<3:21:00,  2.79it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10632/44303 [1:03:15<3:21:00,  2.79it/s, loss=0.111] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10633/44303 [1:03:15<3:20:59,  2.79it/s, loss=0.111]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10633/44303 [1:03:15<3:20:59,  2.79it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10634/44303 [1:03:15<3:20:31,  2.80it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10634/44303 [1:03:16<3:20:31,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10635/44303 [1:03:16<3:20:45,  2.80it/s, loss=0.0605]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10635/44303 [1:03:16<3:20:45,  2.80it/s, loss=0.0962]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10636/44303 [1:03:16<3:21:10,  2.79it/s, loss=0.0962]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10636/44303 [1:03:17<3:21:10,  2.79it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10637/44303 [1:03:17<3:20:57,  2.79it/s, loss=0.0392]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10637/44303 [1:03:17<3:20:57,  2.79it/s, loss=0.0585]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10638/44303 [1:03:17<3:20:34,  2.80it/s, loss=0.0585]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10638/44303 [1:03:17<3:20:34,  2.80it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10639/44303 [1:03:17<3:19:36,  2.81it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10639/44303 [1:03:18<3:19:36,  2.81it/s, loss=0.108] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10640/44303 [1:03:18<3:20:05,  2.80it/s, loss=0.108]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10640/44303 [1:03:18<3:20:05,  2.80it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10641/44303 [1:03:18<3:20:03,  2.80it/s, loss=0.046]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10641/44303 [1:03:18<3:20:03,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10642/44303 [1:03:18<3:19:58,  2.81it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10642/44303 [1:03:19<3:19:58,  2.81it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10643/44303 [1:03:19<3:20:43,  2.79it/s, loss=0.0383]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10643/44303 [1:03:19<3:20:43,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10644/44303 [1:03:19<3:20:19,  2.80it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10644/44303 [1:03:19<3:20:19,  2.80it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10645/44303 [1:03:19<3:20:29,  2.80it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10645/44303 [1:03:20<3:20:29,  2.80it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10646/44303 [1:03:20<3:20:43,  2.79it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10646/44303 [1:03:20<3:20:43,  2.79it/s, loss=0.0988]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10647/44303 [1:03:20<3:19:55,  2.81it/s, loss=0.0988]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10647/44303 [1:03:20<3:19:55,  2.81it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10648/44303 [1:03:20<3:20:33,  2.80it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10648/44303 [1:03:21<3:20:33,  2.80it/s, loss=0.0628]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10649/44303 [1:03:21<3:20:16,  2.80it/s, loss=0.0628]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10649/44303 [1:03:21<3:20:16,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10650/44303 [1:03:21<3:20:11,  2.80it/s, loss=0.0709]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10650/44303 [1:03:22<3:20:11,  2.80it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10651/44303 [1:03:22<3:20:33,  2.80it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10651/44303 [1:03:22<3:20:33,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10652/44303 [1:03:22<3:20:28,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10652/44303 [1:03:22<3:20:28,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10653/44303 [1:03:22<3:20:22,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10653/44303 [1:03:23<3:20:22,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10654/44303 [1:03:23<3:20:27,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10654/44303 [1:03:23<3:20:27,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10655/44303 [1:03:23<3:20:41,  2.79it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10655/44303 [1:03:23<3:20:41,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10656/44303 [1:03:23<3:21:01,  2.79it/s, loss=0.0487]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10656/44303 [1:03:24<3:21:01,  2.79it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10657/44303 [1:03:24<3:21:28,  2.78it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10657/44303 [1:03:24<3:21:28,  2.78it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10658/44303 [1:03:24<3:20:40,  2.79it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10658/44303 [1:03:24<3:20:40,  2.79it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10659/44303 [1:03:24<3:20:10,  2.80it/s, loss=0.0455]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10659/44303 [1:03:25<3:20:10,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10660/44303 [1:03:25<3:20:39,  2.79it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10660/44303 [1:03:25<3:20:39,  2.79it/s, loss=0.0756]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10661/44303 [1:03:25<3:20:10,  2.80it/s, loss=0.0756]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10661/44303 [1:03:25<3:20:10,  2.80it/s, loss=0.0983]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10662/44303 [1:03:25<3:20:15,  2.80it/s, loss=0.0983]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10662/44303 [1:03:26<3:20:15,  2.80it/s, loss=0.0689]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10663/44303 [1:03:26<3:20:12,  2.80it/s, loss=0.0689]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10663/44303 [1:03:26<3:20:12,  2.80it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10664/44303 [1:03:26<3:20:01,  2.80it/s, loss=0.0496]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10664/44303 [1:03:27<3:20:01,  2.80it/s, loss=0.0274]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10665/44303 [1:03:27<3:20:17,  2.80it/s, loss=0.0274]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10665/44303 [1:03:27<3:20:17,  2.80it/s, loss=0.0432]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10666/44303 [1:03:27<3:19:36,  2.81it/s, loss=0.0432]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10666/44303 [1:03:27<3:19:36,  2.81it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10667/44303 [1:03:27<3:19:48,  2.81it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10667/44303 [1:03:28<3:19:48,  2.81it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10668/44303 [1:03:28<3:19:53,  2.80it/s, loss=0.0757]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10668/44303 [1:03:28<3:19:53,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10669/44303 [1:03:28<3:20:45,  2.79it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10669/44303 [1:03:28<3:20:45,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10670/44303 [1:03:28<3:20:18,  2.80it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10670/44303 [1:03:29<3:20:18,  2.80it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10671/44303 [1:03:29<3:20:15,  2.80it/s, loss=0.0697]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10671/44303 [1:03:29<3:20:15,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10672/44303 [1:03:29<3:19:43,  2.81it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10672/44303 [1:03:29<3:19:43,  2.81it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10673/44303 [1:03:29<3:20:18,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10673/44303 [1:03:30<3:20:18,  2.80it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10674/44303 [1:03:30<3:19:35,  2.81it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10674/44303 [1:03:30<3:19:35,  2.81it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10675/44303 [1:03:30<3:19:41,  2.81it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10675/44303 [1:03:30<3:19:41,  2.81it/s, loss=0.051] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10676/44303 [1:03:30<3:21:00,  2.79it/s, loss=0.051]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10676/44303 [1:03:31<3:21:00,  2.79it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10677/44303 [1:03:31<3:20:07,  2.80it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10677/44303 [1:03:31<3:20:07,  2.80it/s, loss=0.0764]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10678/44303 [1:03:31<3:20:34,  2.79it/s, loss=0.0764]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10678/44303 [1:03:32<3:20:34,  2.79it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10679/44303 [1:03:32<3:20:58,  2.79it/s, loss=0.0534]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10679/44303 [1:03:32<3:20:58,  2.79it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10680/44303 [1:03:32<3:19:42,  2.81it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10680/44303 [1:03:32<3:19:42,  2.81it/s, loss=0.0367]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10681/44303 [1:03:32<3:20:12,  2.80it/s, loss=0.0367]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10681/44303 [1:03:33<3:20:12,  2.80it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10682/44303 [1:03:33<3:19:44,  2.81it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10682/44303 [1:03:33<3:19:44,  2.81it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10683/44303 [1:03:33<3:20:11,  2.80it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10683/44303 [1:03:33<3:20:11,  2.80it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10684/44303 [1:03:33<3:20:15,  2.80it/s, loss=0.0639]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10684/44303 [1:03:34<3:20:15,  2.80it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10685/44303 [1:03:34<3:20:06,  2.80it/s, loss=0.0391]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10685/44303 [1:03:34<3:20:06,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10686/44303 [1:03:34<3:19:59,  2.80it/s, loss=0.0501]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10686/44303 [1:03:34<3:19:59,  2.80it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10687/44303 [1:03:34<3:19:15,  2.81it/s, loss=0.0559]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10687/44303 [1:03:35<3:19:15,  2.81it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10688/44303 [1:03:35<3:19:50,  2.80it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10688/44303 [1:03:35<3:19:50,  2.80it/s, loss=0.0644]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10689/44303 [1:03:35<3:19:43,  2.81it/s, loss=0.0644]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10689/44303 [1:03:35<3:19:43,  2.81it/s, loss=0.0378]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10690/44303 [1:03:35<3:19:25,  2.81it/s, loss=0.0378]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10690/44303 [1:03:36<3:19:25,  2.81it/s, loss=0.0257]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10691/44303 [1:03:36<3:20:03,  2.80it/s, loss=0.0257]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10691/44303 [1:03:36<3:20:03,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10692/44303 [1:03:36<3:19:17,  2.81it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10692/44303 [1:03:37<3:19:17,  2.81it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10693/44303 [1:03:37<3:19:56,  2.80it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10693/44303 [1:03:37<3:19:56,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10694/44303 [1:03:37<3:20:25,  2.79it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10694/44303 [1:03:37<3:20:25,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10695/44303 [1:03:37<3:20:09,  2.80it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10695/44303 [1:03:38<3:20:09,  2.80it/s, loss=0.07]  \u001b[A\n","Training Epoch 1:  24%|██▍       | 10696/44303 [1:03:38<3:20:19,  2.80it/s, loss=0.07]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10696/44303 [1:03:38<3:20:19,  2.80it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10697/44303 [1:03:38<3:19:58,  2.80it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10697/44303 [1:03:38<3:19:58,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10698/44303 [1:03:38<3:20:01,  2.80it/s, loss=0.0482]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10698/44303 [1:03:39<3:20:01,  2.80it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10699/44303 [1:03:39<3:20:15,  2.80it/s, loss=0.0514]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10699/44303 [1:03:39<3:20:15,  2.80it/s, loss=0.0529]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10700/44303 [1:03:39<3:20:07,  2.80it/s, loss=0.0529]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10700/44303 [1:03:39<3:20:07,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10701/44303 [1:03:39<3:20:11,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10701/44303 [1:03:40<3:20:11,  2.80it/s, loss=0.0513]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10702/44303 [1:03:40<3:20:31,  2.79it/s, loss=0.0513]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10702/44303 [1:03:40<3:20:31,  2.79it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10703/44303 [1:03:40<3:20:23,  2.79it/s, loss=0.0606]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10703/44303 [1:03:40<3:20:23,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10704/44303 [1:03:40<3:20:33,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10704/44303 [1:03:41<3:20:33,  2.79it/s, loss=0.0738]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10705/44303 [1:03:41<3:20:42,  2.79it/s, loss=0.0738]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10705/44303 [1:03:41<3:20:42,  2.79it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10706/44303 [1:03:41<3:20:05,  2.80it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10706/44303 [1:03:42<3:20:05,  2.80it/s, loss=0.0787]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10707/44303 [1:03:42<3:20:00,  2.80it/s, loss=0.0787]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10707/44303 [1:03:42<3:20:00,  2.80it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10708/44303 [1:03:42<3:20:02,  2.80it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10708/44303 [1:03:42<3:20:02,  2.80it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10709/44303 [1:03:42<3:19:22,  2.81it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10709/44303 [1:03:43<3:19:22,  2.81it/s, loss=0.061] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10710/44303 [1:03:43<3:20:07,  2.80it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10710/44303 [1:03:43<3:20:07,  2.80it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10711/44303 [1:03:43<3:19:05,  2.81it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10711/44303 [1:03:43<3:19:05,  2.81it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10712/44303 [1:03:43<3:19:43,  2.80it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10712/44303 [1:03:44<3:19:43,  2.80it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10713/44303 [1:03:44<3:19:32,  2.81it/s, loss=0.0565]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10713/44303 [1:03:44<3:19:32,  2.81it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10714/44303 [1:03:44<3:20:10,  2.80it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10714/44303 [1:03:44<3:20:10,  2.80it/s, loss=0.095] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10715/44303 [1:03:44<3:19:52,  2.80it/s, loss=0.095]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10715/44303 [1:03:45<3:19:52,  2.80it/s, loss=0.0305]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10716/44303 [1:03:45<3:19:32,  2.81it/s, loss=0.0305]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10716/44303 [1:03:45<3:19:32,  2.81it/s, loss=0.0441]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10717/44303 [1:03:45<3:20:22,  2.79it/s, loss=0.0441]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10717/44303 [1:03:45<3:20:22,  2.79it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10718/44303 [1:03:45<3:19:44,  2.80it/s, loss=0.0552]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10718/44303 [1:03:46<3:19:44,  2.80it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10719/44303 [1:03:46<3:20:19,  2.79it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10719/44303 [1:03:46<3:20:19,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10720/44303 [1:03:46<3:20:28,  2.79it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10720/44303 [1:03:47<3:20:28,  2.79it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10721/44303 [1:03:47<3:19:55,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10721/44303 [1:03:47<3:19:55,  2.80it/s, loss=0.103] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10722/44303 [1:03:47<3:20:51,  2.79it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10722/44303 [1:03:47<3:20:51,  2.79it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10723/44303 [1:03:47<3:20:57,  2.78it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10723/44303 [1:03:48<3:20:57,  2.78it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10724/44303 [1:03:48<3:19:38,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10724/44303 [1:03:48<3:19:38,  2.80it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10725/44303 [1:03:48<3:19:41,  2.80it/s, loss=0.0395]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10725/44303 [1:03:48<3:19:41,  2.80it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10726/44303 [1:03:48<3:19:51,  2.80it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10726/44303 [1:03:49<3:19:51,  2.80it/s, loss=0.0603]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10727/44303 [1:03:49<3:19:56,  2.80it/s, loss=0.0603]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10727/44303 [1:03:49<3:19:56,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10728/44303 [1:03:49<3:20:03,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10728/44303 [1:03:49<3:20:03,  2.80it/s, loss=0.0445]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10729/44303 [1:03:49<3:20:34,  2.79it/s, loss=0.0445]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10729/44303 [1:03:50<3:20:34,  2.79it/s, loss=0.089] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10730/44303 [1:03:50<3:20:08,  2.80it/s, loss=0.089]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10730/44303 [1:03:50<3:20:08,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10731/44303 [1:03:50<3:19:54,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10731/44303 [1:03:50<3:19:54,  2.80it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10732/44303 [1:03:50<3:19:44,  2.80it/s, loss=0.0571]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10732/44303 [1:03:51<3:19:44,  2.80it/s, loss=0.192] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10733/44303 [1:03:51<3:20:21,  2.79it/s, loss=0.192]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10733/44303 [1:03:51<3:20:21,  2.79it/s, loss=0.074]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10734/44303 [1:03:51<3:21:12,  2.78it/s, loss=0.074]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10734/44303 [1:03:52<3:21:12,  2.78it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10735/44303 [1:03:52<3:20:47,  2.79it/s, loss=0.0486]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10735/44303 [1:03:52<3:20:47,  2.79it/s, loss=0.0719]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10736/44303 [1:03:52<3:20:59,  2.78it/s, loss=0.0719]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10736/44303 [1:03:52<3:20:59,  2.78it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10737/44303 [1:03:52<3:20:21,  2.79it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10737/44303 [1:03:53<3:20:21,  2.79it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10738/44303 [1:03:53<3:19:34,  2.80it/s, loss=0.0723]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10738/44303 [1:03:53<3:19:34,  2.80it/s, loss=0.0526]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10739/44303 [1:03:53<3:20:22,  2.79it/s, loss=0.0526]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10739/44303 [1:03:53<3:20:22,  2.79it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10740/44303 [1:03:53<3:20:30,  2.79it/s, loss=0.0581]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10740/44303 [1:03:54<3:20:30,  2.79it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10741/44303 [1:03:54<3:19:10,  2.81it/s, loss=0.0397]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10741/44303 [1:03:54<3:19:10,  2.81it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10742/44303 [1:03:54<3:19:42,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10742/44303 [1:03:54<3:19:42,  2.80it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10743/44303 [1:03:54<3:19:38,  2.80it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10743/44303 [1:03:55<3:19:38,  2.80it/s, loss=0.0256]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10744/44303 [1:03:55<3:19:52,  2.80it/s, loss=0.0256]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10744/44303 [1:03:55<3:19:52,  2.80it/s, loss=0.0513]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10745/44303 [1:03:55<3:20:40,  2.79it/s, loss=0.0513]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10745/44303 [1:03:55<3:20:40,  2.79it/s, loss=0.0841]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10746/44303 [1:03:55<3:20:30,  2.79it/s, loss=0.0841]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10746/44303 [1:03:56<3:20:30,  2.79it/s, loss=0.057] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10747/44303 [1:03:56<3:20:59,  2.78it/s, loss=0.057]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10747/44303 [1:03:56<3:20:59,  2.78it/s, loss=0.048]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10748/44303 [1:03:56<3:20:19,  2.79it/s, loss=0.048]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10748/44303 [1:03:57<3:20:19,  2.79it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10749/44303 [1:03:57<3:20:34,  2.79it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10749/44303 [1:03:57<3:20:34,  2.79it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10750/44303 [1:03:57<3:19:54,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10750/44303 [1:03:57<3:19:54,  2.80it/s, loss=0.0787]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10751/44303 [1:03:57<3:19:44,  2.80it/s, loss=0.0787]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10751/44303 [1:03:58<3:19:44,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10752/44303 [1:03:58<3:19:59,  2.80it/s, loss=0.0672]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10752/44303 [1:03:58<3:19:59,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10753/44303 [1:03:58<3:19:37,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10753/44303 [1:03:58<3:19:37,  2.80it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10754/44303 [1:03:58<3:19:33,  2.80it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10754/44303 [1:03:59<3:19:33,  2.80it/s, loss=0.0681]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10755/44303 [1:03:59<3:19:41,  2.80it/s, loss=0.0681]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10755/44303 [1:03:59<3:19:41,  2.80it/s, loss=0.0731]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10756/44303 [1:03:59<3:19:55,  2.80it/s, loss=0.0731]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10756/44303 [1:03:59<3:19:55,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10757/44303 [1:03:59<3:19:31,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10757/44303 [1:04:00<3:19:31,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10758/44303 [1:04:00<3:19:11,  2.81it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10758/44303 [1:04:00<3:19:11,  2.81it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10759/44303 [1:04:00<3:19:37,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10759/44303 [1:04:00<3:19:37,  2.80it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10760/44303 [1:04:00<3:19:41,  2.80it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10760/44303 [1:04:01<3:19:41,  2.80it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10761/44303 [1:04:01<3:19:09,  2.81it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10761/44303 [1:04:01<3:19:09,  2.81it/s, loss=0.0327]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10762/44303 [1:04:01<3:19:41,  2.80it/s, loss=0.0327]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10762/44303 [1:04:02<3:19:41,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10763/44303 [1:04:02<3:19:38,  2.80it/s, loss=0.0676]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10763/44303 [1:04:02<3:19:38,  2.80it/s, loss=0.0331]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10764/44303 [1:04:02<3:19:04,  2.81it/s, loss=0.0331]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10764/44303 [1:04:02<3:19:04,  2.81it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10765/44303 [1:04:02<3:19:50,  2.80it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10765/44303 [1:04:03<3:19:50,  2.80it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10766/44303 [1:04:03<3:19:07,  2.81it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10766/44303 [1:04:03<3:19:07,  2.81it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10767/44303 [1:04:03<3:19:39,  2.80it/s, loss=0.0555]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10767/44303 [1:04:03<3:19:39,  2.80it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10768/44303 [1:04:03<3:20:10,  2.79it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10768/44303 [1:04:04<3:20:10,  2.79it/s, loss=0.069] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10769/44303 [1:04:04<3:20:11,  2.79it/s, loss=0.069]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10769/44303 [1:04:04<3:20:11,  2.79it/s, loss=0.0778]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10770/44303 [1:04:04<3:19:56,  2.80it/s, loss=0.0778]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10770/44303 [1:04:04<3:19:56,  2.80it/s, loss=0.0319]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10771/44303 [1:04:04<3:20:35,  2.79it/s, loss=0.0319]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10771/44303 [1:04:05<3:20:35,  2.79it/s, loss=0.0961]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10772/44303 [1:04:05<3:19:27,  2.80it/s, loss=0.0961]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10772/44303 [1:04:05<3:19:27,  2.80it/s, loss=0.052] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10773/44303 [1:04:05<3:18:57,  2.81it/s, loss=0.052]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10773/44303 [1:04:05<3:18:57,  2.81it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10774/44303 [1:04:05<3:19:35,  2.80it/s, loss=0.0852]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10774/44303 [1:04:06<3:19:35,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10775/44303 [1:04:06<3:19:23,  2.80it/s, loss=0.0502]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10775/44303 [1:04:06<3:19:23,  2.80it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10776/44303 [1:04:06<3:19:23,  2.80it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10776/44303 [1:04:07<3:19:23,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10777/44303 [1:04:07<3:19:19,  2.80it/s, loss=0.0507]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10777/44303 [1:04:07<3:19:19,  2.80it/s, loss=0.0575]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10778/44303 [1:04:07<3:19:40,  2.80it/s, loss=0.0575]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10778/44303 [1:04:07<3:19:40,  2.80it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10779/44303 [1:04:07<3:19:57,  2.79it/s, loss=0.0535]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10779/44303 [1:04:08<3:19:57,  2.79it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10780/44303 [1:04:08<3:19:20,  2.80it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10780/44303 [1:04:08<3:19:20,  2.80it/s, loss=0.08]  \u001b[A\n","Training Epoch 1:  24%|██▍       | 10781/44303 [1:04:08<3:20:01,  2.79it/s, loss=0.08]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10781/44303 [1:04:08<3:20:01,  2.79it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10782/44303 [1:04:08<3:20:15,  2.79it/s, loss=0.0467]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10782/44303 [1:04:09<3:20:15,  2.79it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10783/44303 [1:04:09<3:18:56,  2.81it/s, loss=0.0424]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10783/44303 [1:04:09<3:18:56,  2.81it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10784/44303 [1:04:09<3:19:40,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10784/44303 [1:04:09<3:19:40,  2.80it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10785/44303 [1:04:09<3:19:42,  2.80it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10785/44303 [1:04:10<3:19:42,  2.80it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10786/44303 [1:04:10<3:18:48,  2.81it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10786/44303 [1:04:10<3:18:48,  2.81it/s, loss=0.038] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10787/44303 [1:04:10<3:19:55,  2.79it/s, loss=0.038]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10787/44303 [1:04:10<3:19:55,  2.79it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10788/44303 [1:04:10<3:19:08,  2.80it/s, loss=0.0561]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10788/44303 [1:04:11<3:19:08,  2.80it/s, loss=0.0323]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10789/44303 [1:04:11<3:19:57,  2.79it/s, loss=0.0323]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10789/44303 [1:04:11<3:19:57,  2.79it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10790/44303 [1:04:11<3:20:03,  2.79it/s, loss=0.0462]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10790/44303 [1:04:12<3:20:03,  2.79it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10791/44303 [1:04:12<3:20:08,  2.79it/s, loss=0.0564]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10791/44303 [1:04:12<3:20:08,  2.79it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10792/44303 [1:04:12<3:19:43,  2.80it/s, loss=0.0373]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10792/44303 [1:04:12<3:19:43,  2.80it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10793/44303 [1:04:12<3:19:59,  2.79it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10793/44303 [1:04:13<3:19:59,  2.79it/s, loss=0.0755]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10794/44303 [1:04:13<3:19:40,  2.80it/s, loss=0.0755]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10794/44303 [1:04:13<3:19:40,  2.80it/s, loss=0.085] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10795/44303 [1:04:13<3:19:31,  2.80it/s, loss=0.085]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10795/44303 [1:04:13<3:19:31,  2.80it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10796/44303 [1:04:13<3:19:48,  2.79it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10796/44303 [1:04:14<3:19:48,  2.79it/s, loss=0.038] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10797/44303 [1:04:14<3:19:23,  2.80it/s, loss=0.038]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10797/44303 [1:04:14<3:19:23,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10798/44303 [1:04:14<3:19:23,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10798/44303 [1:04:14<3:19:23,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10799/44303 [1:04:14<3:19:59,  2.79it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10799/44303 [1:04:15<3:19:59,  2.79it/s, loss=0.123] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10800/44303 [1:04:15<3:20:00,  2.79it/s, loss=0.123]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10800/44303 [1:04:15<3:20:00,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10801/44303 [1:04:15<3:20:02,  2.79it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10801/44303 [1:04:15<3:20:02,  2.79it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10802/44303 [1:04:16<3:20:39,  2.78it/s, loss=0.0933]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10802/44303 [1:04:16<3:20:39,  2.78it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10803/44303 [1:04:16<3:19:52,  2.79it/s, loss=0.0791]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10803/44303 [1:04:16<3:19:52,  2.79it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10804/44303 [1:04:16<3:20:01,  2.79it/s, loss=0.0591]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10804/44303 [1:04:17<3:20:01,  2.79it/s, loss=0.0895]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10805/44303 [1:04:17<3:20:26,  2.79it/s, loss=0.0895]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10805/44303 [1:04:17<3:20:26,  2.79it/s, loss=0.05]  \u001b[A\n","Training Epoch 1:  24%|██▍       | 10806/44303 [1:04:17<3:19:42,  2.80it/s, loss=0.05]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10806/44303 [1:04:17<3:19:42,  2.80it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10807/44303 [1:04:17<3:19:55,  2.79it/s, loss=0.0669]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10807/44303 [1:04:18<3:19:55,  2.79it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10808/44303 [1:04:18<3:19:41,  2.80it/s, loss=0.0472]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10808/44303 [1:04:18<3:19:41,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10809/44303 [1:04:18<3:19:35,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10809/44303 [1:04:18<3:19:35,  2.80it/s, loss=0.076] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10810/44303 [1:04:18<3:19:04,  2.80it/s, loss=0.076]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10810/44303 [1:04:19<3:19:04,  2.80it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10811/44303 [1:04:19<3:20:00,  2.79it/s, loss=0.0453]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10811/44303 [1:04:19<3:20:00,  2.79it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10812/44303 [1:04:19<3:19:54,  2.79it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10812/44303 [1:04:19<3:19:54,  2.79it/s, loss=0.0756]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10813/44303 [1:04:19<3:19:34,  2.80it/s, loss=0.0756]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10813/44303 [1:04:20<3:19:34,  2.80it/s, loss=0.128] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10814/44303 [1:04:20<3:19:28,  2.80it/s, loss=0.128]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10814/44303 [1:04:20<3:19:28,  2.80it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10815/44303 [1:04:20<3:19:09,  2.80it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10815/44303 [1:04:21<3:19:09,  2.80it/s, loss=0.038] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10816/44303 [1:04:21<3:19:10,  2.80it/s, loss=0.038]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10816/44303 [1:04:21<3:19:10,  2.80it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10817/44303 [1:04:21<3:19:11,  2.80it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10817/44303 [1:04:21<3:19:11,  2.80it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10818/44303 [1:04:21<3:18:43,  2.81it/s, loss=0.0623]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10818/44303 [1:04:22<3:18:43,  2.81it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10819/44303 [1:04:22<3:19:48,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10819/44303 [1:04:22<3:19:48,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10820/44303 [1:04:22<3:20:03,  2.79it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10820/44303 [1:04:22<3:20:03,  2.79it/s, loss=0.0339]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10821/44303 [1:04:22<3:19:02,  2.80it/s, loss=0.0339]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10821/44303 [1:04:23<3:19:02,  2.80it/s, loss=0.0293]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10822/44303 [1:04:23<3:19:30,  2.80it/s, loss=0.0293]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10822/44303 [1:04:23<3:19:30,  2.80it/s, loss=0.081] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10823/44303 [1:04:23<3:19:35,  2.80it/s, loss=0.081]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10823/44303 [1:04:23<3:19:35,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10824/44303 [1:04:23<3:19:00,  2.80it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10824/44303 [1:04:24<3:19:00,  2.80it/s, loss=0.049] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10825/44303 [1:04:24<3:19:22,  2.80it/s, loss=0.049]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10825/44303 [1:04:24<3:19:22,  2.80it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10826/44303 [1:04:24<3:19:06,  2.80it/s, loss=0.0556]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10826/44303 [1:04:24<3:19:06,  2.80it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10827/44303 [1:04:24<3:18:52,  2.81it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10827/44303 [1:04:25<3:18:52,  2.81it/s, loss=0.0443]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10828/44303 [1:04:25<3:19:30,  2.80it/s, loss=0.0443]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10828/44303 [1:04:25<3:19:30,  2.80it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10829/44303 [1:04:25<3:18:38,  2.81it/s, loss=0.0567]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10829/44303 [1:04:25<3:18:38,  2.81it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10830/44303 [1:04:26<3:18:57,  2.80it/s, loss=0.0279]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10830/44303 [1:04:26<3:18:57,  2.80it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10831/44303 [1:04:26<3:19:53,  2.79it/s, loss=0.0527]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10831/44303 [1:04:26<3:19:53,  2.79it/s, loss=0.118] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10832/44303 [1:04:26<3:18:35,  2.81it/s, loss=0.118]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10832/44303 [1:04:27<3:18:35,  2.81it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10833/44303 [1:04:27<3:19:02,  2.80it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10833/44303 [1:04:27<3:19:02,  2.80it/s, loss=0.041] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10834/44303 [1:04:27<3:18:24,  2.81it/s, loss=0.041]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10834/44303 [1:04:27<3:18:24,  2.81it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10835/44303 [1:04:27<3:18:31,  2.81it/s, loss=0.0621]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10835/44303 [1:04:28<3:18:31,  2.81it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10836/44303 [1:04:28<3:18:32,  2.81it/s, loss=0.0617]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10836/44303 [1:04:28<3:18:32,  2.81it/s, loss=0.0987]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10837/44303 [1:04:28<3:18:56,  2.80it/s, loss=0.0987]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10837/44303 [1:04:28<3:18:56,  2.80it/s, loss=0.0442]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10838/44303 [1:04:28<3:19:09,  2.80it/s, loss=0.0442]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10838/44303 [1:04:29<3:19:09,  2.80it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10839/44303 [1:04:29<3:18:45,  2.81it/s, loss=0.0753]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10839/44303 [1:04:29<3:18:45,  2.81it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10840/44303 [1:04:29<3:19:11,  2.80it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10840/44303 [1:04:29<3:19:11,  2.80it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10841/44303 [1:04:29<3:19:53,  2.79it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10841/44303 [1:04:30<3:19:53,  2.79it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10842/44303 [1:04:30<3:19:41,  2.79it/s, loss=0.0473]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10842/44303 [1:04:30<3:19:41,  2.79it/s, loss=0.0828]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10843/44303 [1:04:30<3:19:28,  2.80it/s, loss=0.0828]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10843/44303 [1:04:31<3:19:28,  2.80it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10844/44303 [1:04:31<3:19:43,  2.79it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10844/44303 [1:04:31<3:19:43,  2.79it/s, loss=0.102] \u001b[A\n","Training Epoch 1:  24%|██▍       | 10845/44303 [1:04:31<3:19:34,  2.79it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10845/44303 [1:04:31<3:19:34,  2.79it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10846/44303 [1:04:31<3:19:16,  2.80it/s, loss=0.0878]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10846/44303 [1:04:32<3:19:16,  2.80it/s, loss=0.0815]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10847/44303 [1:04:32<3:19:48,  2.79it/s, loss=0.0815]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10847/44303 [1:04:32<3:19:48,  2.79it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10848/44303 [1:04:32<3:19:47,  2.79it/s, loss=0.0813]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10848/44303 [1:04:32<3:19:47,  2.79it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10849/44303 [1:04:32<3:19:07,  2.80it/s, loss=0.0532]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10849/44303 [1:04:33<3:19:07,  2.80it/s, loss=0.0744]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10850/44303 [1:04:33<3:19:50,  2.79it/s, loss=0.0744]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10850/44303 [1:04:33<3:19:50,  2.79it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10851/44303 [1:04:33<3:19:03,  2.80it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10851/44303 [1:04:33<3:19:03,  2.80it/s, loss=0.0894]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10852/44303 [1:04:33<3:18:58,  2.80it/s, loss=0.0894]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10852/44303 [1:04:34<3:18:58,  2.80it/s, loss=0.0696]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10853/44303 [1:04:34<3:19:37,  2.79it/s, loss=0.0696]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10853/44303 [1:04:34<3:19:37,  2.79it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10854/44303 [1:04:34<3:18:32,  2.81it/s, loss=0.0417]\u001b[A\n","Training Epoch 1:  24%|██▍       | 10854/44303 [1:04:34<3:18:32,  2.81it/s, loss=0.037] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10855/44303 [1:04:34<3:19:09,  2.80it/s, loss=0.037]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10855/44303 [1:04:35<3:19:09,  2.80it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10856/44303 [1:04:35<3:19:34,  2.79it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10856/44303 [1:04:35<3:19:34,  2.79it/s, loss=0.029] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10857/44303 [1:04:35<3:19:22,  2.80it/s, loss=0.029]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10857/44303 [1:04:36<3:19:22,  2.80it/s, loss=0.0243]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10858/44303 [1:04:36<3:19:28,  2.79it/s, loss=0.0243]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10858/44303 [1:04:36<3:19:28,  2.79it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10859/44303 [1:04:36<3:19:31,  2.79it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10859/44303 [1:04:36<3:19:31,  2.79it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10860/44303 [1:04:36<3:19:18,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10860/44303 [1:04:37<3:19:18,  2.80it/s, loss=0.118] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10861/44303 [1:04:37<3:19:27,  2.79it/s, loss=0.118]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10861/44303 [1:04:37<3:19:27,  2.79it/s, loss=0.0385]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10862/44303 [1:04:37<3:19:41,  2.79it/s, loss=0.0385]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10862/44303 [1:04:37<3:19:41,  2.79it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10863/44303 [1:04:37<3:18:37,  2.81it/s, loss=0.0803]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10863/44303 [1:04:38<3:18:37,  2.81it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10864/44303 [1:04:38<3:19:31,  2.79it/s, loss=0.0625]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10864/44303 [1:04:38<3:19:31,  2.79it/s, loss=0.0575]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10865/44303 [1:04:38<3:19:36,  2.79it/s, loss=0.0575]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10865/44303 [1:04:38<3:19:36,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10866/44303 [1:04:38<3:18:30,  2.81it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10866/44303 [1:04:39<3:18:30,  2.81it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10867/44303 [1:04:39<3:19:31,  2.79it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10867/44303 [1:04:39<3:19:31,  2.79it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10868/44303 [1:04:39<3:18:48,  2.80it/s, loss=0.0375]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10868/44303 [1:04:39<3:18:48,  2.80it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10869/44303 [1:04:39<3:19:21,  2.80it/s, loss=0.0647]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10869/44303 [1:04:40<3:19:21,  2.80it/s, loss=0.0918]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10870/44303 [1:04:40<3:19:57,  2.79it/s, loss=0.0918]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10870/44303 [1:04:40<3:19:57,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10871/44303 [1:04:40<3:19:54,  2.79it/s, loss=0.0421]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10871/44303 [1:04:41<3:19:54,  2.79it/s, loss=0.0688]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10872/44303 [1:04:41<3:19:06,  2.80it/s, loss=0.0688]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10872/44303 [1:04:41<3:19:06,  2.80it/s, loss=0.053] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10873/44303 [1:04:41<3:19:50,  2.79it/s, loss=0.053]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10873/44303 [1:04:41<3:19:50,  2.79it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10874/44303 [1:04:41<3:19:49,  2.79it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10874/44303 [1:04:42<3:19:49,  2.79it/s, loss=0.0376]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10875/44303 [1:04:42<3:18:57,  2.80it/s, loss=0.0376]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10875/44303 [1:04:42<3:18:57,  2.80it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10876/44303 [1:04:42<3:19:44,  2.79it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10876/44303 [1:04:42<3:19:44,  2.79it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10877/44303 [1:04:42<3:19:26,  2.79it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10877/44303 [1:04:43<3:19:26,  2.79it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10878/44303 [1:04:43<3:19:32,  2.79it/s, loss=0.0768]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10878/44303 [1:04:43<3:19:32,  2.79it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10879/44303 [1:04:43<3:20:12,  2.78it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10879/44303 [1:04:43<3:20:12,  2.78it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10880/44303 [1:04:43<3:19:55,  2.79it/s, loss=0.0566]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10880/44303 [1:04:44<3:19:55,  2.79it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10881/44303 [1:04:44<3:19:17,  2.80it/s, loss=0.0545]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10881/44303 [1:04:44<3:19:17,  2.80it/s, loss=0.039] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10882/44303 [1:04:44<3:19:52,  2.79it/s, loss=0.039]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10882/44303 [1:04:44<3:19:52,  2.79it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10883/44303 [1:04:44<3:20:10,  2.78it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10883/44303 [1:04:45<3:20:10,  2.78it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10884/44303 [1:04:45<3:19:45,  2.79it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10884/44303 [1:04:45<3:19:45,  2.79it/s, loss=0.0338]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10885/44303 [1:04:45<3:19:25,  2.79it/s, loss=0.0338]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10885/44303 [1:04:46<3:19:25,  2.79it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10886/44303 [1:04:46<3:19:06,  2.80it/s, loss=0.0544]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10886/44303 [1:04:46<3:19:06,  2.80it/s, loss=0.0307]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10887/44303 [1:04:46<3:18:50,  2.80it/s, loss=0.0307]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10887/44303 [1:04:46<3:18:50,  2.80it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10888/44303 [1:04:46<3:19:00,  2.80it/s, loss=0.0845]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10888/44303 [1:04:47<3:19:00,  2.80it/s, loss=0.0998]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10889/44303 [1:04:47<3:19:15,  2.79it/s, loss=0.0998]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10889/44303 [1:04:47<3:19:15,  2.79it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10890/44303 [1:04:47<3:19:00,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10890/44303 [1:04:47<3:19:00,  2.80it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10891/44303 [1:04:47<3:19:35,  2.79it/s, loss=0.0695]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10891/44303 [1:04:48<3:19:35,  2.79it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10892/44303 [1:04:48<3:18:21,  2.81it/s, loss=0.0607]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10892/44303 [1:04:48<3:18:21,  2.81it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10893/44303 [1:04:48<3:19:08,  2.80it/s, loss=0.0771]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10893/44303 [1:04:48<3:19:08,  2.80it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10894/44303 [1:04:48<3:19:02,  2.80it/s, loss=0.0616]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10894/44303 [1:04:49<3:19:02,  2.80it/s, loss=0.0303]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10895/44303 [1:04:49<3:18:52,  2.80it/s, loss=0.0303]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10895/44303 [1:04:49<3:18:52,  2.80it/s, loss=0.082] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10896/44303 [1:04:49<3:19:45,  2.79it/s, loss=0.082]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10896/44303 [1:04:49<3:19:45,  2.79it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10897/44303 [1:04:49<3:20:24,  2.78it/s, loss=0.0439]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10897/44303 [1:04:50<3:20:24,  2.78it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10898/44303 [1:04:50<3:20:54,  2.77it/s, loss=0.0655]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10898/44303 [1:04:50<3:20:54,  2.77it/s, loss=0.0769]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10899/44303 [1:04:50<3:20:58,  2.77it/s, loss=0.0769]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10899/44303 [1:04:51<3:20:58,  2.77it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10900/44303 [1:04:51<3:20:20,  2.78it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10900/44303 [1:04:51<3:20:20,  2.78it/s, loss=0.0948]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10901/44303 [1:04:51<3:19:51,  2.79it/s, loss=0.0948]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10901/44303 [1:04:51<3:19:51,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10902/44303 [1:04:51<3:19:43,  2.79it/s, loss=0.0302]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10902/44303 [1:04:52<3:19:43,  2.79it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10903/44303 [1:04:52<3:19:33,  2.79it/s, loss=0.0674]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10903/44303 [1:04:52<3:19:33,  2.79it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10904/44303 [1:04:52<3:19:58,  2.78it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10904/44303 [1:04:52<3:19:58,  2.78it/s, loss=0.0779]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10905/44303 [1:04:52<3:19:10,  2.79it/s, loss=0.0779]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10905/44303 [1:04:53<3:19:10,  2.79it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10906/44303 [1:04:53<3:19:52,  2.78it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10906/44303 [1:04:53<3:19:52,  2.78it/s, loss=0.1]   \u001b[A\n","Training Epoch 1:  25%|██▍       | 10907/44303 [1:04:53<3:19:33,  2.79it/s, loss=0.1]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10907/44303 [1:04:53<3:19:33,  2.79it/s, loss=0.062]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10908/44303 [1:04:53<3:18:53,  2.80it/s, loss=0.062]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10908/44303 [1:04:54<3:18:53,  2.80it/s, loss=0.0714]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10909/44303 [1:04:54<3:19:45,  2.79it/s, loss=0.0714]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10909/44303 [1:04:54<3:19:45,  2.79it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10910/44303 [1:04:54<3:19:45,  2.79it/s, loss=0.0322]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10910/44303 [1:04:54<3:19:45,  2.79it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10911/44303 [1:04:54<3:19:11,  2.79it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10911/44303 [1:04:55<3:19:11,  2.79it/s, loss=0.0652]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10912/44303 [1:04:55<3:19:52,  2.78it/s, loss=0.0652]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10912/44303 [1:04:55<3:19:52,  2.78it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10913/44303 [1:04:55<3:19:50,  2.78it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10913/44303 [1:04:56<3:19:50,  2.78it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10914/44303 [1:04:56<3:18:48,  2.80it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10914/44303 [1:04:56<3:18:48,  2.80it/s, loss=0.035] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10915/44303 [1:04:56<3:19:51,  2.78it/s, loss=0.035]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10915/44303 [1:04:56<3:19:51,  2.78it/s, loss=0.0739]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10916/44303 [1:04:56<3:19:46,  2.79it/s, loss=0.0739]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10916/44303 [1:04:57<3:19:46,  2.79it/s, loss=0.0465]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10917/44303 [1:04:57<3:18:50,  2.80it/s, loss=0.0465]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10917/44303 [1:04:57<3:18:50,  2.80it/s, loss=0.163] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10918/44303 [1:04:57<3:19:15,  2.79it/s, loss=0.163]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10918/44303 [1:04:57<3:19:15,  2.79it/s, loss=0.0877]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10919/44303 [1:04:57<3:18:48,  2.80it/s, loss=0.0877]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10919/44303 [1:04:58<3:18:48,  2.80it/s, loss=0.059] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10920/44303 [1:04:58<3:19:08,  2.79it/s, loss=0.059]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10920/44303 [1:04:58<3:19:08,  2.79it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10921/44303 [1:04:58<3:19:33,  2.79it/s, loss=0.0665]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10921/44303 [1:04:58<3:19:33,  2.79it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10922/44303 [1:04:58<3:18:29,  2.80it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10922/44303 [1:04:59<3:18:29,  2.80it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10923/44303 [1:04:59<3:19:09,  2.79it/s, loss=0.0399]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10923/44303 [1:04:59<3:19:09,  2.79it/s, loss=0.0372]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10924/44303 [1:04:59<3:19:55,  2.78it/s, loss=0.0372]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10924/44303 [1:05:00<3:19:55,  2.78it/s, loss=0.109] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10925/44303 [1:05:00<3:19:27,  2.79it/s, loss=0.109]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10925/44303 [1:05:00<3:19:27,  2.79it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10926/44303 [1:05:00<3:19:19,  2.79it/s, loss=0.0546]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10926/44303 [1:05:00<3:19:19,  2.79it/s, loss=0.0633]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10927/44303 [1:05:00<3:19:47,  2.78it/s, loss=0.0633]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10927/44303 [1:05:01<3:19:47,  2.78it/s, loss=0.044] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10928/44303 [1:05:01<3:19:29,  2.79it/s, loss=0.044]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10928/44303 [1:05:01<3:19:29,  2.79it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10929/44303 [1:05:01<3:19:09,  2.79it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10929/44303 [1:05:01<3:19:09,  2.79it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10930/44303 [1:05:01<3:20:03,  2.78it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10930/44303 [1:05:02<3:20:03,  2.78it/s, loss=0.0609]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10931/44303 [1:05:02<3:19:32,  2.79it/s, loss=0.0609]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10931/44303 [1:05:02<3:19:32,  2.79it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10932/44303 [1:05:02<3:19:29,  2.79it/s, loss=0.0659]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10932/44303 [1:05:02<3:19:29,  2.79it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10933/44303 [1:05:02<3:19:37,  2.79it/s, loss=0.0776]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10933/44303 [1:05:03<3:19:37,  2.79it/s, loss=0.049] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10934/44303 [1:05:03<3:19:10,  2.79it/s, loss=0.049]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10934/44303 [1:05:03<3:19:10,  2.79it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10935/44303 [1:05:03<3:18:27,  2.80it/s, loss=0.117]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10935/44303 [1:05:03<3:18:27,  2.80it/s, loss=0.0407]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10936/44303 [1:05:03<3:19:09,  2.79it/s, loss=0.0407]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10936/44303 [1:05:04<3:19:09,  2.79it/s, loss=0.0365]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10937/44303 [1:05:04<3:18:39,  2.80it/s, loss=0.0365]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10937/44303 [1:05:04<3:18:39,  2.80it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10938/44303 [1:05:04<3:18:05,  2.81it/s, loss=0.0523]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10938/44303 [1:05:05<3:18:05,  2.81it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10939/44303 [1:05:05<3:19:16,  2.79it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10939/44303 [1:05:05<3:19:16,  2.79it/s, loss=0.0689]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10940/44303 [1:05:05<3:18:57,  2.79it/s, loss=0.0689]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10940/44303 [1:05:05<3:18:57,  2.79it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10941/44303 [1:05:05<3:19:05,  2.79it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10941/44303 [1:05:06<3:19:05,  2.79it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10942/44303 [1:05:06<3:19:23,  2.79it/s, loss=0.0508]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10942/44303 [1:05:06<3:19:23,  2.79it/s, loss=0.128] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10943/44303 [1:05:06<3:19:32,  2.79it/s, loss=0.128]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10943/44303 [1:05:06<3:19:32,  2.79it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10944/44303 [1:05:06<3:19:39,  2.78it/s, loss=0.0541]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10944/44303 [1:05:07<3:19:39,  2.78it/s, loss=0.081] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10945/44303 [1:05:07<3:20:10,  2.78it/s, loss=0.081]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10945/44303 [1:05:07<3:20:10,  2.78it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10946/44303 [1:05:07<3:21:00,  2.77it/s, loss=0.0557]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10946/44303 [1:05:07<3:21:00,  2.77it/s, loss=0.045] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10947/44303 [1:05:07<3:19:36,  2.79it/s, loss=0.045]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10947/44303 [1:05:08<3:19:36,  2.79it/s, loss=0.0361]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10948/44303 [1:05:08<3:19:47,  2.78it/s, loss=0.0361]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10948/44303 [1:05:08<3:19:47,  2.78it/s, loss=0.08]  \u001b[A\n","Training Epoch 1:  25%|██▍       | 10949/44303 [1:05:08<3:19:16,  2.79it/s, loss=0.08]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10949/44303 [1:05:08<3:19:16,  2.79it/s, loss=0.144]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10950/44303 [1:05:08<3:19:58,  2.78it/s, loss=0.144]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10950/44303 [1:05:09<3:19:58,  2.78it/s, loss=0.0637]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10951/44303 [1:05:09<3:19:55,  2.78it/s, loss=0.0637]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10951/44303 [1:05:09<3:19:55,  2.78it/s, loss=0.132] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10952/44303 [1:05:09<3:19:28,  2.79it/s, loss=0.132]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10952/44303 [1:05:10<3:19:28,  2.79it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10953/44303 [1:05:10<3:18:46,  2.80it/s, loss=0.0611]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10953/44303 [1:05:10<3:18:46,  2.80it/s, loss=0.12]  \u001b[A\n","Training Epoch 1:  25%|██▍       | 10954/44303 [1:05:10<3:19:05,  2.79it/s, loss=0.12]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10954/44303 [1:05:10<3:19:05,  2.79it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10955/44303 [1:05:10<3:18:28,  2.80it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10955/44303 [1:05:11<3:18:28,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10956/44303 [1:05:11<3:18:47,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10956/44303 [1:05:11<3:18:47,  2.80it/s, loss=0.048] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10957/44303 [1:05:11<3:18:53,  2.79it/s, loss=0.048]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10957/44303 [1:05:11<3:18:53,  2.79it/s, loss=0.0683]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10958/44303 [1:05:11<3:18:41,  2.80it/s, loss=0.0683]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10958/44303 [1:05:12<3:18:41,  2.80it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10959/44303 [1:05:12<3:19:04,  2.79it/s, loss=0.0464]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10959/44303 [1:05:12<3:19:04,  2.79it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10960/44303 [1:05:12<3:19:13,  2.79it/s, loss=0.0394]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10960/44303 [1:05:12<3:19:13,  2.79it/s, loss=0.062] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10961/44303 [1:05:12<3:18:57,  2.79it/s, loss=0.062]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10961/44303 [1:05:13<3:18:57,  2.79it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10962/44303 [1:05:13<3:18:22,  2.80it/s, loss=0.0446]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10962/44303 [1:05:13<3:18:22,  2.80it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10963/44303 [1:05:13<3:18:48,  2.80it/s, loss=0.0401]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10963/44303 [1:05:13<3:18:48,  2.80it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10964/44303 [1:05:13<3:17:59,  2.81it/s, loss=0.0631]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10964/44303 [1:05:14<3:17:59,  2.81it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10965/44303 [1:05:14<3:18:01,  2.81it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10965/44303 [1:05:14<3:18:01,  2.81it/s, loss=0.0219]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10966/44303 [1:05:14<3:19:01,  2.79it/s, loss=0.0219]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10966/44303 [1:05:15<3:19:01,  2.79it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10967/44303 [1:05:15<3:18:27,  2.80it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10967/44303 [1:05:15<3:18:27,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10968/44303 [1:05:15<3:18:35,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10968/44303 [1:05:15<3:18:35,  2.80it/s, loss=0.0988]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10969/44303 [1:05:15<3:18:54,  2.79it/s, loss=0.0988]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10969/44303 [1:05:16<3:18:54,  2.79it/s, loss=0.0526]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10970/44303 [1:05:16<3:18:07,  2.80it/s, loss=0.0526]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10970/44303 [1:05:16<3:18:07,  2.80it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10971/44303 [1:05:16<3:18:31,  2.80it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10971/44303 [1:05:16<3:18:31,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10972/44303 [1:05:16<3:18:40,  2.80it/s, loss=0.0543]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10972/44303 [1:05:17<3:18:40,  2.80it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10973/44303 [1:05:17<3:18:49,  2.79it/s, loss=0.0499]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10973/44303 [1:05:17<3:18:49,  2.79it/s, loss=0.0901]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10974/44303 [1:05:17<3:19:05,  2.79it/s, loss=0.0901]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10974/44303 [1:05:17<3:19:05,  2.79it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10975/44303 [1:05:17<3:18:49,  2.79it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10975/44303 [1:05:18<3:18:49,  2.79it/s, loss=0.0387]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10976/44303 [1:05:18<3:19:10,  2.79it/s, loss=0.0387]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10976/44303 [1:05:18<3:19:10,  2.79it/s, loss=0.0212]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10977/44303 [1:05:18<3:19:28,  2.78it/s, loss=0.0212]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10977/44303 [1:05:18<3:19:28,  2.78it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10978/44303 [1:05:19<3:19:34,  2.78it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10978/44303 [1:05:19<3:19:34,  2.78it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10979/44303 [1:05:19<3:19:26,  2.78it/s, loss=0.0612]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10979/44303 [1:05:19<3:19:26,  2.78it/s, loss=0.106] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10980/44303 [1:05:19<3:19:57,  2.78it/s, loss=0.106]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10980/44303 [1:05:20<3:19:57,  2.78it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10981/44303 [1:05:20<3:19:30,  2.78it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10981/44303 [1:05:20<3:19:30,  2.78it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10982/44303 [1:05:20<3:19:13,  2.79it/s, loss=0.0358]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10982/44303 [1:05:20<3:19:13,  2.79it/s, loss=0.069] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10983/44303 [1:05:20<3:19:04,  2.79it/s, loss=0.069]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10983/44303 [1:05:21<3:19:04,  2.79it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10984/44303 [1:05:21<3:19:29,  2.78it/s, loss=0.0863]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10984/44303 [1:05:21<3:19:29,  2.78it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10985/44303 [1:05:21<3:19:15,  2.79it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10985/44303 [1:05:21<3:19:15,  2.79it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10986/44303 [1:05:21<3:18:43,  2.79it/s, loss=0.0488]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10986/44303 [1:05:22<3:18:43,  2.79it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10987/44303 [1:05:22<3:18:40,  2.79it/s, loss=0.0328]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10987/44303 [1:05:22<3:18:40,  2.79it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10988/44303 [1:05:22<3:18:37,  2.80it/s, loss=0.0597]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10988/44303 [1:05:22<3:18:37,  2.80it/s, loss=0.063] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10989/44303 [1:05:22<3:18:01,  2.80it/s, loss=0.063]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10989/44303 [1:05:23<3:18:01,  2.80it/s, loss=0.078]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10990/44303 [1:05:23<3:18:04,  2.80it/s, loss=0.078]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10990/44303 [1:05:23<3:18:04,  2.80it/s, loss=0.0256]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10991/44303 [1:05:23<3:19:14,  2.79it/s, loss=0.0256]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10991/44303 [1:05:24<3:19:14,  2.79it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10992/44303 [1:05:24<3:18:47,  2.79it/s, loss=0.0542]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10992/44303 [1:05:24<3:18:47,  2.79it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10993/44303 [1:05:24<3:18:29,  2.80it/s, loss=0.0751]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10993/44303 [1:05:24<3:18:29,  2.80it/s, loss=0.118] \u001b[A\n","Training Epoch 1:  25%|██▍       | 10994/44303 [1:05:24<3:18:44,  2.79it/s, loss=0.118]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10994/44303 [1:05:25<3:18:44,  2.79it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10995/44303 [1:05:25<3:18:02,  2.80it/s, loss=0.0624]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10995/44303 [1:05:25<3:18:02,  2.80it/s, loss=0.0603]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10996/44303 [1:05:25<3:17:20,  2.81it/s, loss=0.0603]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10996/44303 [1:05:25<3:17:20,  2.81it/s, loss=0.11]  \u001b[A\n","Training Epoch 1:  25%|██▍       | 10997/44303 [1:05:25<3:18:46,  2.79it/s, loss=0.11]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10997/44303 [1:05:26<3:18:46,  2.79it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10998/44303 [1:05:26<3:17:41,  2.81it/s, loss=0.0582]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10998/44303 [1:05:26<3:17:41,  2.81it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10999/44303 [1:05:26<3:18:20,  2.80it/s, loss=0.0476]\u001b[A\n","Training Epoch 1:  25%|██▍       | 10999/44303 [1:05:26<3:18:20,  2.80it/s, loss=0.0712]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11000/44303 [1:05:26<3:18:50,  2.79it/s, loss=0.0712]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11000/44303 [1:05:27<3:18:50,  2.79it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11001/44303 [1:05:27<3:18:17,  2.80it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11001/44303 [1:05:27<3:18:17,  2.80it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11002/44303 [1:05:27<3:18:36,  2.79it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11002/44303 [1:05:27<3:18:36,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11003/44303 [1:05:27<3:18:39,  2.79it/s, loss=0.0766]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11003/44303 [1:05:28<3:18:39,  2.79it/s, loss=0.0451]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11004/44303 [1:05:28<3:18:01,  2.80it/s, loss=0.0451]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11004/44303 [1:05:28<3:18:01,  2.80it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11005/44303 [1:05:28<3:18:30,  2.80it/s, loss=0.0398]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11005/44303 [1:05:29<3:18:30,  2.80it/s, loss=0.0678]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11006/44303 [1:05:29<3:17:57,  2.80it/s, loss=0.0678]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11006/44303 [1:05:29<3:17:57,  2.80it/s, loss=0.0653]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11007/44303 [1:05:29<3:18:08,  2.80it/s, loss=0.0653]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11007/44303 [1:05:29<3:18:08,  2.80it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11008/44303 [1:05:29<3:18:38,  2.79it/s, loss=0.0519]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11008/44303 [1:05:30<3:18:38,  2.79it/s, loss=0.0461]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11009/44303 [1:05:30<3:17:51,  2.80it/s, loss=0.0461]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11009/44303 [1:05:30<3:17:51,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11010/44303 [1:05:30<3:18:19,  2.80it/s, loss=0.0428]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11010/44303 [1:05:30<3:18:19,  2.80it/s, loss=0.0943]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11011/44303 [1:05:30<3:18:33,  2.79it/s, loss=0.0943]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11011/44303 [1:05:31<3:18:33,  2.79it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11012/44303 [1:05:31<3:17:52,  2.80it/s, loss=0.0402]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11012/44303 [1:05:31<3:17:52,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11013/44303 [1:05:31<3:18:11,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11013/44303 [1:05:31<3:18:11,  2.80it/s, loss=0.134] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11014/44303 [1:05:31<3:18:37,  2.79it/s, loss=0.134]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11014/44303 [1:05:32<3:18:37,  2.79it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11015/44303 [1:05:32<3:18:12,  2.80it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11015/44303 [1:05:32<3:18:12,  2.80it/s, loss=0.037] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11016/44303 [1:05:32<3:18:32,  2.79it/s, loss=0.037]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11016/44303 [1:05:32<3:18:32,  2.79it/s, loss=0.0773]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11017/44303 [1:05:32<3:19:10,  2.79it/s, loss=0.0773]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11017/44303 [1:05:33<3:19:10,  2.79it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11018/44303 [1:05:33<3:18:34,  2.79it/s, loss=0.0389]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11018/44303 [1:05:33<3:18:34,  2.79it/s, loss=0.077] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11019/44303 [1:05:33<3:18:44,  2.79it/s, loss=0.077]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11019/44303 [1:05:34<3:18:44,  2.79it/s, loss=0.0381]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11020/44303 [1:05:34<3:18:21,  2.80it/s, loss=0.0381]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11020/44303 [1:05:34<3:18:21,  2.80it/s, loss=0.059] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11021/44303 [1:05:34<3:17:51,  2.80it/s, loss=0.059]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11021/44303 [1:05:34<3:17:51,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11022/44303 [1:05:34<3:18:20,  2.80it/s, loss=0.0492]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11022/44303 [1:05:35<3:18:20,  2.80it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11023/44303 [1:05:35<3:17:38,  2.81it/s, loss=0.0687]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11023/44303 [1:05:35<3:17:38,  2.81it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11024/44303 [1:05:35<3:17:42,  2.81it/s, loss=0.0643]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11024/44303 [1:05:35<3:17:42,  2.81it/s, loss=0.0675]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11025/44303 [1:05:35<3:17:27,  2.81it/s, loss=0.0675]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11025/44303 [1:05:36<3:17:27,  2.81it/s, loss=0.0588]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11026/44303 [1:05:36<3:17:25,  2.81it/s, loss=0.0588]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11026/44303 [1:05:36<3:17:25,  2.81it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11027/44303 [1:05:36<3:17:44,  2.80it/s, loss=0.0875]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11027/44303 [1:05:36<3:17:44,  2.80it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11028/44303 [1:05:36<3:17:11,  2.81it/s, loss=0.0479]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11028/44303 [1:05:37<3:17:11,  2.81it/s, loss=0.0714]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11029/44303 [1:05:37<3:17:43,  2.80it/s, loss=0.0714]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11029/44303 [1:05:37<3:17:43,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11030/44303 [1:05:37<3:17:55,  2.80it/s, loss=0.0721]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11030/44303 [1:05:37<3:17:55,  2.80it/s, loss=0.0304]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11031/44303 [1:05:37<3:17:45,  2.80it/s, loss=0.0304]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11031/44303 [1:05:38<3:17:45,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11032/44303 [1:05:38<3:18:06,  2.80it/s, loss=0.0572]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11032/44303 [1:05:38<3:18:06,  2.80it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11033/44303 [1:05:38<3:17:02,  2.81it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11033/44303 [1:05:39<3:17:02,  2.81it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11034/44303 [1:05:39<3:17:40,  2.80it/s, loss=0.0792]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11034/44303 [1:05:39<3:17:40,  2.80it/s, loss=0.0817]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11035/44303 [1:05:39<3:18:12,  2.80it/s, loss=0.0817]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11035/44303 [1:05:39<3:18:12,  2.80it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11036/44303 [1:05:39<3:17:46,  2.80it/s, loss=0.0262]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11036/44303 [1:05:40<3:17:46,  2.80it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11037/44303 [1:05:40<3:18:35,  2.79it/s, loss=0.0686]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11037/44303 [1:05:40<3:18:35,  2.79it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11038/44303 [1:05:40<3:18:11,  2.80it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11038/44303 [1:05:40<3:18:11,  2.80it/s, loss=0.118] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11039/44303 [1:05:40<3:18:21,  2.79it/s, loss=0.118]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11039/44303 [1:05:41<3:18:21,  2.79it/s, loss=0.0587]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11040/44303 [1:05:41<3:18:10,  2.80it/s, loss=0.0587]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11040/44303 [1:05:41<3:18:10,  2.80it/s, loss=0.0844]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11041/44303 [1:05:41<3:17:32,  2.81it/s, loss=0.0844]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11041/44303 [1:05:41<3:17:32,  2.81it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11042/44303 [1:05:41<3:17:51,  2.80it/s, loss=0.0694]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11042/44303 [1:05:42<3:17:51,  2.80it/s, loss=0.0691]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11043/44303 [1:05:42<3:17:23,  2.81it/s, loss=0.0691]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11043/44303 [1:05:42<3:17:23,  2.81it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11044/44303 [1:05:42<3:17:56,  2.80it/s, loss=0.0801]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11044/44303 [1:05:42<3:17:56,  2.80it/s, loss=0.0285]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11045/44303 [1:05:42<3:18:28,  2.79it/s, loss=0.0285]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11045/44303 [1:05:43<3:18:28,  2.79it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11046/44303 [1:05:43<3:19:13,  2.78it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11046/44303 [1:05:43<3:19:13,  2.78it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11047/44303 [1:05:43<3:18:30,  2.79it/s, loss=0.0324]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11047/44303 [1:05:44<3:18:30,  2.79it/s, loss=0.0825]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11048/44303 [1:05:44<3:18:44,  2.79it/s, loss=0.0825]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11048/44303 [1:05:44<3:18:44,  2.79it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11049/44303 [1:05:44<3:18:29,  2.79it/s, loss=0.0799]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11049/44303 [1:05:44<3:18:29,  2.79it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11050/44303 [1:05:44<3:17:26,  2.81it/s, loss=0.0474]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11050/44303 [1:05:45<3:17:26,  2.81it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11051/44303 [1:05:45<3:18:09,  2.80it/s, loss=0.0537]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11051/44303 [1:05:45<3:18:09,  2.80it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11052/44303 [1:05:45<3:17:13,  2.81it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11052/44303 [1:05:45<3:17:13,  2.81it/s, loss=0.0782]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11053/44303 [1:05:45<3:17:22,  2.81it/s, loss=0.0782]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11053/44303 [1:05:46<3:17:22,  2.81it/s, loss=0.0388]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11054/44303 [1:05:46<3:17:09,  2.81it/s, loss=0.0388]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11054/44303 [1:05:46<3:17:09,  2.81it/s, loss=0.0719]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11055/44303 [1:05:46<3:17:29,  2.81it/s, loss=0.0719]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11055/44303 [1:05:46<3:17:29,  2.81it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11056/44303 [1:05:46<3:17:35,  2.80it/s, loss=0.0489]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11056/44303 [1:05:47<3:17:35,  2.80it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11057/44303 [1:05:47<3:17:25,  2.81it/s, loss=0.0562]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11057/44303 [1:05:47<3:17:25,  2.81it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11058/44303 [1:05:47<3:17:39,  2.80it/s, loss=0.0386]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11058/44303 [1:05:47<3:17:39,  2.80it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11059/44303 [1:05:47<3:17:27,  2.81it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11059/44303 [1:05:48<3:17:27,  2.81it/s, loss=0.0765]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11060/44303 [1:05:48<3:17:03,  2.81it/s, loss=0.0765]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11060/44303 [1:05:48<3:17:03,  2.81it/s, loss=0.0675]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11061/44303 [1:05:48<3:17:28,  2.81it/s, loss=0.0675]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11061/44303 [1:05:49<3:17:28,  2.81it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11062/44303 [1:05:49<3:17:51,  2.80it/s, loss=0.0604]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11062/44303 [1:05:49<3:17:51,  2.80it/s, loss=0.067] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11063/44303 [1:05:49<3:18:08,  2.80it/s, loss=0.067]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11063/44303 [1:05:49<3:18:08,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11064/44303 [1:05:49<3:18:11,  2.80it/s, loss=0.0393]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11064/44303 [1:05:50<3:18:11,  2.80it/s, loss=0.0786]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11065/44303 [1:05:50<3:18:04,  2.80it/s, loss=0.0786]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11065/44303 [1:05:50<3:18:04,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11066/44303 [1:05:50<3:18:02,  2.80it/s, loss=0.0484]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11066/44303 [1:05:50<3:18:02,  2.80it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11067/44303 [1:05:50<3:17:23,  2.81it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11067/44303 [1:05:51<3:17:23,  2.81it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11068/44303 [1:05:51<3:17:57,  2.80it/s, loss=0.0748]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11068/44303 [1:05:51<3:17:57,  2.80it/s, loss=0.0977]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11069/44303 [1:05:51<3:18:00,  2.80it/s, loss=0.0977]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11069/44303 [1:05:51<3:18:00,  2.80it/s, loss=0.0779]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11070/44303 [1:05:51<3:17:53,  2.80it/s, loss=0.0779]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11070/44303 [1:05:52<3:17:53,  2.80it/s, loss=0.054] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11071/44303 [1:05:52<3:18:13,  2.79it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11071/44303 [1:05:52<3:18:13,  2.79it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11072/44303 [1:05:52<3:17:41,  2.80it/s, loss=0.061]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11072/44303 [1:05:52<3:17:41,  2.80it/s, loss=0.0452]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11073/44303 [1:05:52<3:18:14,  2.79it/s, loss=0.0452]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11073/44303 [1:05:53<3:18:14,  2.79it/s, loss=0.056] \u001b[A\n","Training Epoch 1:  25%|██▍       | 11074/44303 [1:05:53<3:18:18,  2.79it/s, loss=0.056]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11074/44303 [1:05:53<3:18:18,  2.79it/s, loss=0.025]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11075/44303 [1:05:53<3:17:27,  2.80it/s, loss=0.025]\u001b[A\n","Training Epoch 1:  25%|██▍       | 11075/44303 [1:05:54<3:17:27,  2.80it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11076/44303 [1:05:54<3:17:50,  2.80it/s, loss=0.0498]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11076/44303 [1:05:54<3:17:50,  2.80it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11077/44303 [1:05:54<3:17:20,  2.81it/s, loss=0.0475]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11077/44303 [1:05:54<3:17:20,  2.81it/s, loss=0.0346]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11078/44303 [1:05:54<3:16:56,  2.81it/s, loss=0.0346]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11078/44303 [1:05:55<3:16:56,  2.81it/s, loss=0.0891]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11079/44303 [1:05:55<3:17:02,  2.81it/s, loss=0.0891]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11079/44303 [1:05:55<3:17:02,  2.81it/s, loss=0.018] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11080/44303 [1:05:55<3:16:57,  2.81it/s, loss=0.018]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11080/44303 [1:05:55<3:16:57,  2.81it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11081/44303 [1:05:55<3:17:27,  2.80it/s, loss=0.054]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11081/44303 [1:05:56<3:17:27,  2.80it/s, loss=0.0226]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11082/44303 [1:05:56<3:17:02,  2.81it/s, loss=0.0226]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11082/44303 [1:05:56<3:17:02,  2.81it/s, loss=0.0635]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11083/44303 [1:05:56<3:17:07,  2.81it/s, loss=0.0635]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11083/44303 [1:05:56<3:17:07,  2.81it/s, loss=0.0692]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11084/44303 [1:05:56<3:16:23,  2.82it/s, loss=0.0692]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11084/44303 [1:05:57<3:16:23,  2.82it/s, loss=0.0422]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11085/44303 [1:05:57<3:16:44,  2.81it/s, loss=0.0422]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11085/44303 [1:05:57<3:16:44,  2.81it/s, loss=0.246] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11086/44303 [1:05:57<3:16:24,  2.82it/s, loss=0.246]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11086/44303 [1:05:57<3:16:24,  2.82it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11087/44303 [1:05:57<3:16:44,  2.81it/s, loss=0.0413]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11087/44303 [1:05:58<3:16:44,  2.81it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11088/44303 [1:05:58<3:17:31,  2.80it/s, loss=0.0333]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11088/44303 [1:05:58<3:17:31,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11089/44303 [1:05:58<3:17:36,  2.80it/s, loss=0.0577]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11089/44303 [1:05:58<3:17:36,  2.80it/s, loss=0.0438]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11090/44303 [1:05:58<3:17:39,  2.80it/s, loss=0.0438]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11090/44303 [1:05:59<3:17:39,  2.80it/s, loss=0.0814]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11091/44303 [1:05:59<3:17:34,  2.80it/s, loss=0.0814]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11091/44303 [1:05:59<3:17:34,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11092/44303 [1:05:59<3:18:00,  2.80it/s, loss=0.0522]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11092/44303 [1:06:00<3:18:00,  2.80it/s, loss=0.071] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11093/44303 [1:06:00<3:17:37,  2.80it/s, loss=0.071]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11093/44303 [1:06:00<3:17:37,  2.80it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11094/44303 [1:06:00<3:17:10,  2.81it/s, loss=0.103]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11094/44303 [1:06:00<3:17:10,  2.81it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11095/44303 [1:06:00<3:17:44,  2.80it/s, loss=0.0548]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11095/44303 [1:06:01<3:17:44,  2.80it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11096/44303 [1:06:01<3:17:15,  2.81it/s, loss=0.0645]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11096/44303 [1:06:01<3:17:15,  2.81it/s, loss=0.0701]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11097/44303 [1:06:01<3:17:28,  2.80it/s, loss=0.0701]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11097/44303 [1:06:01<3:17:28,  2.80it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11098/44303 [1:06:01<3:17:06,  2.81it/s, loss=0.0627]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11098/44303 [1:06:02<3:17:06,  2.81it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11099/44303 [1:06:02<3:17:20,  2.80it/s, loss=0.0608]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11099/44303 [1:06:02<3:17:20,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11100/44303 [1:06:02<3:17:26,  2.80it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11100/44303 [1:06:02<3:17:26,  2.80it/s, loss=0.145] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11101/44303 [1:06:02<3:17:19,  2.80it/s, loss=0.145]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11101/44303 [1:06:03<3:17:19,  2.80it/s, loss=0.0618]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11102/44303 [1:06:03<3:17:44,  2.80it/s, loss=0.0618]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11102/44303 [1:06:03<3:17:44,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11103/44303 [1:06:03<3:17:26,  2.80it/s, loss=0.0335]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11103/44303 [1:06:03<3:17:26,  2.80it/s, loss=0.0668]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11104/44303 [1:06:03<3:17:28,  2.80it/s, loss=0.0668]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11104/44303 [1:06:04<3:17:28,  2.80it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11105/44303 [1:06:04<3:17:18,  2.80it/s, loss=0.0636]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11105/44303 [1:06:04<3:17:18,  2.80it/s, loss=0.0965]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11106/44303 [1:06:04<3:17:16,  2.80it/s, loss=0.0965]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11106/44303 [1:06:05<3:17:16,  2.80it/s, loss=0.0699]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11107/44303 [1:06:05<3:17:34,  2.80it/s, loss=0.0699]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11107/44303 [1:06:05<3:17:34,  2.80it/s, loss=0.0249]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11108/44303 [1:06:05<3:18:34,  2.79it/s, loss=0.0249]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11108/44303 [1:06:05<3:18:34,  2.79it/s, loss=0.0678]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11109/44303 [1:06:05<3:17:53,  2.80it/s, loss=0.0678]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11109/44303 [1:06:06<3:17:53,  2.80it/s, loss=0.0221]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11110/44303 [1:06:06<3:18:22,  2.79it/s, loss=0.0221]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11110/44303 [1:06:06<3:18:22,  2.79it/s, loss=0.0716]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11111/44303 [1:06:06<3:18:54,  2.78it/s, loss=0.0716]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11111/44303 [1:06:06<3:18:54,  2.78it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11112/44303 [1:06:06<3:17:57,  2.79it/s, loss=0.0718]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11112/44303 [1:06:07<3:17:57,  2.79it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11113/44303 [1:06:07<3:18:16,  2.79it/s, loss=0.0646]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11113/44303 [1:06:07<3:18:16,  2.79it/s, loss=0.032] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11114/44303 [1:06:07<3:18:40,  2.78it/s, loss=0.032]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11114/44303 [1:06:07<3:18:40,  2.78it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11115/44303 [1:06:07<3:18:21,  2.79it/s, loss=0.058]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11115/44303 [1:06:08<3:18:21,  2.79it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11116/44303 [1:06:08<3:19:15,  2.78it/s, loss=0.0747]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11116/44303 [1:06:08<3:19:15,  2.78it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11117/44303 [1:06:08<3:18:27,  2.79it/s, loss=0.0563]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11117/44303 [1:06:09<3:18:27,  2.79it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11118/44303 [1:06:09<3:17:35,  2.80it/s, loss=0.0599]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11118/44303 [1:06:09<3:17:35,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11119/44303 [1:06:09<3:17:23,  2.80it/s, loss=0.0533]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11119/44303 [1:06:09<3:17:23,  2.80it/s, loss=0.0281]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11120/44303 [1:06:09<3:18:02,  2.79it/s, loss=0.0281]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11120/44303 [1:06:10<3:18:02,  2.79it/s, loss=0.116] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11121/44303 [1:06:10<3:17:00,  2.81it/s, loss=0.116]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11121/44303 [1:06:10<3:17:00,  2.81it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11122/44303 [1:06:10<3:16:49,  2.81it/s, loss=0.0539]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11122/44303 [1:06:10<3:16:49,  2.81it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11123/44303 [1:06:10<3:17:26,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11123/44303 [1:06:11<3:17:26,  2.80it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11124/44303 [1:06:11<3:17:04,  2.81it/s, loss=0.0632]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11124/44303 [1:06:11<3:17:04,  2.81it/s, loss=0.0321]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11125/44303 [1:06:11<3:16:32,  2.81it/s, loss=0.0321]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11125/44303 [1:06:11<3:16:32,  2.81it/s, loss=0.0656]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11126/44303 [1:06:11<3:16:31,  2.81it/s, loss=0.0656]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11126/44303 [1:06:12<3:16:31,  2.81it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11127/44303 [1:06:12<3:17:03,  2.81it/s, loss=0.0491]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11127/44303 [1:06:12<3:17:03,  2.81it/s, loss=0.0896]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11128/44303 [1:06:12<3:16:47,  2.81it/s, loss=0.0896]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11128/44303 [1:06:12<3:16:47,  2.81it/s, loss=0.0327]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11129/44303 [1:06:12<3:16:45,  2.81it/s, loss=0.0327]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11129/44303 [1:06:13<3:16:45,  2.81it/s, loss=0.0368]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11130/44303 [1:06:13<3:16:23,  2.82it/s, loss=0.0368]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11130/44303 [1:06:13<3:16:23,  2.82it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11131/44303 [1:06:13<3:16:52,  2.81it/s, loss=0.0717]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11131/44303 [1:06:13<3:16:52,  2.81it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11132/44303 [1:06:13<3:16:18,  2.82it/s, loss=0.0509]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11132/44303 [1:06:14<3:16:18,  2.82it/s, loss=0.0363]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11133/44303 [1:06:14<3:15:59,  2.82it/s, loss=0.0363]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11133/44303 [1:06:14<3:15:59,  2.82it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11134/44303 [1:06:14<3:16:28,  2.81it/s, loss=0.0634]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11134/44303 [1:06:15<3:16:28,  2.81it/s, loss=0.0744]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11135/44303 [1:06:15<3:16:29,  2.81it/s, loss=0.0744]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11135/44303 [1:06:15<3:16:29,  2.81it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11136/44303 [1:06:15<3:16:49,  2.81it/s, loss=0.0592]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11136/44303 [1:06:15<3:16:49,  2.81it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11137/44303 [1:06:15<3:17:06,  2.80it/s, loss=0.0759]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11137/44303 [1:06:16<3:17:06,  2.80it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11138/44303 [1:06:16<3:17:24,  2.80it/s, loss=0.0702]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11138/44303 [1:06:16<3:17:24,  2.80it/s, loss=0.0673]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11139/44303 [1:06:16<3:17:19,  2.80it/s, loss=0.0673]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11139/44303 [1:06:16<3:17:19,  2.80it/s, loss=0.118] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11140/44303 [1:06:16<3:17:06,  2.80it/s, loss=0.118]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11140/44303 [1:06:17<3:17:06,  2.80it/s, loss=0.081]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11141/44303 [1:06:17<3:17:38,  2.80it/s, loss=0.081]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11141/44303 [1:06:17<3:17:38,  2.80it/s, loss=0.123]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11142/44303 [1:06:17<3:16:55,  2.81it/s, loss=0.123]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11142/44303 [1:06:17<3:16:55,  2.81it/s, loss=0.042]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11143/44303 [1:06:17<3:17:06,  2.80it/s, loss=0.042]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11143/44303 [1:06:18<3:17:06,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11144/44303 [1:06:18<3:16:57,  2.81it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11144/44303 [1:06:18<3:16:57,  2.81it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11145/44303 [1:06:18<3:16:52,  2.81it/s, loss=0.0578]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11145/44303 [1:06:18<3:16:52,  2.81it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11146/44303 [1:06:18<3:17:18,  2.80it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11146/44303 [1:06:19<3:17:18,  2.80it/s, loss=0.033] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11147/44303 [1:06:19<3:17:13,  2.80it/s, loss=0.033]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11147/44303 [1:06:19<3:17:13,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11148/44303 [1:06:19<3:17:21,  2.80it/s, loss=0.0515]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11148/44303 [1:06:20<3:17:21,  2.80it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11149/44303 [1:06:20<3:17:56,  2.79it/s, loss=0.0531]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11149/44303 [1:06:20<3:17:56,  2.79it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11150/44303 [1:06:20<3:17:35,  2.80it/s, loss=0.0663]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11150/44303 [1:06:20<3:17:35,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11151/44303 [1:06:20<3:17:34,  2.80it/s, loss=0.0553]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11151/44303 [1:06:21<3:17:34,  2.80it/s, loss=0.03]  \u001b[A\n","Training Epoch 1:  25%|██▌       | 11152/44303 [1:06:21<3:17:29,  2.80it/s, loss=0.03]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11152/44303 [1:06:21<3:17:29,  2.80it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11153/44303 [1:06:21<3:17:17,  2.80it/s, loss=0.102]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11153/44303 [1:06:21<3:17:17,  2.80it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11154/44303 [1:06:21<3:17:09,  2.80it/s, loss=0.0629]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11154/44303 [1:06:22<3:17:09,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11155/44303 [1:06:22<3:17:05,  2.80it/s, loss=0.0667]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11155/44303 [1:06:22<3:17:05,  2.80it/s, loss=0.0367]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11156/44303 [1:06:22<3:16:54,  2.81it/s, loss=0.0367]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11156/44303 [1:06:22<3:16:54,  2.81it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11157/44303 [1:06:22<3:16:52,  2.81it/s, loss=0.0516]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11157/44303 [1:06:23<3:16:52,  2.81it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11158/44303 [1:06:23<3:16:44,  2.81it/s, loss=0.0433]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11158/44303 [1:06:23<3:16:44,  2.81it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11159/44303 [1:06:23<3:17:07,  2.80it/s, loss=0.0504]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11159/44303 [1:06:23<3:17:07,  2.80it/s, loss=0.0898]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11160/44303 [1:06:23<3:16:51,  2.81it/s, loss=0.0898]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11160/44303 [1:06:24<3:16:51,  2.81it/s, loss=0.109] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11161/44303 [1:06:24<3:16:50,  2.81it/s, loss=0.109]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11161/44303 [1:06:24<3:16:50,  2.81it/s, loss=0.0688]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11162/44303 [1:06:24<3:16:38,  2.81it/s, loss=0.0688]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11162/44303 [1:06:25<3:16:38,  2.81it/s, loss=0.0944]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11163/44303 [1:06:25<3:16:39,  2.81it/s, loss=0.0944]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11163/44303 [1:06:25<3:16:39,  2.81it/s, loss=0.06]  \u001b[A\n","Training Epoch 1:  25%|██▌       | 11164/44303 [1:06:25<3:16:41,  2.81it/s, loss=0.06]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11164/44303 [1:06:25<3:16:41,  2.81it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11165/44303 [1:06:25<3:16:12,  2.81it/s, loss=0.0495]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11165/44303 [1:06:26<3:16:12,  2.81it/s, loss=0.0705]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11166/44303 [1:06:26<3:16:37,  2.81it/s, loss=0.0705]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11166/44303 [1:06:26<3:16:37,  2.81it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11167/44303 [1:06:26<3:16:20,  2.81it/s, loss=0.0551]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11167/44303 [1:06:26<3:16:20,  2.81it/s, loss=0.0769]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11168/44303 [1:06:26<3:16:40,  2.81it/s, loss=0.0769]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11168/44303 [1:06:27<3:16:40,  2.81it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11169/44303 [1:06:27<3:15:55,  2.82it/s, loss=0.0416]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11169/44303 [1:06:27<3:15:55,  2.82it/s, loss=0.0568]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11170/44303 [1:06:27<3:16:12,  2.81it/s, loss=0.0568]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11170/44303 [1:06:27<3:16:12,  2.81it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11171/44303 [1:06:27<3:16:19,  2.81it/s, loss=0.0758]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11171/44303 [1:06:28<3:16:19,  2.81it/s, loss=0.0961]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11172/44303 [1:06:28<3:16:32,  2.81it/s, loss=0.0961]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11172/44303 [1:06:28<3:16:32,  2.81it/s, loss=0.0381]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11173/44303 [1:06:28<3:16:57,  2.80it/s, loss=0.0381]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11173/44303 [1:06:28<3:16:57,  2.80it/s, loss=0.041] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11174/44303 [1:06:28<3:16:34,  2.81it/s, loss=0.041]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11174/44303 [1:06:29<3:16:34,  2.81it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11175/44303 [1:06:29<3:16:40,  2.81it/s, loss=0.0847]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11175/44303 [1:06:29<3:16:40,  2.81it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11176/44303 [1:06:29<3:17:10,  2.80it/s, loss=0.0703]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11176/44303 [1:06:30<3:17:10,  2.80it/s, loss=0.0266]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11177/44303 [1:06:30<3:16:51,  2.80it/s, loss=0.0266]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11177/44303 [1:06:30<3:16:51,  2.80it/s, loss=0.0836]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11178/44303 [1:06:30<3:17:16,  2.80it/s, loss=0.0836]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11178/44303 [1:06:30<3:17:16,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11179/44303 [1:06:30<3:17:18,  2.80it/s, loss=0.0783]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11179/44303 [1:06:31<3:17:18,  2.80it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11180/44303 [1:06:31<3:17:47,  2.79it/s, loss=0.0503]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11180/44303 [1:06:31<3:17:47,  2.79it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11181/44303 [1:06:31<3:18:33,  2.78it/s, loss=0.0431]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11181/44303 [1:06:31<3:18:33,  2.78it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11182/44303 [1:06:31<3:17:33,  2.79it/s, loss=0.0698]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11182/44303 [1:06:32<3:17:33,  2.79it/s, loss=0.0837]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11183/44303 [1:06:32<3:16:49,  2.80it/s, loss=0.0837]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11183/44303 [1:06:32<3:16:49,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11184/44303 [1:06:32<3:17:15,  2.80it/s, loss=0.0371]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11184/44303 [1:06:32<3:17:15,  2.80it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11185/44303 [1:06:32<3:16:11,  2.81it/s, loss=0.0648]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11185/44303 [1:06:33<3:16:11,  2.81it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11186/44303 [1:06:33<3:16:52,  2.80it/s, loss=0.0867]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11186/44303 [1:06:33<3:16:52,  2.80it/s, loss=0.043] \u001b[A\n","Training Epoch 1:  25%|██▌       | 11187/44303 [1:06:33<3:17:16,  2.80it/s, loss=0.043]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11187/44303 [1:06:33<3:17:16,  2.80it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11188/44303 [1:06:33<3:16:12,  2.81it/s, loss=0.0477]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11188/44303 [1:06:34<3:16:12,  2.81it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11189/44303 [1:06:34<3:17:04,  2.80it/s, loss=0.0579]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11189/44303 [1:06:34<3:17:04,  2.80it/s, loss=0.0991]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11190/44303 [1:06:34<3:16:28,  2.81it/s, loss=0.0991]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11190/44303 [1:06:35<3:16:28,  2.81it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11191/44303 [1:06:35<3:16:52,  2.80it/s, loss=0.0839]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11191/44303 [1:06:35<3:16:52,  2.80it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11192/44303 [1:06:35<3:15:56,  2.82it/s, loss=0.0554]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11192/44303 [1:06:35<3:15:56,  2.82it/s, loss=0.0796]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11193/44303 [1:06:35<3:15:38,  2.82it/s, loss=0.0796]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11193/44303 [1:06:36<3:15:38,  2.82it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11194/44303 [1:06:36<3:16:15,  2.81it/s, loss=0.0729]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11194/44303 [1:06:36<3:16:15,  2.81it/s, loss=0.0673]\u001b[A\n","Training Epoch 1:  25%|██▌       | 11195/44303 [1:06:36<3:16:59,  2.80it/s, loss=0.0673]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-a697bd5352bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m  \u001b[0;31m# Hata hesapla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Geri yayılım (backpropagation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ağırlıkları güncelle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["from tqdm import tqdm\n","from torch.optim import AdamW\n","from transformers import get_scheduler\n","\n","# Modeli eğitime alalım\n","model.train()\n","\n","# Optimizer\n","optimizer = AdamW(model.parameters(), lr=5e-5)\n","\n","# Öğrenme oranı scheduler'ı\n","num_training_steps = len(train_dataloader) * 3  # 3 epoch\n","lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n","\n","# GPU'yu kullanalım\n","model.to(device)\n","\n","# Eğitim döngüsü\n","num_epochs = 3  # 3 epoch çalıştıracağız\n","for epoch in range(num_epochs):\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","\n","    # tqdm ile batch'ler üzerinde ilerleme çubuğu ekleyelim\n","    progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch+1}\", total=len(train_dataloader))\n","\n","    for batch in progress_bar:\n","        input_ids = batch[\"input_ids\"].to(device)\n","        attention_mask = batch[\"attention_mask\"].to(device)\n","        labels = batch[\"labels\"].to(device)\n","\n","        # Modelin tahminini al\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n","\n","        loss = outputs.loss  # Hata hesapla\n","        loss.backward()  # Geri yayılım (backpropagation)\n","\n","        optimizer.step()  # Ağırlıkları güncelle\n","        lr_scheduler.step()  # Öğrenme oranını güncelle\n","        optimizer.zero_grad()  # Gradient'leri sıfırla\n","\n","        # İlerleme çubuğunu güncelle\n","        progress_bar.set_postfix(loss=loss.item())\n","\n","    print(f\"Loss for epoch {epoch+1}: {loss.item():.4f}\")\n"]},{"cell_type":"markdown","metadata":{"id":"EyhevLhjZ559"},"source":["## Eğitilmiş Modeli Kaydetme"]},{"cell_type":"markdown","metadata":{"id":"TlVmEeYfZ83w"},"source":["### Modeli ve Tokenizer’ı Kaydetme"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1742110716339,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"k25HjAYLZiXQ","outputId":"15f3a21c-151c-4097-94d8-239be05c6fa9"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:2758: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[62388]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Model ve tokenizer şu dizine kaydedildi: /content/translation_model_tr2en\n"]}],"source":["import os\n","\n","save_path = \"/content/translation_model_tr2en\"  # Kaydetmek istediğin dizini belirle\n","os.makedirs(save_path, exist_ok=True)\n","\n","model.save_pretrained(save_path)\n","tokenizer.save_pretrained(save_path)\n","\n","print(f\"Model ve tokenizer şu dizine kaydedildi: {save_path}\")\n"]},{"cell_type":"markdown","metadata":{"id":"8UBxf82QIS7P"},"source":["## Modeli Test Etme"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":4032724,"status":"aborted","timestamp":1742110716344,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"p0aj7mncZ_y7","outputId":"37f1a385-c96f-46c6-dd75-e89ad5a1eff7"},"outputs":[{"data":{"text/plain":["MarianMTModel(\n","  (model): MarianModel(\n","    (shared): Embedding(62389, 512, padding_idx=62388)\n","    (encoder): MarianEncoder(\n","      (embed_tokens): Embedding(62389, 512, padding_idx=62388)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianEncoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (activation_fn): SiLU()\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (decoder): MarianDecoder(\n","      (embed_tokens): Embedding(62389, 512, padding_idx=62388)\n","      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n","      (layers): ModuleList(\n","        (0-5): 6 x MarianDecoderLayer(\n","          (self_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (activation_fn): SiLU()\n","          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (encoder_attn): MarianAttention(\n","            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n","            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n","          )\n","          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n","          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n","          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (lm_head): Linear(in_features=512, out_features=62389, bias=False)\n",")"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","\n","# Kaydedilen modeli yükleyelim\n","model_path = \"/content/translation_model_tr2en\"  # Eğer Google Drive'a kaydettiysen path'i değiştir\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n","tokenizer = AutoTokenizer.from_pretrained(model_path)\n","\n","# Modeli GPU'ya taşıyalım\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"markdown","metadata":{"id":"YUFpBDygpBVf"},"source":["### Model İndirme"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":4032728,"status":"aborted","timestamp":1742110716350,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"ABxIYqqPpDnM","outputId":"766c1ffd-6e83-4419-9726-c94d10c27b33"},"outputs":[{"ename":"FileNotFoundError","evalue":"Cannot find file: /content/translation_model_tr2en.zip","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-f42ff7ae0679>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Dosyayı bilgisayarınıza indirmek için\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/translation_model_tr2en.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    231\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Cannot find file: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/translation_model_tr2en.zip"]}],"source":["import shutil\n","from google.colab import files\n","\n","# Kaydedilen modelin bulunduğu dizini sıkıştırıyoruz\n","shutil.make_archive('/content/translation_model_tr2en.zip', 'zip', save_path)\n","\n","# Dosyayı bilgisayarınıza indirmek için\n","files.download('/content/translation_model_tr2en.zip')"]},{"cell_type":"markdown","metadata":{"id":"yxiTa7_sIU9S"},"source":["## Test Cümleleri"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":589,"status":"ok","timestamp":1742110884976,"user":{"displayName":"Taha Buğra Çiçek","userId":"06907806787964251494"},"user_tz":-180},"id":"s2npiqYBIRmS","outputId":"2df406b7-70fa-43d1-8799-53578454d426"},"outputs":[{"output_type":"stream","name":"stdout","text":["Türkçe: Merhaba, nasılsın? \n","İngilizce: Hi, how are you?\n","\n","Türkçe: Bu model Türkçeden İngilizceye çeviri yapabiliyor. \n","İngilizce: This model can translate from Turkish to English.\n","\n","Türkçe: Bugün hava çok güzel. \n","İngilizce: It's a beautiful day today.\n","\n","Türkçe: Yapay zeka geleceğin teknolojisidir. \n","İngilizce: Artificial intelligence is the technology of the future.\n","\n","Türkçe: Seni seviyorum.merhaba \n","İngilizce: I love you. Hi.\n","\n"]}],"source":["def translate(text, model, tokenizer):\n","    model.eval()  # Modeli evaluation moduna al\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n","\n","    with torch.no_grad():\n","        outputs = model.generate(**inputs)\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Test cümleleri\n","test_sentences = [\n","    \"Merhaba, nasılsın?\",\n","    \"Bu model Türkçeden İngilizceye çeviri yapabiliyor.\",\n","    \"Bugün hava çok güzel.\",\n","    \"Yapay zeka geleceğin teknolojisidir.\",\n","    \"Seni seviyorum.\"\n","]\n","\n","for sentence in test_sentences:\n","    translation = translate(sentence, model, tokenizer)\n","    print(f\"Türkçe: {sentence} \\nİngilizce: {translation}\\n\")"]},{"cell_type":"code","source":[],"metadata":{"id":"kQElP71U5THC"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyOe3P6WlHfvIvA6T75mDNYB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}